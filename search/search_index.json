{"config":{"indexing":"full","lang":["fr"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Home"},{"location":"index.html#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"index.html#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"index.html#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"PRESENTATION/index.html","text":"Pr\u00e9sentation du projet Les documents de cette section ont pour objectif de d\u00e9finir le p\u00e9rim\u00e8tre et l'\u00e9cosyst\u00e8me du projet. De ce fait, on trouve : le p\u00e9rim\u00e8tre fonctionnel du projet la description de l'\u00e9cosyst\u00e8me du projet la description des livrables du projet","title":"Introduction"},{"location":"PRESENTATION/index.html#presentation-du-projet","text":"Les documents de cette section ont pour objectif de d\u00e9finir le p\u00e9rim\u00e8tre et l'\u00e9cosyst\u00e8me du projet. De ce fait, on trouve : le p\u00e9rim\u00e8tre fonctionnel du projet la description de l'\u00e9cosyst\u00e8me du projet la description des livrables du projet","title":"Pr\u00e9sentation du projet"},{"location":"PRESENTATION/presentation_ecosysteme.html","text":"Pr\u00e9sentation de l'\u00e9cosyst\u00e8me de Civiparoisse dans un contexte de communication de masse avec du public Civiparoisse est un outil qui s'int\u00e8gre dans un projet paroissial. Ce syst\u00e8me d'information s'int\u00e8gre dans un environnement dont nous vous proposons de comprendre le r\u00f4le. Un outil simple, au service d'une organisation et d'un projet En entreprise, on consid\u00e8re fr\u00e9quemment que l'\u00e9l\u00e9ment fondateur est \" l'id\u00e9e de l'entreprise\", qui se mod\u00e9lise dans un business plan, une strat\u00e9gie , qui comporte des objectifs \u00e0 atteindre. L'entreprise se dote d'une structuration, une organisation dont le but est d'atteindre les objectifs. L'organisation est elle-m\u00eame \u00e9paul\u00e9e \u00e0 travers d'outils, dont le syst\u00e8me d'information , pour atteindre les objectifs. En paroisse, la situation est analogue : * l'\u00e9l\u00e9ment fondateur de la paroisse est la volont\u00e9 de constituer une communaut\u00e9 de paroissiens, avec un projet paroissial . * l' organisation de la paroisse vise \u00e0 r\u00e9aliser ce projet de vie paroissiale, au travers des structures institutionnelles (conseil presbyt\u00e9ral, consistoire, inspection, Uepal) mais \u00e9galement au travers de structures locales (groupes de rencontres comme groupe de bricolage, groupe musical, chorale, \u00e9cole du dimanche, cat\u00e9chisme, \u00e9tude biblique, ...) qui contribient \u00e0 ce projet. * les diff\u00e9rents acteurs de la paroisse ont besoin d'\u00e9changer des informations, pour lequel la mise en oeuvre d'un syst\u00e8me d'information peut faciliter les \u00e9changes. Le syst\u00e8me d'information (SI) est donc un support , mais non une fin en soi. La structure du SI en elle-m\u00eame importe peu, l'essentiel est qu'il facilite les \u00e9changes d'informations. Ce support a par exemple contribu\u00e9 \u00e0 maintenir le lien entre les paroissiens durant les p\u00e9riodes de confinement ou de distanciation sociale. L'int\u00e9gration de l'informatique, support de communication utilis\u00e9 dans la vie quotidienne, fait qu'une informatisation des paroisses devient un atout important pour s'adapter aux habitudes et besoins des paroissiens courants ou \u00e0 venir : les paroisses doivent donc disposer d'une certaine identit\u00e9 num\u00e9rique , qui va \u00eatre surtout utile \u00e0 la communication interne ou externe. Civiparoisse n'est donc in fine qu'un outil qui pourra rentrer dans le cadre du syst\u00e8me d'information, mais qui ne se suffit pas \u00e0 lui-m\u00eame. Communication sur Internet : identit\u00e9 num\u00e9rique, CRM, rapports, webmarketing, outils La communication suppose plusieurs \u00e9l\u00e9ments : un \u00e9metteur: source du message un r\u00e9cepteur: cible du message un support: un medium de communication un code : des conventions communes pour r\u00e9ussir \u00e0 faire passer le contenu un contenu : le sens que l'on veut faire passer. On d\u00e9duit de la liste pr\u00e9c\u00e9dente que l'\u00e9metteur doit \u00eatre identifi\u00e9, d'o\u00f9 la notion d' identit\u00e9 num\u00e9rique qui est \u00e0 d\u00e9velopper dans le cadre des communications sur Internet. Cette identit\u00e9 num\u00e9rique prend plusieurs formes : * un nom de domaine associ\u00e9 \u00e0 l'entit\u00e9 * des adresses de services (adresse de messagerie, num\u00e9ro de t\u00e9l\u00e9phone pour les SMS, adresse SIP pour les communications VoIP...) * un ou plut\u00f4t plusieurs certificats SSL (certificats pour l'identit\u00e9, pour la signature) * une charte graphique : un format de pr\u00e9sentation avec des signes distinctifs (jeux de couleurs, style de pr\u00e9sentation, logo)... La connaissance du r\u00e9cepteur est \u00e9galement importante, puisque le code est commun \u00e0 l'\u00e9metteur et au r\u00e9cepteur : on pourrait donc en particulier prendre soin de certains \u00e9l\u00e9ments comme le langage, les valeurs, les r\u00e9f\u00e9rences connues de l'\u00e9metteur et du r\u00e9cepteur. La connaissance du r\u00e9cepteur est donc \u00e9galement important : cette connaissance est ce qui est traditionnellement g\u00e9r\u00e9/stock\u00e9 par les CRM (Customer Relationship Management), et l'on va chercher \u00e0 extraire des donn\u00e9es depuis cette connaissance pour affiner au plus juste la communication par rapport au r\u00e9cepteur : le datamining , qui peut prendre des formes aussi simple que des extractions de rapports , ou des formes plus compliqu\u00e9es comme l'application d'algorithmes d'intelligence artificielle par exemple pour effectuer une segmentation des r\u00e9cepteurs. La possibilit\u00e9 de communiquer est n\u00e9cessaire \u00e0 un grand nombre, si ce n'est toutes les paroisses, car la communication va \u00eatre un support pour atteindre certains objectifs en vue de r\u00e9aliser le projet paroissial. De ce fait, il est int\u00e9ressant de chercher \u00e0 appliquer des notions de marketing \u00e0 cet effet, et de webmarketing dans le cadre des communications num\u00e9riques, afin de mettre le plus de chances de son c\u00f4t\u00e9 possible d'atteindre le but. Le support joue \u00e9galement un grand r\u00f4le, car les supports peuvent \u00eatre diversifi\u00e9s et compl\u00e9mentaires : le site web peut fournir une vision \"institutionnelle\" de la paroisse, s'adresse \u00e0 un public large, avec des parties de sites \u00e9ventuellement pr\u00e9par\u00e9es pour satisfaire l'int\u00e9r\u00eat de publics plus restreints ; il peut \u00e9galement se faire l'\u00e9cho de l'actualit\u00e9 d'une paroisse la lettre d'information pourra permettre de se tenir au courant de l'actualit\u00e9 de mani\u00e8re passive (sans faire d'action sp\u00e9cifique pour le r\u00e9cepteur) les mailings cibl\u00e9s : diffusion d'information \u00e0 des groupes, comme par exemple les participants \u00e0 une activit\u00e9 Positionnement de CiviParoisse CiviParoisse veut faciliter des points \u00e9voqu\u00e9s au-dessus, comme la gestion de la connaissance des relations avec vos interlocuteurs (paroissiens notamment, mais pas que), la cr\u00e9ation de lettres d'informations et de mailings cibl\u00e9s. Il aura \u00e9galement des d\u00e9pendances sur d'autres \u00e9l\u00e9ments (nom de domaine, certificats SSL, adresses de messagerie, charte graphique, voire m\u00eame le serveur web pour le stockage de m\u00e9dias pour les mails). Son utilisation s'int\u00e8gre donc dans des d\u00e9marches globales qui doivent avoir \u00eat\u00e9 r\u00e9fl\u00e9chies aupr\u00e9alable. C'est donc un outil dont il faut apprendre \u00e0 se servir . L'\u00e9quipe d'accompagnement Civiparoisse vous aidera bien entendu dans la structuration du projet pour votre paroisse, et vous accompagnera dans l'apprentissage de ce nouvel outil.","title":"Ecosyst\u00e8me projet"},{"location":"PRESENTATION/presentation_ecosysteme.html#presentation-de-lecosysteme-de-civiparoisse-dans-un-contexte-de-communication-de-masse-avec-du-public","text":"Civiparoisse est un outil qui s'int\u00e8gre dans un projet paroissial. Ce syst\u00e8me d'information s'int\u00e8gre dans un environnement dont nous vous proposons de comprendre le r\u00f4le.","title":"Pr\u00e9sentation de l'\u00e9cosyst\u00e8me de Civiparoisse dans un contexte de communication de masse avec du public"},{"location":"PRESENTATION/presentation_ecosysteme.html#un-outil-simple-au-service-dune-organisation-et-dun-projet","text":"En entreprise, on consid\u00e8re fr\u00e9quemment que l'\u00e9l\u00e9ment fondateur est \" l'id\u00e9e de l'entreprise\", qui se mod\u00e9lise dans un business plan, une strat\u00e9gie , qui comporte des objectifs \u00e0 atteindre. L'entreprise se dote d'une structuration, une organisation dont le but est d'atteindre les objectifs. L'organisation est elle-m\u00eame \u00e9paul\u00e9e \u00e0 travers d'outils, dont le syst\u00e8me d'information , pour atteindre les objectifs. En paroisse, la situation est analogue : * l'\u00e9l\u00e9ment fondateur de la paroisse est la volont\u00e9 de constituer une communaut\u00e9 de paroissiens, avec un projet paroissial . * l' organisation de la paroisse vise \u00e0 r\u00e9aliser ce projet de vie paroissiale, au travers des structures institutionnelles (conseil presbyt\u00e9ral, consistoire, inspection, Uepal) mais \u00e9galement au travers de structures locales (groupes de rencontres comme groupe de bricolage, groupe musical, chorale, \u00e9cole du dimanche, cat\u00e9chisme, \u00e9tude biblique, ...) qui contribient \u00e0 ce projet. * les diff\u00e9rents acteurs de la paroisse ont besoin d'\u00e9changer des informations, pour lequel la mise en oeuvre d'un syst\u00e8me d'information peut faciliter les \u00e9changes. Le syst\u00e8me d'information (SI) est donc un support , mais non une fin en soi. La structure du SI en elle-m\u00eame importe peu, l'essentiel est qu'il facilite les \u00e9changes d'informations. Ce support a par exemple contribu\u00e9 \u00e0 maintenir le lien entre les paroissiens durant les p\u00e9riodes de confinement ou de distanciation sociale. L'int\u00e9gration de l'informatique, support de communication utilis\u00e9 dans la vie quotidienne, fait qu'une informatisation des paroisses devient un atout important pour s'adapter aux habitudes et besoins des paroissiens courants ou \u00e0 venir : les paroisses doivent donc disposer d'une certaine identit\u00e9 num\u00e9rique , qui va \u00eatre surtout utile \u00e0 la communication interne ou externe. Civiparoisse n'est donc in fine qu'un outil qui pourra rentrer dans le cadre du syst\u00e8me d'information, mais qui ne se suffit pas \u00e0 lui-m\u00eame.","title":"Un outil simple, au service d'une organisation et d'un projet"},{"location":"PRESENTATION/presentation_ecosysteme.html#communication-sur-internet-identite-numerique-crm-rapports-webmarketing-outils","text":"La communication suppose plusieurs \u00e9l\u00e9ments : un \u00e9metteur: source du message un r\u00e9cepteur: cible du message un support: un medium de communication un code : des conventions communes pour r\u00e9ussir \u00e0 faire passer le contenu un contenu : le sens que l'on veut faire passer. On d\u00e9duit de la liste pr\u00e9c\u00e9dente que l'\u00e9metteur doit \u00eatre identifi\u00e9, d'o\u00f9 la notion d' identit\u00e9 num\u00e9rique qui est \u00e0 d\u00e9velopper dans le cadre des communications sur Internet. Cette identit\u00e9 num\u00e9rique prend plusieurs formes : * un nom de domaine associ\u00e9 \u00e0 l'entit\u00e9 * des adresses de services (adresse de messagerie, num\u00e9ro de t\u00e9l\u00e9phone pour les SMS, adresse SIP pour les communications VoIP...) * un ou plut\u00f4t plusieurs certificats SSL (certificats pour l'identit\u00e9, pour la signature) * une charte graphique : un format de pr\u00e9sentation avec des signes distinctifs (jeux de couleurs, style de pr\u00e9sentation, logo)... La connaissance du r\u00e9cepteur est \u00e9galement importante, puisque le code est commun \u00e0 l'\u00e9metteur et au r\u00e9cepteur : on pourrait donc en particulier prendre soin de certains \u00e9l\u00e9ments comme le langage, les valeurs, les r\u00e9f\u00e9rences connues de l'\u00e9metteur et du r\u00e9cepteur. La connaissance du r\u00e9cepteur est donc \u00e9galement important : cette connaissance est ce qui est traditionnellement g\u00e9r\u00e9/stock\u00e9 par les CRM (Customer Relationship Management), et l'on va chercher \u00e0 extraire des donn\u00e9es depuis cette connaissance pour affiner au plus juste la communication par rapport au r\u00e9cepteur : le datamining , qui peut prendre des formes aussi simple que des extractions de rapports , ou des formes plus compliqu\u00e9es comme l'application d'algorithmes d'intelligence artificielle par exemple pour effectuer une segmentation des r\u00e9cepteurs. La possibilit\u00e9 de communiquer est n\u00e9cessaire \u00e0 un grand nombre, si ce n'est toutes les paroisses, car la communication va \u00eatre un support pour atteindre certains objectifs en vue de r\u00e9aliser le projet paroissial. De ce fait, il est int\u00e9ressant de chercher \u00e0 appliquer des notions de marketing \u00e0 cet effet, et de webmarketing dans le cadre des communications num\u00e9riques, afin de mettre le plus de chances de son c\u00f4t\u00e9 possible d'atteindre le but. Le support joue \u00e9galement un grand r\u00f4le, car les supports peuvent \u00eatre diversifi\u00e9s et compl\u00e9mentaires : le site web peut fournir une vision \"institutionnelle\" de la paroisse, s'adresse \u00e0 un public large, avec des parties de sites \u00e9ventuellement pr\u00e9par\u00e9es pour satisfaire l'int\u00e9r\u00eat de publics plus restreints ; il peut \u00e9galement se faire l'\u00e9cho de l'actualit\u00e9 d'une paroisse la lettre d'information pourra permettre de se tenir au courant de l'actualit\u00e9 de mani\u00e8re passive (sans faire d'action sp\u00e9cifique pour le r\u00e9cepteur) les mailings cibl\u00e9s : diffusion d'information \u00e0 des groupes, comme par exemple les participants \u00e0 une activit\u00e9","title":"Communication sur Internet : identit\u00e9 num\u00e9rique, CRM, rapports, webmarketing, outils"},{"location":"PRESENTATION/presentation_ecosysteme.html#positionnement-de-civiparoisse","text":"CiviParoisse veut faciliter des points \u00e9voqu\u00e9s au-dessus, comme la gestion de la connaissance des relations avec vos interlocuteurs (paroissiens notamment, mais pas que), la cr\u00e9ation de lettres d'informations et de mailings cibl\u00e9s. Il aura \u00e9galement des d\u00e9pendances sur d'autres \u00e9l\u00e9ments (nom de domaine, certificats SSL, adresses de messagerie, charte graphique, voire m\u00eame le serveur web pour le stockage de m\u00e9dias pour les mails). Son utilisation s'int\u00e8gre donc dans des d\u00e9marches globales qui doivent avoir \u00eat\u00e9 r\u00e9fl\u00e9chies aupr\u00e9alable. C'est donc un outil dont il faut apprendre \u00e0 se servir . L'\u00e9quipe d'accompagnement Civiparoisse vous aidera bien entendu dans la structuration du projet pour votre paroisse, et vous accompagnera dans l'apprentissage de ce nouvel outil.","title":"Positionnement de CiviParoisse"},{"location":"PRESENTATION/presentation_fonctionnelle.html","text":"Civiparoisse : Aspects fonctionnels Le projet CiviParoisse est un projet r\u00e9cent, qui fournit aux paroisses un outil de gestion op\u00e9rationnelle. Le projet a \u00e9t\u00e9 confort\u00e9 par le virage num\u00e9rique d\u00fb \u00e0 la crise sanitaire (en particulier lors des confinements). Ce document pr\u00e9sente les diff\u00e9rents aspects du projet (notamment fonctionnels, techniques, organisationnels). Les fonctionnalit\u00e9s qui sont requises par les paroisses peuvent \u00eatre globalement regroup\u00e9es en 4 familles : la connaissance des acteurs de la paroisse la communication avec les acteurs les statistiques de la paroisse une aide pour certains sujets de gestion li\u00e9s \u00e0 la paroisse. La connaissance des acteurs de la paroisse La connaissance des acteurs de la paroisse est un \u00e9l\u00e9ment essentiel : une paroisse est en premier lieu une communaut\u00e9 de personnes, dont les interactions vont contribuer \u00e0 la vie de la paroisse. Cette connaissance requiert de conna\u00eetre et de mettre \u00e0 jour des donn\u00e9es personnelles usuelles (nom, pr\u00e9nom, adresse, t\u00e9l\u00e9phone, mail\u2026), mais \u00e9galement des donn\u00e9es plus intimes (filiation), de m\u00eame que des donn\u00e9es sensibles (ayant trait \u00e0 la religion). On parle ici d\u2019acteurs de la paroisse, car des personnes de diff\u00e9rents profils peuvent y figurer : les paroissiens , c\u2019est \u00e0 dire les membres de la paroisse, ainsi que des personnes ressources pour la paroisse (exemple : contact du tr\u00e9sorier de la paroisse), des personnes externes mais dont il faut conserver les donn\u00e9es pour des situations particuli\u00e8res (ex : informations sur les parents s\u00e9par\u00e9s d\u2019un cat\u00e9chum\u00e8ne). Des personnes morales peuvent \u00e9galement \u00eatre repr\u00e9sent\u00e9es (associations, institutions locales comme la municipalit\u00e9 ou une communaut\u00e9 de communes), de m\u00eame que des groupes (ex : activit\u00e9s paroissiales : chorale, cat\u00e9chum\u00e8nes, sacristains, organistes, ouvroir\u2026). Outre les donn\u00e9es sur les acteurs en eux-m\u00eames, il est \u00e9galement important de pouvoir disposer de pr\u00e9cisions sur la relation entre les acteurs : par exemple, dans le cadre d\u2019une activit\u00e9, savoir qui est le responsable de l\u2019activit\u00e9. Ces relations peuvent d\u2019ailleurs \u00e9voluer dans le temps (ex : les conseillers presbyt\u00e9raux, qui ont des mandats limit\u00e9s dans la dur\u00e9e), mais peuvent \u00e9galement \u00eatre multiples (ex : certains conseillers presbyt\u00e9raux sont en plus membre du bureau ; des paroissiens peuvent \u00eatre des membres consultatifs du conseil presbyt\u00e9ral pour des domaines d\u2019expertise sp\u00e9cifique, ...). La communication avec les acteurs de la paroisse La communication des paroisses repose traditionnellement sur plusieurs vecteurs : les annonces lors des cultes le journal paroissial papier le bouche \u00e0 oreille. Ces m\u00e9thodes sont peu adapt\u00e9es aux \u00e9volutions technologiques : le mail les appels t\u00e9l\u00e9phoniques les r\u00e9seaux sociaux les sites web. Civiparoisse cherche \u00e0 optimiser la communication par mail envers les diff\u00e9rents acteurs. On peut distinguer plusieurs cas d\u2019utilisation : la newsletter : c\u2019est le pendant \u00e9lectronique du journal paroissial, avec des informations \u00ab g\u00e9n\u00e9rales \u00bb. Il est n\u00e9cessaire de proposer \u00e9galement une possibilit\u00e9 de se d\u00e9sabonner de la newsletter les campagnes de mails cibl\u00e9s : on envoie des mails avec des informations sur des sujets pr\u00e9cis \u00e0 des personnes s\u00e9lectionn\u00e9es en fonction des crit\u00e8res li\u00e9s \u00e0 la connaissance des acteurs la communication vers une personne : Civiparoisse peut afficher les coordonn\u00e9es d\u2019une personne, et m\u00eame permettre l'envoi de mails individuels. les mails syst\u00e8me d\u2019administration : logs, alertes,\u2026 Il y a un cas d\u2019utilisation li\u00e9, mais qui est en p\u00e9riph\u00e9rie du projet : le stockage des m\u00e9dias r\u00e9f\u00e9renc\u00e9s par les mails. Le plus simple serait : soit d\u2019inclure les m\u00e9dias via des pi\u00e8ces jointes, ou des data URI soit de stocker les m\u00e9dias dans un serveur web tiers, ou un CDN. Dans le cas d\u2019une communication pour le compte de la paroisse, il y a des besoins compl\u00e9mentaires, mais qui sortent du cadre du projet : identit\u00e9 de la paroisse sur internet : son site web identit\u00e9 visuelle de la paroisse, dont d\u00e9coulent des chartes graphiques pour les diff\u00e9rents m\u00e9dias connaissances et comp\u00e9tences en webmarketing, notamment pour les communications de masse organisation \u00e0 un niveau plus global : projet de paroisse (\u00e9quivalent d\u2019un business plan), organisation interne de la paroisse pour r\u00e9aliser le projet de paroisse... Enfin, le projet Civiparoisse n\u2019a pas vocation \u00e0 h\u00e9berger un site web de paroisse, en raison de la nature des donn\u00e9es op\u00e9rationnelles d\u00e9j\u00e0 h\u00e9berg\u00e9es, qui ne sont pas publiques. De m\u00eame, les r\u00e9seaux sociaux sont des outils externes qui se situent plut\u00f4t sur des plateformes h\u00e9berg\u00e9es tierces (YouTube, Facebook, Twitter, LinkedIn\u2026) avec d\u2019\u00e9ventuelles int\u00e9grations sur un site web (non pr\u00e9vu dans ce projet). Les statistiques de la paroisse Les paroisses sont consommatrices de statistiques, pour des fins diverses : rapport sur les diff\u00e9rents \u00e9v\u00e8nements : les bapt\u00eames, confirmations, mariage, d\u00e9c\u00e8s sur l\u2019ann\u00e9e \u00e9coul\u00e9e rapports op\u00e9rationnels : liste des personnes ayant un anniversaire proche, liste des donn\u00e9es qui commencent \u00e0 dater et doivent donc \u00eatre v\u00e9rifi\u00e9es, les paroissiens pr\u00e9sents sur un secteur donn\u00e9, etc... data mining sur les donn\u00e9es collect\u00e9es, pour mieux ajuster le projet de paroisse : rapports d\u00e9mographiques, rapports sur les comp\u00e9tences\u2026 Il n\u2019est pas encore pr\u00e9vu d\u2019utiliser des outils de reporting sp\u00e9cialis\u00e9s (Jasper Report Server par exemple) pour ce besoin, mais ceci pourra changer par la suite. Aide pour certains besoins de gestion La paroisse est tenue de maintenir le registre paroissial, duquel on doit pouvoir sortir au besoin une proposition de liste des \u00e9lecteurs. La gestion de ces documents n\u00e9cessite le traitement d\u2019informations pr\u00e9cises, que ce soit sur les croyances, le bapt\u00eame, le lieu de r\u00e9sidence. Un autre p\u00f4le de ce besoin est la g\u00e9n\u00e9ration de re\u00e7us de dons, ce qui implique donc le traitement de donn\u00e9es comptables. On comprendra que le besoin d\u2019aide pour certaines n\u00e9cessit\u00e9s de gestion s\u2019int\u00e8gre dans les autres besoins \u00e9voqu\u00e9s, mais sera amener \u00e0 \u00e9voluer pour s\u2019adapter aux \u00e9volutions des textes (droit local, r\u00e8glement int\u00e9rieur des \u00e9glises, d\u00e9cisions du Directoire de l\u2019UEPAL, d\u00e9cisions pr\u00e9fectorales\u2026).","title":"P\u00e9rim\u00e8tre fonctionnel"},{"location":"PRESENTATION/presentation_fonctionnelle.html#civiparoisse-aspects-fonctionnels","text":"Le projet CiviParoisse est un projet r\u00e9cent, qui fournit aux paroisses un outil de gestion op\u00e9rationnelle. Le projet a \u00e9t\u00e9 confort\u00e9 par le virage num\u00e9rique d\u00fb \u00e0 la crise sanitaire (en particulier lors des confinements). Ce document pr\u00e9sente les diff\u00e9rents aspects du projet (notamment fonctionnels, techniques, organisationnels). Les fonctionnalit\u00e9s qui sont requises par les paroisses peuvent \u00eatre globalement regroup\u00e9es en 4 familles : la connaissance des acteurs de la paroisse la communication avec les acteurs les statistiques de la paroisse une aide pour certains sujets de gestion li\u00e9s \u00e0 la paroisse.","title":"Civiparoisse : Aspects fonctionnels"},{"location":"PRESENTATION/presentation_fonctionnelle.html#la-connaissance-des-acteurs-de-la-paroisse","text":"La connaissance des acteurs de la paroisse est un \u00e9l\u00e9ment essentiel : une paroisse est en premier lieu une communaut\u00e9 de personnes, dont les interactions vont contribuer \u00e0 la vie de la paroisse. Cette connaissance requiert de conna\u00eetre et de mettre \u00e0 jour des donn\u00e9es personnelles usuelles (nom, pr\u00e9nom, adresse, t\u00e9l\u00e9phone, mail\u2026), mais \u00e9galement des donn\u00e9es plus intimes (filiation), de m\u00eame que des donn\u00e9es sensibles (ayant trait \u00e0 la religion). On parle ici d\u2019acteurs de la paroisse, car des personnes de diff\u00e9rents profils peuvent y figurer : les paroissiens , c\u2019est \u00e0 dire les membres de la paroisse, ainsi que des personnes ressources pour la paroisse (exemple : contact du tr\u00e9sorier de la paroisse), des personnes externes mais dont il faut conserver les donn\u00e9es pour des situations particuli\u00e8res (ex : informations sur les parents s\u00e9par\u00e9s d\u2019un cat\u00e9chum\u00e8ne). Des personnes morales peuvent \u00e9galement \u00eatre repr\u00e9sent\u00e9es (associations, institutions locales comme la municipalit\u00e9 ou une communaut\u00e9 de communes), de m\u00eame que des groupes (ex : activit\u00e9s paroissiales : chorale, cat\u00e9chum\u00e8nes, sacristains, organistes, ouvroir\u2026). Outre les donn\u00e9es sur les acteurs en eux-m\u00eames, il est \u00e9galement important de pouvoir disposer de pr\u00e9cisions sur la relation entre les acteurs : par exemple, dans le cadre d\u2019une activit\u00e9, savoir qui est le responsable de l\u2019activit\u00e9. Ces relations peuvent d\u2019ailleurs \u00e9voluer dans le temps (ex : les conseillers presbyt\u00e9raux, qui ont des mandats limit\u00e9s dans la dur\u00e9e), mais peuvent \u00e9galement \u00eatre multiples (ex : certains conseillers presbyt\u00e9raux sont en plus membre du bureau ; des paroissiens peuvent \u00eatre des membres consultatifs du conseil presbyt\u00e9ral pour des domaines d\u2019expertise sp\u00e9cifique, ...).","title":"La connaissance des acteurs de la paroisse"},{"location":"PRESENTATION/presentation_fonctionnelle.html#la-communication-avec-les-acteurs-de-la-paroisse","text":"La communication des paroisses repose traditionnellement sur plusieurs vecteurs : les annonces lors des cultes le journal paroissial papier le bouche \u00e0 oreille. Ces m\u00e9thodes sont peu adapt\u00e9es aux \u00e9volutions technologiques : le mail les appels t\u00e9l\u00e9phoniques les r\u00e9seaux sociaux les sites web. Civiparoisse cherche \u00e0 optimiser la communication par mail envers les diff\u00e9rents acteurs. On peut distinguer plusieurs cas d\u2019utilisation : la newsletter : c\u2019est le pendant \u00e9lectronique du journal paroissial, avec des informations \u00ab g\u00e9n\u00e9rales \u00bb. Il est n\u00e9cessaire de proposer \u00e9galement une possibilit\u00e9 de se d\u00e9sabonner de la newsletter les campagnes de mails cibl\u00e9s : on envoie des mails avec des informations sur des sujets pr\u00e9cis \u00e0 des personnes s\u00e9lectionn\u00e9es en fonction des crit\u00e8res li\u00e9s \u00e0 la connaissance des acteurs la communication vers une personne : Civiparoisse peut afficher les coordonn\u00e9es d\u2019une personne, et m\u00eame permettre l'envoi de mails individuels. les mails syst\u00e8me d\u2019administration : logs, alertes,\u2026 Il y a un cas d\u2019utilisation li\u00e9, mais qui est en p\u00e9riph\u00e9rie du projet : le stockage des m\u00e9dias r\u00e9f\u00e9renc\u00e9s par les mails. Le plus simple serait : soit d\u2019inclure les m\u00e9dias via des pi\u00e8ces jointes, ou des data URI soit de stocker les m\u00e9dias dans un serveur web tiers, ou un CDN. Dans le cas d\u2019une communication pour le compte de la paroisse, il y a des besoins compl\u00e9mentaires, mais qui sortent du cadre du projet : identit\u00e9 de la paroisse sur internet : son site web identit\u00e9 visuelle de la paroisse, dont d\u00e9coulent des chartes graphiques pour les diff\u00e9rents m\u00e9dias connaissances et comp\u00e9tences en webmarketing, notamment pour les communications de masse organisation \u00e0 un niveau plus global : projet de paroisse (\u00e9quivalent d\u2019un business plan), organisation interne de la paroisse pour r\u00e9aliser le projet de paroisse... Enfin, le projet Civiparoisse n\u2019a pas vocation \u00e0 h\u00e9berger un site web de paroisse, en raison de la nature des donn\u00e9es op\u00e9rationnelles d\u00e9j\u00e0 h\u00e9berg\u00e9es, qui ne sont pas publiques. De m\u00eame, les r\u00e9seaux sociaux sont des outils externes qui se situent plut\u00f4t sur des plateformes h\u00e9berg\u00e9es tierces (YouTube, Facebook, Twitter, LinkedIn\u2026) avec d\u2019\u00e9ventuelles int\u00e9grations sur un site web (non pr\u00e9vu dans ce projet).","title":"La communication avec les acteurs de la paroisse"},{"location":"PRESENTATION/presentation_fonctionnelle.html#les-statistiques-de-la-paroisse","text":"Les paroisses sont consommatrices de statistiques, pour des fins diverses : rapport sur les diff\u00e9rents \u00e9v\u00e8nements : les bapt\u00eames, confirmations, mariage, d\u00e9c\u00e8s sur l\u2019ann\u00e9e \u00e9coul\u00e9e rapports op\u00e9rationnels : liste des personnes ayant un anniversaire proche, liste des donn\u00e9es qui commencent \u00e0 dater et doivent donc \u00eatre v\u00e9rifi\u00e9es, les paroissiens pr\u00e9sents sur un secteur donn\u00e9, etc... data mining sur les donn\u00e9es collect\u00e9es, pour mieux ajuster le projet de paroisse : rapports d\u00e9mographiques, rapports sur les comp\u00e9tences\u2026 Il n\u2019est pas encore pr\u00e9vu d\u2019utiliser des outils de reporting sp\u00e9cialis\u00e9s (Jasper Report Server par exemple) pour ce besoin, mais ceci pourra changer par la suite.","title":"Les statistiques de la paroisse"},{"location":"PRESENTATION/presentation_fonctionnelle.html#aide-pour-certains-besoins-de-gestion","text":"La paroisse est tenue de maintenir le registre paroissial, duquel on doit pouvoir sortir au besoin une proposition de liste des \u00e9lecteurs. La gestion de ces documents n\u00e9cessite le traitement d\u2019informations pr\u00e9cises, que ce soit sur les croyances, le bapt\u00eame, le lieu de r\u00e9sidence. Un autre p\u00f4le de ce besoin est la g\u00e9n\u00e9ration de re\u00e7us de dons, ce qui implique donc le traitement de donn\u00e9es comptables. On comprendra que le besoin d\u2019aide pour certaines n\u00e9cessit\u00e9s de gestion s\u2019int\u00e8gre dans les autres besoins \u00e9voqu\u00e9s, mais sera amener \u00e0 \u00e9voluer pour s\u2019adapter aux \u00e9volutions des textes (droit local, r\u00e8glement int\u00e9rieur des \u00e9glises, d\u00e9cisions du Directoire de l\u2019UEPAL, d\u00e9cisions pr\u00e9fectorales\u2026).","title":"Aide pour certains besoins de gestion"},{"location":"PRESENTATION/presentation_livrables.html","text":"Pr\u00e9sentation des livrables Civiparoisse La philosophie du projet est de laisser les paroisses qui souhaitent utiliser Civiparoisse libres et responsables de leurs choix d'impl\u00e9mentation. De ce fait, Civiparoisse d\u00e9finit un certain nombre de livrables que les paroisses pourront utiliser si elles le souhaitent. Ces livrables correspondent \u00e0 des niveaux d'int\u00e9gration de Civiparoisse dans des environnements de plus en plus \u00e9tendus. Approches envisag\u00e9es pour les paroisses La mise en \u0153uvre de la solution est envisageable sous trois formes, en fonction des souhaits des paroisses : le code d\u00e9velopp\u00e9 \u00e9tant sous licence de logiciel libre, les paroisses sont libres de r\u00e9utiliser le code d\u2019elles-m\u00eames et d\u2019h\u00e9berger la solution comme bon leur semble, voire m\u00eame de cr\u00e9er leur propre solution ; toutefois, on constate en pratique que les ressources humaines ayant des comp\u00e9tences en informatique sont rares dans les paroisses, et donc, m\u00eame si la possibilit\u00e9 d\u2019ind\u00e9pendance des paroisses existe, cette solution est difficilement envisageable les paroisses peuvent souhaiter disposer d\u2019un \u00ab package logiciel \u00bb et assurer les aspects infrastructures elles-m\u00eames : ceci permet aux paroisses qui d\u00e9sirent administrer leur solution de le faire comme bon leur semble, tout en profitant toutefois d\u2019une solution logicielle commune. Ceci peut \u00e9galement \u00eatre arrangeant pour une paroisse qui aurait d\u00e9j\u00e0 une infrastructure existante pr\u00e9voir la possibilit\u00e9 d\u2019une infrastructure d\u2019h\u00e9bergement \u00ab centralis\u00e9e \u00bb, o\u00f9 seront d\u00e9ploy\u00e9es les instances packag\u00e9es d\u00e9crites au-dessus : cette deuxi\u00e8me solution est la voie privil\u00e9gi\u00e9e, avec d\u2019\u00e9ventuelles \u00e9conomies d\u2019\u00e9chelles (en particulier, les moyens humains utilis\u00e9s, mais \u00e9galement les mat\u00e9riels) ; en contrepartie, les paroisses perdent notamment la main mise sur le syst\u00e8me : il s\u2019agira donc de concevoir un \u00ab produit standardis\u00e9 d\u2019h\u00e9bergement \u00bb. Livrables On retrouve donc, dans un degr\u00e9 d'int\u00e9gration croissant : Composants logiciels sp\u00e9cifiques Ces composants sont pour l'heure au nombre de trois : plugin pour l'authentification, au niveau de Drupal plugin d'installation de CiviCRM ** extension CiviCRM contenant le code de Civiparoisse. Images Docker Si l\u2019on regarde l\u2019\u00e9volution des pratiques d\u2019h\u00e9bergement informatique, on est pass\u00e9 progressivement des serveurs physiques d\u00e9di\u00e9s aux machines virtuelles, et depuis quelques ann\u00e9es, avec l\u2019av\u00e8nement de la tendance devops, on assiste plut\u00f4t \u00e0 un passage \u00e0 des architectures microservices containaris\u00e9s. Dans le cadre du package logiciel pour la production, il semble plus judicieux de passer par des containers et l\u2019infrastructure microservices. En effet, ce type d\u2019architecture est con\u00e7ue pour faciliter les mises \u00e0 jour des infrastructures de mani\u00e8re rapide, en recr\u00e9ant les images des containers via des fichiers de build. De plus, on peut avoir une s\u00e9paration plus nette entre les chemins qui sont en lecture \u00e9crite et ceux en lecture seule, avec en particulier la notion de volumes. Cette notion de volume peut d\u2019ailleurs aussi \u00eatre exploit\u00e9e pour chercher \u00e0 concentrer les \u00e9l\u00e9ments de configuration des environnements dans des endroits sp\u00e9cifiques (config map kubernetes par exemple), et les donn\u00e9es sensibles (clefs par exemple) peuvent \u00eatre stock\u00e9s dans des volumes de secrets. Enfin, les logs peuvent \u00eatre disponibles via les entr\u00e9es sorties standard. En revanche, pour des d\u00e9monstrations, l\u2019installation dans une machine virtuelle est plus accessible et plus simple \u00e0 mettre en \u0153uvre. Les images tendent \u00e0 s'affiner progressivement ; pour l'heure, on retrouve les images suivantes : composer_base : une image avec une version de composer dont les d\u00e9pendances sont compatibles avec le code de CiviCRM composer_files : image qui va mettre en oeuvre un fichier composer.json permettant de r\u00e9cup\u00e9rer l'ensemble des fichiers n\u00e9cessaires \u00e0 l'installation du syst\u00e8me tools : image qui ajoute des outils d'usage g\u00e9n\u00e9ral et qui va servir en tant qu'image \"tout terrain\" pour des images \u00e0 utilisation \"\u00e9ph\u00e9m\u00e8re\" init : image pour initialiser une instance (au niveau des fichiers et de la base de donn\u00e9es) de CiviCRM, avec une configuration initiale basique cron : image pour ex\u00e9cuter les t\u00e2ches p\u00e9riodiques selfkeys : image pour figer un ensemble de clefs autosign\u00e9es pour faciliter les d\u00e9ploiements de d\u00e9monstration httpd : le serveur web interne, qui est acc\u00e9d\u00e9 indirectement pour r\u00e9pondre aux utilisateurs authenticator : un petit service d'authentification pour v\u00e9rifier les identifiants d'un utilisateur proxy : reverse proxy qui va authentifier les requ\u00eates des utilisateurs et les transmettre au serveur web interne. Des docker-compose compl\u00e8tent ces images pour monter rapidement un environnement pour faire une d\u00e9monstration ou des essais. Pr\u00e9requis Les pr\u00e9requis constituent des \u00e9l\u00e9ments que les paroisses qui souhaitent utiliser les images devront s\u2019occuper elles-m\u00eames. On ne peut ni couvrir tous les sujets, ni les aborder sp\u00e9cifiquement, mais on peut citer en premi\u00e8re intention les points suivants : les paroisses devront administrer civicrm et drupal, et savoir utiliser la solution : les paroisses devront avoir un responsable qui sera administrateur civicrm et drupal, poureffectuer les op\u00e9rations courantes d\u2019administration (cr\u00e9ation, d\u00e9sactivation de comptes, reset de mot de passe...) les paroisses devront savoir comment reconstruire une image : ceci est notamment n\u00e9cessaire pour palier au cas o\u00f9 un patch de s\u00e9curit\u00e9 devrait rapidement appliqu\u00e9 les images, lorsqu\u2019utilis\u00e9es dans des containers, n\u00e9cessitent des volumes de donn\u00e9es pour les donn\u00e9es persistantes. Ces volumes seront g\u00e9r\u00e9s par l\u2019h\u00f4te. On aura besoin de plusieurs volumes, avec la particularit\u00e9 que les volumes de fichiers m\u00e9tiers seront partag\u00e9s entre containers (cron, web, et sauvegarde, notamment). Les volumes devront \u00eatre chiffr\u00e9s, et la sauvegarde devra \u00eatre chiffr\u00e9e et d\u00e9port\u00e9e vers un site distant en France, qui offre des garanties quant \u00e0 la s\u00e9curit\u00e9 des donn\u00e9es l\u2019h\u00f4te : il faut le voir comme un environnement d\u2019ex\u00e9cution qui a \u00e9t\u00e9 fiabilis\u00e9, de haute disponibilit\u00e9, et le plus s\u00e9curis\u00e9 possible un nom de domaine est requis, car il est utile en particulier pour les enregistrements DNS sp\u00e9cifiques pour les techniques antispam (DKIM, SPF) de plus, il faudra g\u00e9rer un service de messagerie li\u00e9 au domaine, en particulier pour r\u00e9cup\u00e9rer et traiter les retours en erreur des envois de mails en masse. Les envois de mails en masse devront d\u2019ailleurs passer par un prestataire sp\u00e9cialis\u00e9, car normalement ces prestataires devraient mieux savoir g\u00e9rer des probl\u00e8mes de mails consid\u00e9r\u00e9s comme spams, et peuvent \u00e9ventuellement avoir des serveurs reconnus comme des sources de trafic l\u00e9gitime il faudra non seulement placer l\u2019ensemble de l\u2019infrastructure derri\u00e8re un pare-feu, mais il faudra \u00e9galement pr\u00e9voir un acc\u00e8s \u00e0 CiviParoisse uniquement via un VPN, acc\u00e9d\u00e9 via une authentification forte des certificats vont \u00e9galement \u00eatre n\u00e9cessaires, en particulier pour le serveur web, ce qui pose le probl\u00e8me de la gestion des clefs et d\u2019une PKI. L\u2019ensemble des flux r\u00e9seaux devra \u00eatre chiffr\u00e9 il faudra \u00e9galement mettre en place des outils de supervision / monitoring des containers, de m\u00eame que la r\u00e9cup\u00e9ration et l\u2019analyse des logs. Vu la complexit\u00e9, les comp\u00e9tences, et la disponibilit\u00e9 des ressources, autant mat\u00e9rielles qu\u2019humaines, qui entrent en jeu, on peut a priori penser qu\u2019il sera plus efficace de centraliser l\u2019h\u00e9bergement (et intrins\u00e8quement l\u2019administration) des instances. Int\u00e9gration Kubernetes un package Helm : le package permet de fournir un processus de d\u00e9ploiement dans des plateformes Kubernetes H\u00e9bergement un h\u00e9bergement dans une infrastructure n\u00e9goci\u00e9e par l'Uepal. L'ensemble des codes seront livr\u00e9s dans des d\u00e9p\u00f4ts Git \u00e0 acc\u00e8s public. Il est \u00e0 noter que ces d\u00e9p\u00f4ts \u00e0 acc\u00e8s public ne sont pas les d\u00e9p\u00f4ts utilis\u00e9s pour le d\u00e9veloppement, et ne contiendront que des \"\"versions num\u00e9rot\u00e9es\" des codes.","title":"Livrables"},{"location":"PRESENTATION/presentation_livrables.html#presentation-des-livrables-civiparoisse","text":"La philosophie du projet est de laisser les paroisses qui souhaitent utiliser Civiparoisse libres et responsables de leurs choix d'impl\u00e9mentation. De ce fait, Civiparoisse d\u00e9finit un certain nombre de livrables que les paroisses pourront utiliser si elles le souhaitent. Ces livrables correspondent \u00e0 des niveaux d'int\u00e9gration de Civiparoisse dans des environnements de plus en plus \u00e9tendus.","title":"Pr\u00e9sentation des livrables Civiparoisse"},{"location":"PRESENTATION/presentation_livrables.html#approches-envisagees-pour-les-paroisses","text":"La mise en \u0153uvre de la solution est envisageable sous trois formes, en fonction des souhaits des paroisses : le code d\u00e9velopp\u00e9 \u00e9tant sous licence de logiciel libre, les paroisses sont libres de r\u00e9utiliser le code d\u2019elles-m\u00eames et d\u2019h\u00e9berger la solution comme bon leur semble, voire m\u00eame de cr\u00e9er leur propre solution ; toutefois, on constate en pratique que les ressources humaines ayant des comp\u00e9tences en informatique sont rares dans les paroisses, et donc, m\u00eame si la possibilit\u00e9 d\u2019ind\u00e9pendance des paroisses existe, cette solution est difficilement envisageable les paroisses peuvent souhaiter disposer d\u2019un \u00ab package logiciel \u00bb et assurer les aspects infrastructures elles-m\u00eames : ceci permet aux paroisses qui d\u00e9sirent administrer leur solution de le faire comme bon leur semble, tout en profitant toutefois d\u2019une solution logicielle commune. Ceci peut \u00e9galement \u00eatre arrangeant pour une paroisse qui aurait d\u00e9j\u00e0 une infrastructure existante pr\u00e9voir la possibilit\u00e9 d\u2019une infrastructure d\u2019h\u00e9bergement \u00ab centralis\u00e9e \u00bb, o\u00f9 seront d\u00e9ploy\u00e9es les instances packag\u00e9es d\u00e9crites au-dessus : cette deuxi\u00e8me solution est la voie privil\u00e9gi\u00e9e, avec d\u2019\u00e9ventuelles \u00e9conomies d\u2019\u00e9chelles (en particulier, les moyens humains utilis\u00e9s, mais \u00e9galement les mat\u00e9riels) ; en contrepartie, les paroisses perdent notamment la main mise sur le syst\u00e8me : il s\u2019agira donc de concevoir un \u00ab produit standardis\u00e9 d\u2019h\u00e9bergement \u00bb.","title":"Approches envisag\u00e9es pour les paroisses"},{"location":"PRESENTATION/presentation_livrables.html#livrables","text":"On retrouve donc, dans un degr\u00e9 d'int\u00e9gration croissant :","title":"Livrables"},{"location":"PRESENTATION/presentation_livrables.html#composants-logiciels-specifiques","text":"Ces composants sont pour l'heure au nombre de trois : plugin pour l'authentification, au niveau de Drupal plugin d'installation de CiviCRM ** extension CiviCRM contenant le code de Civiparoisse.","title":"Composants logiciels sp\u00e9cifiques"},{"location":"PRESENTATION/presentation_livrables.html#images-docker","text":"Si l\u2019on regarde l\u2019\u00e9volution des pratiques d\u2019h\u00e9bergement informatique, on est pass\u00e9 progressivement des serveurs physiques d\u00e9di\u00e9s aux machines virtuelles, et depuis quelques ann\u00e9es, avec l\u2019av\u00e8nement de la tendance devops, on assiste plut\u00f4t \u00e0 un passage \u00e0 des architectures microservices containaris\u00e9s. Dans le cadre du package logiciel pour la production, il semble plus judicieux de passer par des containers et l\u2019infrastructure microservices. En effet, ce type d\u2019architecture est con\u00e7ue pour faciliter les mises \u00e0 jour des infrastructures de mani\u00e8re rapide, en recr\u00e9ant les images des containers via des fichiers de build. De plus, on peut avoir une s\u00e9paration plus nette entre les chemins qui sont en lecture \u00e9crite et ceux en lecture seule, avec en particulier la notion de volumes. Cette notion de volume peut d\u2019ailleurs aussi \u00eatre exploit\u00e9e pour chercher \u00e0 concentrer les \u00e9l\u00e9ments de configuration des environnements dans des endroits sp\u00e9cifiques (config map kubernetes par exemple), et les donn\u00e9es sensibles (clefs par exemple) peuvent \u00eatre stock\u00e9s dans des volumes de secrets. Enfin, les logs peuvent \u00eatre disponibles via les entr\u00e9es sorties standard. En revanche, pour des d\u00e9monstrations, l\u2019installation dans une machine virtuelle est plus accessible et plus simple \u00e0 mettre en \u0153uvre. Les images tendent \u00e0 s'affiner progressivement ; pour l'heure, on retrouve les images suivantes : composer_base : une image avec une version de composer dont les d\u00e9pendances sont compatibles avec le code de CiviCRM composer_files : image qui va mettre en oeuvre un fichier composer.json permettant de r\u00e9cup\u00e9rer l'ensemble des fichiers n\u00e9cessaires \u00e0 l'installation du syst\u00e8me tools : image qui ajoute des outils d'usage g\u00e9n\u00e9ral et qui va servir en tant qu'image \"tout terrain\" pour des images \u00e0 utilisation \"\u00e9ph\u00e9m\u00e8re\" init : image pour initialiser une instance (au niveau des fichiers et de la base de donn\u00e9es) de CiviCRM, avec une configuration initiale basique cron : image pour ex\u00e9cuter les t\u00e2ches p\u00e9riodiques selfkeys : image pour figer un ensemble de clefs autosign\u00e9es pour faciliter les d\u00e9ploiements de d\u00e9monstration httpd : le serveur web interne, qui est acc\u00e9d\u00e9 indirectement pour r\u00e9pondre aux utilisateurs authenticator : un petit service d'authentification pour v\u00e9rifier les identifiants d'un utilisateur proxy : reverse proxy qui va authentifier les requ\u00eates des utilisateurs et les transmettre au serveur web interne. Des docker-compose compl\u00e8tent ces images pour monter rapidement un environnement pour faire une d\u00e9monstration ou des essais.","title":"Images Docker"},{"location":"PRESENTATION/presentation_livrables.html#prerequis","text":"Les pr\u00e9requis constituent des \u00e9l\u00e9ments que les paroisses qui souhaitent utiliser les images devront s\u2019occuper elles-m\u00eames. On ne peut ni couvrir tous les sujets, ni les aborder sp\u00e9cifiquement, mais on peut citer en premi\u00e8re intention les points suivants : les paroisses devront administrer civicrm et drupal, et savoir utiliser la solution : les paroisses devront avoir un responsable qui sera administrateur civicrm et drupal, poureffectuer les op\u00e9rations courantes d\u2019administration (cr\u00e9ation, d\u00e9sactivation de comptes, reset de mot de passe...) les paroisses devront savoir comment reconstruire une image : ceci est notamment n\u00e9cessaire pour palier au cas o\u00f9 un patch de s\u00e9curit\u00e9 devrait rapidement appliqu\u00e9 les images, lorsqu\u2019utilis\u00e9es dans des containers, n\u00e9cessitent des volumes de donn\u00e9es pour les donn\u00e9es persistantes. Ces volumes seront g\u00e9r\u00e9s par l\u2019h\u00f4te. On aura besoin de plusieurs volumes, avec la particularit\u00e9 que les volumes de fichiers m\u00e9tiers seront partag\u00e9s entre containers (cron, web, et sauvegarde, notamment). Les volumes devront \u00eatre chiffr\u00e9s, et la sauvegarde devra \u00eatre chiffr\u00e9e et d\u00e9port\u00e9e vers un site distant en France, qui offre des garanties quant \u00e0 la s\u00e9curit\u00e9 des donn\u00e9es l\u2019h\u00f4te : il faut le voir comme un environnement d\u2019ex\u00e9cution qui a \u00e9t\u00e9 fiabilis\u00e9, de haute disponibilit\u00e9, et le plus s\u00e9curis\u00e9 possible un nom de domaine est requis, car il est utile en particulier pour les enregistrements DNS sp\u00e9cifiques pour les techniques antispam (DKIM, SPF) de plus, il faudra g\u00e9rer un service de messagerie li\u00e9 au domaine, en particulier pour r\u00e9cup\u00e9rer et traiter les retours en erreur des envois de mails en masse. Les envois de mails en masse devront d\u2019ailleurs passer par un prestataire sp\u00e9cialis\u00e9, car normalement ces prestataires devraient mieux savoir g\u00e9rer des probl\u00e8mes de mails consid\u00e9r\u00e9s comme spams, et peuvent \u00e9ventuellement avoir des serveurs reconnus comme des sources de trafic l\u00e9gitime il faudra non seulement placer l\u2019ensemble de l\u2019infrastructure derri\u00e8re un pare-feu, mais il faudra \u00e9galement pr\u00e9voir un acc\u00e8s \u00e0 CiviParoisse uniquement via un VPN, acc\u00e9d\u00e9 via une authentification forte des certificats vont \u00e9galement \u00eatre n\u00e9cessaires, en particulier pour le serveur web, ce qui pose le probl\u00e8me de la gestion des clefs et d\u2019une PKI. L\u2019ensemble des flux r\u00e9seaux devra \u00eatre chiffr\u00e9 il faudra \u00e9galement mettre en place des outils de supervision / monitoring des containers, de m\u00eame que la r\u00e9cup\u00e9ration et l\u2019analyse des logs. Vu la complexit\u00e9, les comp\u00e9tences, et la disponibilit\u00e9 des ressources, autant mat\u00e9rielles qu\u2019humaines, qui entrent en jeu, on peut a priori penser qu\u2019il sera plus efficace de centraliser l\u2019h\u00e9bergement (et intrins\u00e8quement l\u2019administration) des instances.","title":"Pr\u00e9requis"},{"location":"PRESENTATION/presentation_livrables.html#integration-kubernetes","text":"un package Helm : le package permet de fournir un processus de d\u00e9ploiement dans des plateformes Kubernetes","title":"Int\u00e9gration Kubernetes"},{"location":"PRESENTATION/presentation_livrables.html#hebergement","text":"un h\u00e9bergement dans une infrastructure n\u00e9goci\u00e9e par l'Uepal. L'ensemble des codes seront livr\u00e9s dans des d\u00e9p\u00f4ts Git \u00e0 acc\u00e8s public. Il est \u00e0 noter que ces d\u00e9p\u00f4ts \u00e0 acc\u00e8s public ne sont pas les d\u00e9p\u00f4ts utilis\u00e9s pour le d\u00e9veloppement, et ne contiendront que des \"\"versions num\u00e9rot\u00e9es\" des codes.","title":"H\u00e9bergement"},{"location":"TECHNIQUE/roles.html","text":"Int\u00e9gration des r\u00f4les Les r\u00f4les utilisateurs sont un sujet complexe. Un r\u00f4le regroupe un ensemble de permissions qui sont n\u00e9cessaires \u00e0 la r\u00e9alisation d'une t\u00e2che. On attribute ensuite \u00e0 un utilisateur le ou les r\u00f4les qui lui sont n\u00e9cessaires. Au niveau de CiviCRM au-dessus de Drupal, on constate que les permissions utilis\u00e9es sont int\u00e9gr\u00e9es dans Drupal, si bien que la gestion des r\u00f4les se ferait r\u00e9ellement au niveau de Drupal et pas au niveau de CiviCRM. On ne parle en revanche pas ici du syst\u00e8me d'ACL propos\u00e9 par CiviCRM. Attention : L'exception de l'utilisateur Drupal UID 1 Cet utilisateur est une exception dans Drupal, car il est pr\u00e9vu pour toujours se voir donner toutes les permissions. Sch\u00e9ma yaml Les r\u00f4les sont stock\u00e9s comme des objets de configuration, et se retrouvent de ce fait dans la table config de Drupal, et comment par user.role . Etant donn\u00e9 que ce sont des objets de configuration, ils sont d\u00e9crits par un sch\u00e9ma ( /app/web/core/modules/user/config/schema/user.schema.yml ): user.role.* : type : config_entity label : 'User role settings' mapping : id : type : string label : 'ID' label : type : label label : 'Label' weight : type : integer label : 'User role weight' is_admin : type : boolean label : 'User is admin' permissions : type : sequence label : 'Permissions' sequence : type : string label : 'Permission' Il devient de ce fait plus int\u00e9ressant de coder les r\u00f4les dans des fichiers yaml, voire m\u00eame de les cr\u00e9er sur une instance de d\u00e9veloppement, supprimer leur uuid, et de les r\u00e9cup\u00e9rer pour les int\u00e9grer dans les autres instances, o\u00f9 le nom de fichier d\u00e9termine le nom de l'objet de configuration. Export d'un r\u00f4le drush config:get user.role.r1 >user.role.r1.yml cat user.role.r1.yml uuid : b0d165ca-3a16-4996-9aa8-e57366a22a2c langcode : fr status : true dependencies : module : - block - civicrm id : r1 label : R1 weight : 4 is_admin : null permissions : - 'administer blocks' - 'authenticate with password' Pour supprimer au passage l'UUID : cat user.role.r1.yml | grep -v uuid >TEST/user.role.r1.yml Import des r\u00f4les Pour importer le fichier yaml, il faut faire attention de bien indiquer un import partiel (sans quoi les objets de configuration non existants sont supprim\u00e9s). La source est le r\u00e9pertoire dans lequel sont stock\u00e9s les fichiers \u00e0 importer. drush --no-interaction config:import --partial --source = /app/TEST -vvv V\u00e9rification de l'\u00e9tat Pour v\u00e9rifier la source de configuration pour les diff\u00e9rents objets : drush config:status Impl\u00e9mentation dans le SI Le moyen le plus simple d'int\u00e9grer les r\u00f4les est de cr\u00e9er un package composer suppl\u00e9mentaire \u00e0 l'aide d'un d\u00e9p\u00f4t git, et d'appeler les commandes drush lors de l'installation initiale et lors des mises \u00e0 jour. De ce fait, les packages de r\u00f4les seront versionn\u00e9s et la correspondance de versions sera ma\u00eetris\u00e9e via le composer.json principal ; de plus, ces fichiers seront pr\u00e9sents directement dans les images Docker, qui elles-m\u00eames peuvent \u00eatre tagg\u00e9es, et donc versionn\u00e9es. Strat\u00e9gie \u00e0 long terme Il est probable que l'ensemble des r\u00f4les propos\u00e9s avec Civiparoisse ne correspondra pas aux besoins de toutes les paroisses, et que des jeux de r\u00f4les vont venir remplacer ou compl\u00e9ter le jeu de r\u00f4les initial. Toutefois, il faut assurer une certaine \"compatibilit\u00e9 ascendante\", de sorte \u00e0 ne pas casser les droits et surtout les droits non donn\u00e9s aux utilisateurs. Ainsi, si un r\u00f4le est cr\u00e9e, il ne devra pas \u00eatre modifi\u00e9, car il faut consid\u00e9rer qu'il a pu \u00eatre utilis\u00e9 par une paroisse, et qu'il ne faut pas interf\u00e9rer dans les droits donn\u00e9s par une paroisse. A ce sujet, comme les paroisses peuvent \u00e9galement cr\u00e9er des r\u00f4les, il faudra d\u00e9finir un pr\u00e9fixe utilis\u00e9 pour les r\u00f4les pr\u00e9par\u00e9s pour Civiparoisse. On pourrait donc arriver \u00e0 un nom de r\u00f4le comme user.role.civiparoisse.<nom_jeu>_<nom_role> . Un cas particulier doit cependant \u00eatre pr\u00e9vu : le cas o\u00f9 les permissions \u00e9voluent dans CiviCRM ou Drupal. Dans ce cas pr\u00e9cis, on peut envisager de supprimer les droits des anciens r\u00f4les cr\u00e9es par Civiparoisse et pr\u00e9parer un nouveau jeu de r\u00f4les : l'utilisateur UID 1 pourra de toute mani\u00e8re intervenir pour mettre en place les nouveaux droits : c'est une approche s\u00fbre, dans la mesure o\u00f9 on ne donnera \u00e0 aucun moment par m\u00e9garde des droits trop importants \u00e0 des utilisateurs. En revanche, si l'utilisateur UID 1 n'est pas un utilisateur de la paroisse (\u00e9quipe technique interne Civiparoisse), il faudra convenir d'une r\u00e9union de maintenance avec les responsables de la paroisse pour effectuer les actions qui conviennent.","title":"R\u00f4les"},{"location":"TECHNIQUE/roles.html#integration-des-roles","text":"Les r\u00f4les utilisateurs sont un sujet complexe. Un r\u00f4le regroupe un ensemble de permissions qui sont n\u00e9cessaires \u00e0 la r\u00e9alisation d'une t\u00e2che. On attribute ensuite \u00e0 un utilisateur le ou les r\u00f4les qui lui sont n\u00e9cessaires. Au niveau de CiviCRM au-dessus de Drupal, on constate que les permissions utilis\u00e9es sont int\u00e9gr\u00e9es dans Drupal, si bien que la gestion des r\u00f4les se ferait r\u00e9ellement au niveau de Drupal et pas au niveau de CiviCRM. On ne parle en revanche pas ici du syst\u00e8me d'ACL propos\u00e9 par CiviCRM. Attention : L'exception de l'utilisateur Drupal UID 1 Cet utilisateur est une exception dans Drupal, car il est pr\u00e9vu pour toujours se voir donner toutes les permissions.","title":"Int\u00e9gration des r\u00f4les"},{"location":"TECHNIQUE/roles.html#schema-yaml","text":"Les r\u00f4les sont stock\u00e9s comme des objets de configuration, et se retrouvent de ce fait dans la table config de Drupal, et comment par user.role . Etant donn\u00e9 que ce sont des objets de configuration, ils sont d\u00e9crits par un sch\u00e9ma ( /app/web/core/modules/user/config/schema/user.schema.yml ): user.role.* : type : config_entity label : 'User role settings' mapping : id : type : string label : 'ID' label : type : label label : 'Label' weight : type : integer label : 'User role weight' is_admin : type : boolean label : 'User is admin' permissions : type : sequence label : 'Permissions' sequence : type : string label : 'Permission' Il devient de ce fait plus int\u00e9ressant de coder les r\u00f4les dans des fichiers yaml, voire m\u00eame de les cr\u00e9er sur une instance de d\u00e9veloppement, supprimer leur uuid, et de les r\u00e9cup\u00e9rer pour les int\u00e9grer dans les autres instances, o\u00f9 le nom de fichier d\u00e9termine le nom de l'objet de configuration.","title":"Sch\u00e9ma yaml"},{"location":"TECHNIQUE/roles.html#export-dun-role","text":"drush config:get user.role.r1 >user.role.r1.yml cat user.role.r1.yml uuid : b0d165ca-3a16-4996-9aa8-e57366a22a2c langcode : fr status : true dependencies : module : - block - civicrm id : r1 label : R1 weight : 4 is_admin : null permissions : - 'administer blocks' - 'authenticate with password' Pour supprimer au passage l'UUID : cat user.role.r1.yml | grep -v uuid >TEST/user.role.r1.yml","title":"Export d'un r\u00f4le"},{"location":"TECHNIQUE/roles.html#import-des-roles","text":"Pour importer le fichier yaml, il faut faire attention de bien indiquer un import partiel (sans quoi les objets de configuration non existants sont supprim\u00e9s). La source est le r\u00e9pertoire dans lequel sont stock\u00e9s les fichiers \u00e0 importer. drush --no-interaction config:import --partial --source = /app/TEST -vvv","title":"Import des r\u00f4les"},{"location":"TECHNIQUE/roles.html#verification-de-letat","text":"Pour v\u00e9rifier la source de configuration pour les diff\u00e9rents objets : drush config:status","title":"V\u00e9rification de l'\u00e9tat"},{"location":"TECHNIQUE/roles.html#implementation-dans-le-si","text":"Le moyen le plus simple d'int\u00e9grer les r\u00f4les est de cr\u00e9er un package composer suppl\u00e9mentaire \u00e0 l'aide d'un d\u00e9p\u00f4t git, et d'appeler les commandes drush lors de l'installation initiale et lors des mises \u00e0 jour. De ce fait, les packages de r\u00f4les seront versionn\u00e9s et la correspondance de versions sera ma\u00eetris\u00e9e via le composer.json principal ; de plus, ces fichiers seront pr\u00e9sents directement dans les images Docker, qui elles-m\u00eames peuvent \u00eatre tagg\u00e9es, et donc versionn\u00e9es.","title":"Impl\u00e9mentation dans le SI"},{"location":"TECHNIQUE/roles.html#strategie-a-long-terme","text":"Il est probable que l'ensemble des r\u00f4les propos\u00e9s avec Civiparoisse ne correspondra pas aux besoins de toutes les paroisses, et que des jeux de r\u00f4les vont venir remplacer ou compl\u00e9ter le jeu de r\u00f4les initial. Toutefois, il faut assurer une certaine \"compatibilit\u00e9 ascendante\", de sorte \u00e0 ne pas casser les droits et surtout les droits non donn\u00e9s aux utilisateurs. Ainsi, si un r\u00f4le est cr\u00e9e, il ne devra pas \u00eatre modifi\u00e9, car il faut consid\u00e9rer qu'il a pu \u00eatre utilis\u00e9 par une paroisse, et qu'il ne faut pas interf\u00e9rer dans les droits donn\u00e9s par une paroisse. A ce sujet, comme les paroisses peuvent \u00e9galement cr\u00e9er des r\u00f4les, il faudra d\u00e9finir un pr\u00e9fixe utilis\u00e9 pour les r\u00f4les pr\u00e9par\u00e9s pour Civiparoisse. On pourrait donc arriver \u00e0 un nom de r\u00f4le comme user.role.civiparoisse.<nom_jeu>_<nom_role> . Un cas particulier doit cependant \u00eatre pr\u00e9vu : le cas o\u00f9 les permissions \u00e9voluent dans CiviCRM ou Drupal. Dans ce cas pr\u00e9cis, on peut envisager de supprimer les droits des anciens r\u00f4les cr\u00e9es par Civiparoisse et pr\u00e9parer un nouveau jeu de r\u00f4les : l'utilisateur UID 1 pourra de toute mani\u00e8re intervenir pour mettre en place les nouveaux droits : c'est une approche s\u00fbre, dans la mesure o\u00f9 on ne donnera \u00e0 aucun moment par m\u00e9garde des droits trop importants \u00e0 des utilisateurs. En revanche, si l'utilisateur UID 1 n'est pas un utilisateur de la paroisse (\u00e9quipe technique interne Civiparoisse), il faudra convenir d'une r\u00e9union de maintenance avec les responsables de la paroisse pour effectuer les actions qui conviennent.","title":"Strat\u00e9gie \u00e0 long terme"},{"location":"TECHNIQUE/serveur_media.html","text":"Serveur de m\u00e9dias Besoin Le serveur de m\u00e9dias est une fonctionnalit\u00e9 n\u00e9cessaire, compl\u00e9mentaire \u00e0 l'envoi de mails par CiviCRM. En effet, pour que les mails ne soient pas de taille trop importante, on d\u00e9pose souvent les fichiers souvent utilis\u00e9s ou plus lourds (images par exemple) dans un serveur de m\u00e9dias, o\u00f9 le m\u00e9dia sera r\u00e9cup\u00e9r\u00e9 \u00e0 la vol\u00e9e lors des consultations des mails. Bien entendu, les fichiers confidentiels ne doivent pas \u00eatre envoy\u00e9s par mail sans pr\u00e9caution (chiffrement par exemple), et on \u00e9vitera \u00e9galement de les laisser \u00e0 disposition de tous sur un serveur non authentifi\u00e9. Un deuxi\u00e8me besoin compl\u00e9mentaire est la possibilit\u00e9 de d\u00e9poser une page web qui repr\u00e9sente un mail envoy\u00e9, et qui serait difficile \u00e0 lire du c\u00f4t\u00e9 de l'exp\u00e9diteur. Ce besoin doit toutefois \u00eatre \u00e9tudi\u00e9 au cas par cas, car ce genre de mail est en contradiction avec les mails personnalis\u00e9s (mails sous forme de templates avec des champs de donn\u00e9es par exemple). Il semble par ailleurs que r\u00e9aliser une page web qui afficherait des donn\u00e9es personnalis\u00e9es par le biais d'un \u00e9l\u00e9ment comme un token d'authentification dans l'URL serait hasardeux, et poserait des questions quant \u00e0 la protection des donn\u00e9es (sauf \u00e0 disposer par exemple d'une clef publique de chiffrement pour envoyer du contenu \u00e0 un utilisateur). Il est \u00e0 noter que m\u00eame dans le cadre des mails personnalis\u00e9s, les mails ne sont la plupart du temps pas chiffr\u00e9s par des clefs asym\u00e9triques, comme par exemple via des technologies telles que S/MIME. De ce fait, bien que les transferts entre serveurs de mails peuvent \u00eatre chiffr\u00e9s, le contenu des mails pourrait toutefois \u00eatre d\u00e9couvert lors du transit sur un serveur (et les mails sont g\u00e9n\u00e9ralement analys\u00e9s avec des outils comme des antispams ou des antivirus). Il est donc essentiel de faire particuli\u00e8rement attention \u00e0 ce que les donn\u00e9es qui transitent dans les mails ne soient pas des donn\u00e9es sensibles. Pour en revenir au besoin, il est donc n\u00e9cessaire de s'authentifier aupr\u00e8s du syst\u00e8me pour pouvoir d\u00e9poser des fichiers, mais il n'est pas n\u00e9cessaire ensuite de s'authentifier pour les r\u00e9cup\u00e9rer. Eventuel besoin compl\u00e9mentaire : serveur d'\u00e9changes de fichiers ; analyse de possibles solutions Certaines paroisses peuvent avoir besoin d'une solution simple de stockage de fichiers pour certains projets, avec des acc\u00e8s r\u00e9serv\u00e9s \u00e0 certaines personnes. Ce besoin n\u00e9cessite donc des outils suppl\u00e9mentaires : une authentification de l'ensemble des utilisateurs un m\u00e9canisme de contr\u00f4les des droits sur les fichiers Pour autant, il reste n\u00e9cessaire que certains documents soient acc\u00e9d\u00e9s sans authentification et via le protocole HTTP Plusieurs types d'outils semblent fournir des solutions : le stockage sur des services clouds : Google Drive est un exemple qui permet le stockage de documents, et la gestion des droits sur les documents ; n\u00e9anmoins, certains utilisateurs peuvent se montrer r\u00e9ticents \u00e0 utilisateur des services directement issus des GAFAS. On pourrait \u00e9galement penser \u00e0 Azure Blob Storage. les logiciels de type Enterprise Content Management / Document Management System : elles fournissent des solutions qui d\u00e9passent fonctionnellement le besoin, et semblent pour la plupart \u00eatre assez lourdes et impliqueraient des ressources assez importantes aussi bien humaines que machines pour \u00eatre exploit\u00e9es correctement. Par ailleurs, certains logiciels disposent d'une version communaut\u00e9 et d'une version payante, et que des \u00e9carts importants dans les num\u00e9ros de version existent. Enfin, on trouve quelques projets de logiciel libre DMS plus l\u00e9gers, mais dont le code source n'est parfois plus maintenu ou ne semble plus \u00eatre en phase avec les pratiques actuelles les solutions construites sur des briques importantes syst\u00e8me/infrastructure : dans ce genre de solution, les paroisses devraient disposer de comp\u00e9tences techniques (ex : annuaire LDAP, gestion des utilisateurs et groupes Unix, SSH...) qui semblent difficilement \u00e0 leur port\u00e9e Les recherches n'ont pas permis de d\u00e9terminer une solution satisfaisante \u00e0 int\u00e9grer dans le projet pour le besoin. Etant donn\u00e9 que ce besoin n'est pas imm\u00e9diatement en lien avec CiviCRM, et que les solutions Drive semblent \u00eatre les plus simples \u00e0 mettre en oeuvre, ce besoin compl\u00e9mentaire ne sera pas adress\u00e9 par le projet. Solution propos\u00e9e (hors scope projet) La solution que l'on retient pour le moment pour le serveur de m\u00e9dias est une instance de Drupal avec une base de donn\u00e9es sqlite, dans le but de faire un serveur aussi l\u00e9ger que possible. Le projet comporte des versions modifi\u00e9es des images utilis\u00e9es pour CiviCRM : composer_media_base : la version de composer livr\u00e9e avec Ubuntu ne supporte pas le auth-plugin : true ; du coup il fallait r\u00e9cup\u00e9rer une version qui le supporte media_files : la r\u00e9cup\u00e9ration des fichiers n\u00e9cessaires media_tools : l'image avec les fichiers et les outils media_init : l'image pour l'installation des volumes media_httpd : l'image pour le serveur web media_cron : l'image pour le cron L'image selfkeys a \u00e9t\u00e9 modifi\u00e9e pour int\u00e9grer la signature d'un certificat pour ce serveur. Etant donn\u00e9 que ces images sont d\u00e9riv\u00e9es des images principales, on se reportera \u00e0 la documentation de ces derni\u00e8res pour comprendre le fonctionnement des images d\u00e9riv\u00e9es.","title":"Serveur de m\u00e9dias"},{"location":"TECHNIQUE/serveur_media.html#serveur-de-medias","text":"","title":"Serveur de m\u00e9dias"},{"location":"TECHNIQUE/serveur_media.html#besoin","text":"Le serveur de m\u00e9dias est une fonctionnalit\u00e9 n\u00e9cessaire, compl\u00e9mentaire \u00e0 l'envoi de mails par CiviCRM. En effet, pour que les mails ne soient pas de taille trop importante, on d\u00e9pose souvent les fichiers souvent utilis\u00e9s ou plus lourds (images par exemple) dans un serveur de m\u00e9dias, o\u00f9 le m\u00e9dia sera r\u00e9cup\u00e9r\u00e9 \u00e0 la vol\u00e9e lors des consultations des mails. Bien entendu, les fichiers confidentiels ne doivent pas \u00eatre envoy\u00e9s par mail sans pr\u00e9caution (chiffrement par exemple), et on \u00e9vitera \u00e9galement de les laisser \u00e0 disposition de tous sur un serveur non authentifi\u00e9. Un deuxi\u00e8me besoin compl\u00e9mentaire est la possibilit\u00e9 de d\u00e9poser une page web qui repr\u00e9sente un mail envoy\u00e9, et qui serait difficile \u00e0 lire du c\u00f4t\u00e9 de l'exp\u00e9diteur. Ce besoin doit toutefois \u00eatre \u00e9tudi\u00e9 au cas par cas, car ce genre de mail est en contradiction avec les mails personnalis\u00e9s (mails sous forme de templates avec des champs de donn\u00e9es par exemple). Il semble par ailleurs que r\u00e9aliser une page web qui afficherait des donn\u00e9es personnalis\u00e9es par le biais d'un \u00e9l\u00e9ment comme un token d'authentification dans l'URL serait hasardeux, et poserait des questions quant \u00e0 la protection des donn\u00e9es (sauf \u00e0 disposer par exemple d'une clef publique de chiffrement pour envoyer du contenu \u00e0 un utilisateur). Il est \u00e0 noter que m\u00eame dans le cadre des mails personnalis\u00e9s, les mails ne sont la plupart du temps pas chiffr\u00e9s par des clefs asym\u00e9triques, comme par exemple via des technologies telles que S/MIME. De ce fait, bien que les transferts entre serveurs de mails peuvent \u00eatre chiffr\u00e9s, le contenu des mails pourrait toutefois \u00eatre d\u00e9couvert lors du transit sur un serveur (et les mails sont g\u00e9n\u00e9ralement analys\u00e9s avec des outils comme des antispams ou des antivirus). Il est donc essentiel de faire particuli\u00e8rement attention \u00e0 ce que les donn\u00e9es qui transitent dans les mails ne soient pas des donn\u00e9es sensibles. Pour en revenir au besoin, il est donc n\u00e9cessaire de s'authentifier aupr\u00e8s du syst\u00e8me pour pouvoir d\u00e9poser des fichiers, mais il n'est pas n\u00e9cessaire ensuite de s'authentifier pour les r\u00e9cup\u00e9rer.","title":"Besoin"},{"location":"TECHNIQUE/serveur_media.html#eventuel-besoin-complementaire-serveur-dechanges-de-fichiers-analyse-de-possibles-solutions","text":"Certaines paroisses peuvent avoir besoin d'une solution simple de stockage de fichiers pour certains projets, avec des acc\u00e8s r\u00e9serv\u00e9s \u00e0 certaines personnes. Ce besoin n\u00e9cessite donc des outils suppl\u00e9mentaires : une authentification de l'ensemble des utilisateurs un m\u00e9canisme de contr\u00f4les des droits sur les fichiers Pour autant, il reste n\u00e9cessaire que certains documents soient acc\u00e9d\u00e9s sans authentification et via le protocole HTTP Plusieurs types d'outils semblent fournir des solutions : le stockage sur des services clouds : Google Drive est un exemple qui permet le stockage de documents, et la gestion des droits sur les documents ; n\u00e9anmoins, certains utilisateurs peuvent se montrer r\u00e9ticents \u00e0 utilisateur des services directement issus des GAFAS. On pourrait \u00e9galement penser \u00e0 Azure Blob Storage. les logiciels de type Enterprise Content Management / Document Management System : elles fournissent des solutions qui d\u00e9passent fonctionnellement le besoin, et semblent pour la plupart \u00eatre assez lourdes et impliqueraient des ressources assez importantes aussi bien humaines que machines pour \u00eatre exploit\u00e9es correctement. Par ailleurs, certains logiciels disposent d'une version communaut\u00e9 et d'une version payante, et que des \u00e9carts importants dans les num\u00e9ros de version existent. Enfin, on trouve quelques projets de logiciel libre DMS plus l\u00e9gers, mais dont le code source n'est parfois plus maintenu ou ne semble plus \u00eatre en phase avec les pratiques actuelles les solutions construites sur des briques importantes syst\u00e8me/infrastructure : dans ce genre de solution, les paroisses devraient disposer de comp\u00e9tences techniques (ex : annuaire LDAP, gestion des utilisateurs et groupes Unix, SSH...) qui semblent difficilement \u00e0 leur port\u00e9e Les recherches n'ont pas permis de d\u00e9terminer une solution satisfaisante \u00e0 int\u00e9grer dans le projet pour le besoin. Etant donn\u00e9 que ce besoin n'est pas imm\u00e9diatement en lien avec CiviCRM, et que les solutions Drive semblent \u00eatre les plus simples \u00e0 mettre en oeuvre, ce besoin compl\u00e9mentaire ne sera pas adress\u00e9 par le projet.","title":"Eventuel besoin compl\u00e9mentaire : serveur d'\u00e9changes de fichiers ; analyse de possibles solutions"},{"location":"TECHNIQUE/serveur_media.html#solution-proposee-hors-scope-projet","text":"La solution que l'on retient pour le moment pour le serveur de m\u00e9dias est une instance de Drupal avec une base de donn\u00e9es sqlite, dans le but de faire un serveur aussi l\u00e9ger que possible. Le projet comporte des versions modifi\u00e9es des images utilis\u00e9es pour CiviCRM : composer_media_base : la version de composer livr\u00e9e avec Ubuntu ne supporte pas le auth-plugin : true ; du coup il fallait r\u00e9cup\u00e9rer une version qui le supporte media_files : la r\u00e9cup\u00e9ration des fichiers n\u00e9cessaires media_tools : l'image avec les fichiers et les outils media_init : l'image pour l'installation des volumes media_httpd : l'image pour le serveur web media_cron : l'image pour le cron L'image selfkeys a \u00e9t\u00e9 modifi\u00e9e pour int\u00e9grer la signature d'un certificat pour ce serveur. Etant donn\u00e9 que ces images sont d\u00e9riv\u00e9es des images principales, on se reportera \u00e0 la documentation de ces derni\u00e8res pour comprendre le fonctionnement des images d\u00e9riv\u00e9es.","title":"Solution propos\u00e9e (hors scope projet)"},{"location":"TECHNIQUE/INTEGRATION/index.html","text":"Index Cette section liste des documents concernant l'int\u00e9gration de Civiparoisse. Etude technique de l'authentification Docker","title":"Index"},{"location":"TECHNIQUE/INTEGRATION/index.html#index","text":"Cette section liste des documents concernant l'int\u00e9gration de Civiparoisse. Etude technique de l'authentification Docker","title":"Index"},{"location":"TECHNIQUE/INTEGRATION/db_ssl.html","text":"Connexion chiffr\u00e9e \u00e0 la BD MySQL La connexion chiffr\u00e9e \u00e0 la BD est un \u00e9l\u00e9ment qui ne doit pas \u00eatre n\u00e9glig\u00e9 : l'acc\u00e8s \u00e0 la BD doit \u00eatre limit\u00e9 et ne doit pas \u00eatre permis \u00e0 d'autres intervenants que le cron et serveur web interne, et le trafic doit \u00eatre chiffr\u00e9 pour assurer la confidentialit\u00e9 des informations. De m\u00eame, les donn\u00e9es doivent \u00eatre stock\u00e9es dans la BD de mani\u00e8re chiffr\u00e9e. Ce chiffrement n'est pas forc\u00e9ment effectu\u00e9 par le SGBD, car il peut \u00e9ventuellement \u00eatre effectu\u00e9 par le syst\u00e8me de fichiers. On retiendra, par simplicit\u00e9, ce sc\u00e9nario. En ce qui concerne la connexion \u00e0 la BD, un point important est qu'il convient de distinguer deux types d'acc\u00e8s : l'acc\u00e8s r\u00e9seau, par une stack TCP/IP : cet acc\u00e8s doit \u00eatre s\u00e9curis\u00e9 par SSL l'acc\u00e8s par socket : cet acc\u00e8s est g\u00e9r\u00e9 par les droits d'acc\u00e8s du fichier de socket, et la communication proprement dite se passe au niveau du kernel : la surcouche SSL ne s'applique pas. Pour mettre en oeuvre la connexion chiffr\u00e9e, plusieurs approches sont possibles : l'acc\u00e8s chiffr\u00e9 jusqu'\u00e0 la BD en passant par les m\u00e9canismes de MySQL : il y a effectivement un support SSL int\u00e9gr\u00e9 dans MySQL, mais il faut bien remarquer que ce support n'est pas semblable \u00e0 une connexion SSL de HTTPS : la connexion est n\u00e9goci\u00e9e au niveau protocolaire : voir <>https://dev.mysql.com/doc/dev/mysql-server/latest/page_protocol_connection_phase.html>. Si CiviCRM semble pr\u00e9voir d\u00e8s l'installation la configuration SSL \u00e0 la BD, cela ne semble pas \u00eatre le cas de Drush/Drupal, et rend ce m\u00e9canisme difficile \u00e0 utiliser et n\u00e9cessite plusieurs configurations \u00e0 maintenir (CiviCRM et Drupal). l'acc\u00e8s par un proxy SQL : le proxy SQL proprement dit intervient au niveau protocolaire dans les communications. On peut citer deux proxys : MySQLRouter : ce proxy est disponible sous Ubuntu, et fait partie du code du server MySQL. Il est simple \u00e0 configurer, et permet normalement de faire la distinction entre la connection client-proxy et la connection proxy-serveur, de sorte que le TLS puisse \u00eatre n\u00e9goci\u00e9 de mani\u00e8re distincte. Toutefois, un bug introduit dans la version 8.0.24 fait que m\u00eame si l'on ne souhaite au niveau du client qu'ouvrir uniquement une socket Unix (et pas un acc\u00e8s r\u00e9seau), un acc\u00e8s r\u00e9seau est quand m\u00eame ouvert sur un port al\u00e9atoire. De ce fait, ce logiciel n'a pas \u00e9t\u00e9 retenu. ProxySQL https://proxysql.com/ : ce proxy est un logiciel tiers Opensource. Son fonctionnement n\u00e9cessite de stocker les identifiants de connexion dans sa configuration. Ceci n'est pas souhait\u00e9, et le logiciel a donc \u00e9t\u00e9 \u00e9cart\u00e9 pour cette raison. l'acc\u00e8s par un tunnel SSL : le tunnel SSL est en fait une encapsulation des donn\u00e9es protocolaires dans un flux TCP SSL ; le plus simple pour obtenir ce fonctionnement est d'utiliser socat, tout aussi bien en tant que client qu'en serveur, avec les configurations ad\u00e9quates: la partie serveur va \u00e9couter en SSL sur une socket inet et va brancher le flux apr\u00e8s authentification SSL sur la socket de MySQL, tandis que la partie client va fournir une socket unix et faire transiter gr\u00e2ce \u00e0 une authentification par certificat SSL d\u00fbment configur\u00e9 le trafic vers le serveur. L'int\u00e9r\u00eat de ce syst\u00e8me est qu'il est simple \u00e0 mettre en oeuvre, et qu'il est transparent au niveau applicatif. L'inconv\u00e9nient est qu'il n\u00e9cessite d'utiliser le design pattern sidecar pour fournir les connexions, ce qui augmente quelque peu les ressources utilis\u00e9es. On remarquera toutefois que cette approche sidecar est dans les normes, puisqu'elle est par exemple propos\u00e9e pour certains acc\u00e8s \u00e0 Google Cloud SQL : voir https://cloud.google.com/sql/docs/mysql/sql-proxy En d\u00e9finitive, l'approche de tunnel SSL via socat est celle retenue. Sa configuration est relativement facile, et est effectu\u00e9e dans les images docker DB_TLS_CLIENT et DB_TLS_SERVER . Annexe : probl\u00e8me MySQLRouter Le probl\u00e8me se situe peut-\u00eatre sur le fichier mysql_routing.cc : https://github.com/mysql/mysql-server/blob/fbdaa4def30d269bc4de5b85de61de34b11c0afc/router/src/routing/src/mysql_routing.cc#L185 if (context_.get_bind_address().port() > 0 || context_.get_bind_named_socket().is_set()) { auto res = start_acceptor(env); if (!res) { clear_running(env); throw std::runtime_error( string_format(\"Failed setting up TCP service using %s: %s\", context_.get_bind_address().str().c_str(), res.error().message().c_str())); } Il est possible que le probl\u00e8me soit apparu dans la 8.0.24 dont un des sympt\u00f4mes (mais qui n'explique pas le probl\u00e8me) est le code d'au-dessus. Un test de compilation (bricol\u00e9e pour outrepasser un probl\u00e8me de FIPS) et d'ex\u00e9cution n'a pas montr\u00e9 le probl\u00e8me avec la 8.0.23 en v\u00e9rifiant /proc/ pid /net/tcp et tcp6.","title":"DB_SSL"},{"location":"TECHNIQUE/INTEGRATION/db_ssl.html#connexion-chiffree-a-la-bd-mysql","text":"La connexion chiffr\u00e9e \u00e0 la BD est un \u00e9l\u00e9ment qui ne doit pas \u00eatre n\u00e9glig\u00e9 : l'acc\u00e8s \u00e0 la BD doit \u00eatre limit\u00e9 et ne doit pas \u00eatre permis \u00e0 d'autres intervenants que le cron et serveur web interne, et le trafic doit \u00eatre chiffr\u00e9 pour assurer la confidentialit\u00e9 des informations. De m\u00eame, les donn\u00e9es doivent \u00eatre stock\u00e9es dans la BD de mani\u00e8re chiffr\u00e9e. Ce chiffrement n'est pas forc\u00e9ment effectu\u00e9 par le SGBD, car il peut \u00e9ventuellement \u00eatre effectu\u00e9 par le syst\u00e8me de fichiers. On retiendra, par simplicit\u00e9, ce sc\u00e9nario. En ce qui concerne la connexion \u00e0 la BD, un point important est qu'il convient de distinguer deux types d'acc\u00e8s : l'acc\u00e8s r\u00e9seau, par une stack TCP/IP : cet acc\u00e8s doit \u00eatre s\u00e9curis\u00e9 par SSL l'acc\u00e8s par socket : cet acc\u00e8s est g\u00e9r\u00e9 par les droits d'acc\u00e8s du fichier de socket, et la communication proprement dite se passe au niveau du kernel : la surcouche SSL ne s'applique pas. Pour mettre en oeuvre la connexion chiffr\u00e9e, plusieurs approches sont possibles : l'acc\u00e8s chiffr\u00e9 jusqu'\u00e0 la BD en passant par les m\u00e9canismes de MySQL : il y a effectivement un support SSL int\u00e9gr\u00e9 dans MySQL, mais il faut bien remarquer que ce support n'est pas semblable \u00e0 une connexion SSL de HTTPS : la connexion est n\u00e9goci\u00e9e au niveau protocolaire : voir <>https://dev.mysql.com/doc/dev/mysql-server/latest/page_protocol_connection_phase.html>. Si CiviCRM semble pr\u00e9voir d\u00e8s l'installation la configuration SSL \u00e0 la BD, cela ne semble pas \u00eatre le cas de Drush/Drupal, et rend ce m\u00e9canisme difficile \u00e0 utiliser et n\u00e9cessite plusieurs configurations \u00e0 maintenir (CiviCRM et Drupal). l'acc\u00e8s par un proxy SQL : le proxy SQL proprement dit intervient au niveau protocolaire dans les communications. On peut citer deux proxys : MySQLRouter : ce proxy est disponible sous Ubuntu, et fait partie du code du server MySQL. Il est simple \u00e0 configurer, et permet normalement de faire la distinction entre la connection client-proxy et la connection proxy-serveur, de sorte que le TLS puisse \u00eatre n\u00e9goci\u00e9 de mani\u00e8re distincte. Toutefois, un bug introduit dans la version 8.0.24 fait que m\u00eame si l'on ne souhaite au niveau du client qu'ouvrir uniquement une socket Unix (et pas un acc\u00e8s r\u00e9seau), un acc\u00e8s r\u00e9seau est quand m\u00eame ouvert sur un port al\u00e9atoire. De ce fait, ce logiciel n'a pas \u00e9t\u00e9 retenu. ProxySQL https://proxysql.com/ : ce proxy est un logiciel tiers Opensource. Son fonctionnement n\u00e9cessite de stocker les identifiants de connexion dans sa configuration. Ceci n'est pas souhait\u00e9, et le logiciel a donc \u00e9t\u00e9 \u00e9cart\u00e9 pour cette raison. l'acc\u00e8s par un tunnel SSL : le tunnel SSL est en fait une encapsulation des donn\u00e9es protocolaires dans un flux TCP SSL ; le plus simple pour obtenir ce fonctionnement est d'utiliser socat, tout aussi bien en tant que client qu'en serveur, avec les configurations ad\u00e9quates: la partie serveur va \u00e9couter en SSL sur une socket inet et va brancher le flux apr\u00e8s authentification SSL sur la socket de MySQL, tandis que la partie client va fournir une socket unix et faire transiter gr\u00e2ce \u00e0 une authentification par certificat SSL d\u00fbment configur\u00e9 le trafic vers le serveur. L'int\u00e9r\u00eat de ce syst\u00e8me est qu'il est simple \u00e0 mettre en oeuvre, et qu'il est transparent au niveau applicatif. L'inconv\u00e9nient est qu'il n\u00e9cessite d'utiliser le design pattern sidecar pour fournir les connexions, ce qui augmente quelque peu les ressources utilis\u00e9es. On remarquera toutefois que cette approche sidecar est dans les normes, puisqu'elle est par exemple propos\u00e9e pour certains acc\u00e8s \u00e0 Google Cloud SQL : voir https://cloud.google.com/sql/docs/mysql/sql-proxy En d\u00e9finitive, l'approche de tunnel SSL via socat est celle retenue. Sa configuration est relativement facile, et est effectu\u00e9e dans les images docker DB_TLS_CLIENT et DB_TLS_SERVER .","title":"Connexion chiffr\u00e9e \u00e0 la BD MySQL"},{"location":"TECHNIQUE/INTEGRATION/db_ssl.html#annexe-probleme-mysqlrouter","text":"Le probl\u00e8me se situe peut-\u00eatre sur le fichier mysql_routing.cc : https://github.com/mysql/mysql-server/blob/fbdaa4def30d269bc4de5b85de61de34b11c0afc/router/src/routing/src/mysql_routing.cc#L185 if (context_.get_bind_address().port() > 0 || context_.get_bind_named_socket().is_set()) { auto res = start_acceptor(env); if (!res) { clear_running(env); throw std::runtime_error( string_format(\"Failed setting up TCP service using %s: %s\", context_.get_bind_address().str().c_str(), res.error().message().c_str())); } Il est possible que le probl\u00e8me soit apparu dans la 8.0.24 dont un des sympt\u00f4mes (mais qui n'explique pas le probl\u00e8me) est le code d'au-dessus. Un test de compilation (bricol\u00e9e pour outrepasser un probl\u00e8me de FIPS) et d'ex\u00e9cution n'a pas montr\u00e9 le probl\u00e8me avec la 8.0.23 en v\u00e9rifiant /proc/ pid /net/tcp et tcp6.","title":"Annexe : probl\u00e8me MySQLRouter"},{"location":"TECHNIQUE/INTEGRATION/docker.html","text":"Docker Docker permet de mettre en oeuvre une architecture microservices, avec des images sp\u00e9cialis\u00e9es, adapt\u00e9es aux environnements gr\u00e2ce par exemple \u00e0 des variables d'environnement que l'on peut passer en argument de docker-run (par exemple). Le but des images est d'\u00eatre des images les plus stables possibles - id\u00e9alement des images que l'on pourrait utiliser en lecture seule. Les parties variables seraient id\u00e9alement toutes dans des volumes. Chaque Dockerfile du projet dispose d'une directive LABEL directement apr\u00e8s la directive FROM initiale, de sorte \u00e0 pouvoir invalider simplement le cache en modifiant les valeurs des labels. Un script de build des images ( build.sh ) est fourni dans le d\u00e9p\u00f4t. Liste des images Un certain nombre d'images Docker est n\u00e9cessaire pour ex\u00e9cuter un environnement Civiparoisse complet. Ces images, dans l'ordre de build, sont : composer_base composer_files tools init cron selfkeys httpd authenticator proxy D\u00e9pendances des images entre elles En se basant sur la directive FROM des Dockerfiles, on obtient les d\u00e9pendances suivantes : ubuntu authenticator selfkeys composer_base composer_files tools cron init ubuntu/apache2 httpd proxy ubuntu/mysql Toutefois, il y a \u00e9galement des injections de donn\u00e9es d'une image \u00e0 l'autre via COPY --from : * selfkeys * authenticator * httpd * proxy * composer_files * httpd * tools * indirectement (cf from ): cron * indirectement (cf from ): init Le but de ces d\u00e9pendances est de \"stabiliser\" le contenu des images build\u00e9es, pour que le contenu qui doit \u00eatre pr\u00e9sent dans plusieurs images soit identique. Principe de fonctionnement On suppose l'existence d'un forwarder TCP pricipal qui va faire l'aiguillage vers le bon reverse-proxy de paroisse en se basant sur le Server Name Indication, qui appara\u00eet en clair dans la connexion TLS. Il y a donc une connexion TLS entre le client et le serveur TLS, mais deux liaisons TCP (client/forwarder et forwarder/reverse proxy). Le reverse proxy va authentifier les utilisateurs, au travers des identifiants Drupal convoy\u00e9s via du HTTP Basic au-dessus d'une liason TLS, et probablement un autre moyen (certificat SSL par exemple). En ce qui concerne les identifiants, ils sont test\u00e9 au travers d'un authenticateur qui est branch\u00e9 sur le reverse proxy au travers d'une socket Unix. Chaque requ\u00eate adress\u00e9e au reverse proxy doit \u00eatre authentifi\u00e9e, et d\u00e9clenchera un appel \u00e0 l'authenticateur. L'authenticateur va effectuer une requ\u00eate vers le serveur web interne pour v\u00e9rifier que l'utilisateur est bien reconnu. Si tel est le cas, le reverse proxy va transf\u00e9rer la requ\u00eate vers le serveur web interne pour \u00eatre trait\u00e9e. Gestion des droits sur les fichiers La gestion des droits sur les fichiers est un sujet complexe. On suppose que les syst\u00e8mes de fichiers mis en oeuvre dans le syst\u00e8me proposent une gestion des droits traditionnels \"\u00e0 la Unix\", avec des droits read-write-exec que l'on peut attribuer \u00e0 un propri\u00e9taire, un groupe, et le reste du monde ; et on suppose qu'on peut identifier le propri\u00e9taire et le groupe de r\u00e9f\u00e9rence des fichiers. Etant donn\u00e9 qu'en principe seul le propri\u00e9taire et root peuvent changer les permissions sur un fichier, et qu'il est pr\u00e9f\u00e9rable que le compte root ne soit pas trop utilis\u00e9 (par exemple pour \u00e9viter par la suite une ex\u00e9cution en root via du bit SUID), il a \u00e9t\u00e9 privil\u00e9gi\u00e9 de cr\u00e9er un compte sp\u00e9cifique, verrouill\u00e9, dont le but est d'\u00eatre propri\u00e9taire des fichiers : le compte paroisse (UID 1000). Un groupe paroisse (GID 1000) est \u00e9galement provisionn\u00e9. Le principe g\u00e9n\u00e9ral est que les fichiers (pour l'instant, non syst\u00e8me) qui sont pr\u00e9sents dans les images sont des fichiers destin\u00e9s \u00e0 \u00eatre en lecture seule, tandis que les fichiers des volumes seront en lecture \u00e9criture. Il s'agit d'appliquer le principe des droits minimaux pour effectuer les op\u00e9rations. L'id\u00e9e est de donner aux fichiers le propri\u00e9taire paroisse, et le groupe www-data. De l\u00e0, on peut positionner les droits sur les fichiers. De m\u00eame, il y a un compte authenticator (UID 1001) et un groupe authenticator (GID 1001) qui ont \u00e9t\u00e9 cr\u00e9es sur l'image d'authenticateur. Compte \u00e9galement verrouill\u00e9. En ce qui concerne les clefs, il faut se rappeler qu'Apache lit les clefs en tant que l'utilisateur lanc\u00e9 (root) avant de descendre ses droits. Du coup, les clefs n'ont pas besoin d'\u00eatre lues par www-data. Volumes principaux Ces volumes sont : civicomp_dbvol: le volume de base de donn\u00e9es civicomp_filevol: le volume des fichiers, avec les fichiers sp\u00e9cifiques \u00e0 l'instance courante civicomp_privatevol : le volume des fichiers priv\u00e9s Les volumes sont mont\u00e9s avec l'option nocopy: true car ce fonctionnement correspond au fonctionnement en environnement Kubernetes. En environnement Kubernetes, il y aura des montages suppl\u00e9mentaires (les secrets et les variables d'environnement, par exemple). Docker-compose Deux docker-compose sont disponibles. L'un d'eux, docker-init.yml est pr\u00e9vu pour initialiser les volumes, tandis que l'autre ( docker-compose.yml , nom par d\u00e9faut) est utilis\u00e9 pour l'ex\u00e9cution classique. L'int\u00e9r\u00eat du docuker-compose r\u00e9side dans le fait que docker-compose va s'occuper de faire les liaisons n\u00e9cessaires entre les containers et les volumes, sans avoir besoin de saisir des lignes de commande fastidieuses. C'est donc un syst\u00e8me analogue \u00e0 ce qu'on retrouve dans la d\u00e9claration d'objets dans Kubernetes. Initialisation des volumes On suppose qu'on se trouve dans le r\u00e9pertoire contenant les fichiers compose. docker-compose -f docker-init.yml up docker-compose -f docker-init.yml rm Utilisation de l'environnement Docker au quotidien Il faut penser \u00e0 mettre \u00e0 jour son /etc/hosts pour disposer de la r\u00e9solution de noms n\u00e9cessaire. Ensuite, on peut faire des op\u00e9rations quotidiennes avec des commandes comme, par exemple (en \u00e9tant dans le r\u00e9pertoire contenant les fichiers compose) : docker-compose -d up # [on fait le travail] docker-compose stop","title":"Description g\u00e9n\u00e9rale"},{"location":"TECHNIQUE/INTEGRATION/docker.html#docker","text":"Docker permet de mettre en oeuvre une architecture microservices, avec des images sp\u00e9cialis\u00e9es, adapt\u00e9es aux environnements gr\u00e2ce par exemple \u00e0 des variables d'environnement que l'on peut passer en argument de docker-run (par exemple). Le but des images est d'\u00eatre des images les plus stables possibles - id\u00e9alement des images que l'on pourrait utiliser en lecture seule. Les parties variables seraient id\u00e9alement toutes dans des volumes. Chaque Dockerfile du projet dispose d'une directive LABEL directement apr\u00e8s la directive FROM initiale, de sorte \u00e0 pouvoir invalider simplement le cache en modifiant les valeurs des labels. Un script de build des images ( build.sh ) est fourni dans le d\u00e9p\u00f4t.","title":"Docker"},{"location":"TECHNIQUE/INTEGRATION/docker.html#liste-des-images","text":"Un certain nombre d'images Docker est n\u00e9cessaire pour ex\u00e9cuter un environnement Civiparoisse complet. Ces images, dans l'ordre de build, sont : composer_base composer_files tools init cron selfkeys httpd authenticator proxy","title":"Liste des images"},{"location":"TECHNIQUE/INTEGRATION/docker.html#dependances-des-images-entre-elles","text":"En se basant sur la directive FROM des Dockerfiles, on obtient les d\u00e9pendances suivantes : ubuntu authenticator selfkeys composer_base composer_files tools cron init ubuntu/apache2 httpd proxy ubuntu/mysql Toutefois, il y a \u00e9galement des injections de donn\u00e9es d'une image \u00e0 l'autre via COPY --from : * selfkeys * authenticator * httpd * proxy * composer_files * httpd * tools * indirectement (cf from ): cron * indirectement (cf from ): init Le but de ces d\u00e9pendances est de \"stabiliser\" le contenu des images build\u00e9es, pour que le contenu qui doit \u00eatre pr\u00e9sent dans plusieurs images soit identique.","title":"D\u00e9pendances des images entre elles"},{"location":"TECHNIQUE/INTEGRATION/docker.html#principe-de-fonctionnement","text":"On suppose l'existence d'un forwarder TCP pricipal qui va faire l'aiguillage vers le bon reverse-proxy de paroisse en se basant sur le Server Name Indication, qui appara\u00eet en clair dans la connexion TLS. Il y a donc une connexion TLS entre le client et le serveur TLS, mais deux liaisons TCP (client/forwarder et forwarder/reverse proxy). Le reverse proxy va authentifier les utilisateurs, au travers des identifiants Drupal convoy\u00e9s via du HTTP Basic au-dessus d'une liason TLS, et probablement un autre moyen (certificat SSL par exemple). En ce qui concerne les identifiants, ils sont test\u00e9 au travers d'un authenticateur qui est branch\u00e9 sur le reverse proxy au travers d'une socket Unix. Chaque requ\u00eate adress\u00e9e au reverse proxy doit \u00eatre authentifi\u00e9e, et d\u00e9clenchera un appel \u00e0 l'authenticateur. L'authenticateur va effectuer une requ\u00eate vers le serveur web interne pour v\u00e9rifier que l'utilisateur est bien reconnu. Si tel est le cas, le reverse proxy va transf\u00e9rer la requ\u00eate vers le serveur web interne pour \u00eatre trait\u00e9e.","title":"Principe de fonctionnement"},{"location":"TECHNIQUE/INTEGRATION/docker.html#gestion-des-droits-sur-les-fichiers","text":"La gestion des droits sur les fichiers est un sujet complexe. On suppose que les syst\u00e8mes de fichiers mis en oeuvre dans le syst\u00e8me proposent une gestion des droits traditionnels \"\u00e0 la Unix\", avec des droits read-write-exec que l'on peut attribuer \u00e0 un propri\u00e9taire, un groupe, et le reste du monde ; et on suppose qu'on peut identifier le propri\u00e9taire et le groupe de r\u00e9f\u00e9rence des fichiers. Etant donn\u00e9 qu'en principe seul le propri\u00e9taire et root peuvent changer les permissions sur un fichier, et qu'il est pr\u00e9f\u00e9rable que le compte root ne soit pas trop utilis\u00e9 (par exemple pour \u00e9viter par la suite une ex\u00e9cution en root via du bit SUID), il a \u00e9t\u00e9 privil\u00e9gi\u00e9 de cr\u00e9er un compte sp\u00e9cifique, verrouill\u00e9, dont le but est d'\u00eatre propri\u00e9taire des fichiers : le compte paroisse (UID 1000). Un groupe paroisse (GID 1000) est \u00e9galement provisionn\u00e9. Le principe g\u00e9n\u00e9ral est que les fichiers (pour l'instant, non syst\u00e8me) qui sont pr\u00e9sents dans les images sont des fichiers destin\u00e9s \u00e0 \u00eatre en lecture seule, tandis que les fichiers des volumes seront en lecture \u00e9criture. Il s'agit d'appliquer le principe des droits minimaux pour effectuer les op\u00e9rations. L'id\u00e9e est de donner aux fichiers le propri\u00e9taire paroisse, et le groupe www-data. De l\u00e0, on peut positionner les droits sur les fichiers. De m\u00eame, il y a un compte authenticator (UID 1001) et un groupe authenticator (GID 1001) qui ont \u00e9t\u00e9 cr\u00e9es sur l'image d'authenticateur. Compte \u00e9galement verrouill\u00e9. En ce qui concerne les clefs, il faut se rappeler qu'Apache lit les clefs en tant que l'utilisateur lanc\u00e9 (root) avant de descendre ses droits. Du coup, les clefs n'ont pas besoin d'\u00eatre lues par www-data.","title":"Gestion des droits sur les fichiers"},{"location":"TECHNIQUE/INTEGRATION/docker.html#volumes-principaux","text":"Ces volumes sont : civicomp_dbvol: le volume de base de donn\u00e9es civicomp_filevol: le volume des fichiers, avec les fichiers sp\u00e9cifiques \u00e0 l'instance courante civicomp_privatevol : le volume des fichiers priv\u00e9s Les volumes sont mont\u00e9s avec l'option nocopy: true car ce fonctionnement correspond au fonctionnement en environnement Kubernetes. En environnement Kubernetes, il y aura des montages suppl\u00e9mentaires (les secrets et les variables d'environnement, par exemple).","title":"Volumes principaux"},{"location":"TECHNIQUE/INTEGRATION/docker.html#docker-compose","text":"Deux docker-compose sont disponibles. L'un d'eux, docker-init.yml est pr\u00e9vu pour initialiser les volumes, tandis que l'autre ( docker-compose.yml , nom par d\u00e9faut) est utilis\u00e9 pour l'ex\u00e9cution classique. L'int\u00e9r\u00eat du docuker-compose r\u00e9side dans le fait que docker-compose va s'occuper de faire les liaisons n\u00e9cessaires entre les containers et les volumes, sans avoir besoin de saisir des lignes de commande fastidieuses. C'est donc un syst\u00e8me analogue \u00e0 ce qu'on retrouve dans la d\u00e9claration d'objets dans Kubernetes.","title":"Docker-compose"},{"location":"TECHNIQUE/INTEGRATION/docker.html#initialisation-des-volumes","text":"On suppose qu'on se trouve dans le r\u00e9pertoire contenant les fichiers compose. docker-compose -f docker-init.yml up docker-compose -f docker-init.yml rm","title":"Initialisation des volumes"},{"location":"TECHNIQUE/INTEGRATION/docker.html#utilisation-de-lenvironnement-docker-au-quotidien","text":"Il faut penser \u00e0 mettre \u00e0 jour son /etc/hosts pour disposer de la r\u00e9solution de noms n\u00e9cessaire. Ensuite, on peut faire des op\u00e9rations quotidiennes avec des commandes comme, par exemple (en \u00e9tant dans le r\u00e9pertoire contenant les fichiers compose) : docker-compose -d up # [on fait le travail] docker-compose stop","title":"Utilisation de l'environnement Docker au quotidien"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html","text":"Etude : Authentification Apache / CiviCRM L\u2019authentification de CiviCRM peut correspondre \u00e0 deux notions, qui ne se recoupent pas forc\u00e9ment : l\u2019utilisateur qui est logu\u00e9 dans le CMS : on se base alors sur les m\u00e9canismes du CMS, qui peuvent \u00eatre diff\u00e9rents en fonction des CMS le contact enregistr\u00e9 dans le CRM : ce protocole permet \u00e9galement de reconna\u00eetre comme utilisateur CiviCRM un contact. Par ailleurs, Authx dispose \u00e9galement d\u2019une page qui expose l\u2019identification de l\u2019utilisateur courant (/civicrm/authx/id), page qui a \u00e9galement l\u2019avantage d\u2019\u00eatre l\u00e9g\u00e8re \u00e0 charger. Dans le cadre du projet CiviParoisse, il n\u2019est pas souhaitable, pour des questions de s\u00e9curit\u00e9 et de confidentialit\u00e9 des donn\u00e9es, qu\u2019un contact sans compte dans le CMS puisse interagir avec le CRM. Il s\u2019agira donc de faire en sorte que seuls les utilisateurs logu\u00e9s dans le CMS puissent avoir un acc\u00e8s au syst\u00e8me. L\u2019acc\u00e8s au CMS devra d\u2019ailleurs \u00eatre compris de mani\u00e8re assez large : en effet, si on consid\u00e8re des documents qui sont stock\u00e9s sous formes de fichiers directement accessibles via Apache, le CMS ne sera pas charg\u00e9 pour l\u2019acc\u00e8s \u00e0 ces fichiers et donc le contr\u00f4le d\u2019acc\u00e8s que pourrait effectuer le CMS ne se fera pas. Or, les contr\u00f4les sont \u00e9galement requis sur ces fichiers. Il s\u2019agit donc d\u2019effectuer une authentification directement au niveau du serveur web. Pour autant, le processus doit rester simple pour les utilisateurs finaux : il s\u2019agit donc de ne pas leur demander de retenir trop de mots de passe : il faut donc que l\u2019authentification effectu\u00e9e au niveau de Apache puisse \u00eatre propag\u00e9e au CMS. Toutefois, \u00e9tant donn\u00e9 que les utilisateurs pourraient choisir des mots de passe simple (ou les \u00e9crire sur des morceaux de papier), il convient de proposer une authentification \u00e0 2 facteurs, par exemple en se basant non seulement sur une connaissance (le mot de passe), mais \u00e9galement une possession (un certificat SSL, voire un token de s\u00e9curit\u00e9). Le travail \u00e0 effectuer est donc assez complexe, et a n\u00e9cessit\u00e9 des recherches pouss\u00e9es. Ce travail peut se diviser en deux parties, l\u2019une concernant l\u2019authentification par mot de passe, et l\u2019autre concernant l\u2019authentification par certificat SSL et HSM ; en revanche, il faudra \u00e9galement veiller \u00e0 la correspondance des identit\u00e9s entre les deux m\u00e9thodes (ne pas autoriser le certificat d\u2019un utilisateur A et le mot de passe d\u2019un utilisateur B lors d\u2019un seul login). Authentification par mot de passe Le choix du CMS : Drupal L\u2019authentification par mot de passe est g\u00e9r\u00e9e par le CMS. CiviCRM propose un support de 4 CMS (Drupal, Backdrop, Wordpress et Joomla). Ces CMS proposent tous nativement une authentification par nom d\u2019utilisateur et mot de passe, avec un hash sal\u00e9 du mot de passe stock\u00e9 en base de donn\u00e9es. De la sorte, si la base de donn\u00e9es fuite, les mots de passe ne sont pas pour autant pr\u00e9sents, car les fonctions de hash cherchent \u00e0 \u00eatre des fonctions \u00e0 sens unique qui ne permettent pas de pr\u00e9dire des collisions de hashes (lorsque cela arrive, la fonction ne peut plus \u00eatre utilis\u00e9e comme fonction de s\u00e9curit\u00e9). Les fonctions de hashes utilis\u00e9es peuvent diff\u00e9rer, mais il semble que la plupart des CMS supportent les hashes calcul\u00e9s par le code du projet phpass ( https://www.openwall.com/phpass/ ). On notera toutefois que la page du projet indique qu\u2019il faudrait pr\u00e9f\u00e9rer l\u2019utilisation des fonctions natives de PHP 5.5 et ult\u00e9rieur. M\u00eame si l\u2019on observe une certaine unicit\u00e9 de mani\u00e8re de faire chez les CMS support\u00e9s, la n\u00e9cessit\u00e9 de d\u00e9finir le CMS qui sera utilis\u00e9 arrive quand m\u00eame rapidement, puisqu\u2019il s\u2019agira d\u2019impl\u00e9menter un SSO entre le serveur web et le CMS. Les recherches effectu\u00e9es ont conduit \u00e0 privil\u00e9gier Drupal, pour plusieurs raisons : les recherches sur les proc\u00e9dures d\u2019installation ont montr\u00e9 l\u2019int\u00e9r\u00eat, pour l\u2019automatisation de l\u2019installation et la mise \u00e0 jour des syst\u00e8mes, de disposer d\u2019un gestionnaire de versions. Or, CiviCRM utilise Composer, qui est \u00e9galement utilis\u00e9 par Drupal. A l\u2019inverse, Backdrop et Wordpress ne semblent pas int\u00e9grer officiellement la gestion des d\u00e9pendances via Composer. Au niveau de Joomla, le support de Composer est souhait\u00e9 et int\u00e9gr\u00e9 dans la feuille de route, mais n\u2019est pas encore atteint. Drupal utilise le framework Symfony, et ce framework dispose d\u2019un support d\u2019authentification HTTP Basic : le syst\u00e8me int\u00e8gre donc d\u00e9j\u00e0 des composants qui faciliteront le SSO entre le serveur web et le CMS le projet CiviParoisse est historiquement bas\u00e9 sur le CMS Drupal ; les b\u00e9n\u00e9voles qui travaillent sur les aspects techniques ont de ce fait cherch\u00e9 \u00e0 remonter en local des instances Drupal + CiviCRM, d\u2019o\u00f9 une \u00e9ventuelle r\u00e9utilisation ou mont\u00e9e en comp\u00e9tences sur ce CMS il semblerait que CiviCRM ait des affinit\u00e9s avec Drupal (comme par exemple les conventions de code qui ont \u00e9t\u00e9 r\u00e9utilis\u00e9es). Le choix du serveur web : Apache Le choix du serveur web est \u00e9galement un choix important, car il en existe un grand nombre (Apache, Nginx, Jetty, Lighttpd pour ne citer qu\u2019eux). Apache est le serveur web qui est traditionnellement employ\u00e9 \u00ab par d\u00e9faut \u00bb dans les sites web PHP (stack LAMP ou WAMP, avec A pour Apache), et de ce fait est susceptible d\u2019\u00eatre mieux connu par les b\u00e9n\u00e9voles que les autres solutions. De ce fait, m\u00eame si d\u2019autres serveurs pourraient \u00e9ventuellement \u00eatre employ\u00e9s, la recherche s\u2019est concentr\u00e9e sur l\u2019interfa\u00e7age avec Apache. Toutefois, si le besoin se fait sentir, on pourra chercher \u00e0 se tourner vers d\u2019autres solutions (dont Nginx). Strat\u00e9gie d\u2019interfa\u00e7age La strat\u00e9gie d\u2019interfa\u00e7age va chercher \u00e0 utiliser au maximum les codes existants pour d\u00e9velopper (et maintenir) un minimum de m\u00e9canismes sp\u00e9cifiques. De ce fait, deux axes vont \u00eatre mis en \u0153uvre : la consommation des identifiants pr\u00e9sent\u00e9s par Apache \u00e0 Drupal pour disposer d\u2019un m\u00e9canisme SSO. la mise \u00e0 disposition \u00e0 Apache d\u2019un m\u00e9canisme de validation des donn\u00e9es d\u2019authentification, m\u00e9canisme fourni par Drupal ou CiviCRM (authx) Consommation des identifiants pr\u00e9sent\u00e9s par Apache \u00e0 Drupal La consommation des donn\u00e9es d\u2019authentification pr\u00e9sent\u00e9es par Apache \u00e0 du code PHP est assez standardis\u00e9e : traditionnellement, le serveur Apache peut fournir une variable d\u2019environnement REMOTE_USER pour indiquer l\u2019identifiant d\u2019un utilisateur, si l\u2019authentification a \u00e9t\u00e9 effectu\u00e9e au niveau d\u2019Apache. Lorsqu\u2019il s\u2019agit d\u2019une authentification de type HTTP Basic, les donn\u00e9es sont pr\u00e9sent\u00e9es \u00e9galement \u00e0 PHP via les variables $_SERVER['PHP_AUTH_USER'] et $_SERVER[\u2018PHP_AUTH_PW\u2019] . Comme on le verra plus tard, Apache n\u2019est pas en mesure de v\u00e9rifier de fa\u00e7on autonome les donn\u00e9es d\u2019identification, et devra se reposer sur Drupal et PHP pour faire le travail via de l\u2019authentification de type HTTP Basic. Cette authentification de type HTTP Basic sera transmise avec chaque requ\u00eate de page. Le HTTP Basic est support\u00e9 via Symfony, mais n\u2019est pas consid\u00e9r\u00e9 comme une m\u00e9thode d\u2019authentification globale (utilisable tout le temps par d\u00e9faut, \u00e0 l\u2019inverse de l\u2019authentification par cookie). Il s\u2019agit donc au niveau de Drupal de cr\u00e9er un petit module qui permet d\u2019injecter le fournisseur HTTP Basic comme un fournisseur global via un fichier .services.yml : services : basic_auth.authentication.basic_auth : class : Drupal\\basic_auth\\Authentication\\Provider\\BasicAuth arguments : [ '@config.factory' , '@user.auth' , '@flood' , '@entity_type.manager' ] tags : - { name : authentication_provider , provider_id : 'basic_auth' , priority : 100 , global : TRUE } C\u2019est le seul r\u00e9glage \u00e0 effectuer pour consommer les donn\u00e9es. Si les donn\u00e9es d\u2019authentification ne sont pas juste, une erreur de type 4XX est renvoy\u00e9e. En revanche, il reste \u00e0 la charge d\u2019Apache de toujours envoyer les donn\u00e9es d\u2019identification pour qu\u2019elles soient consomm\u00e9es (le header HTTP Authorization : Basic devra \u00eatre pr\u00e9sent dans toutes les requ\u00eates), sans quoi un code 200 pourrait \u00eatre renvoy\u00e9 \u00e0 tort. Mise \u00e0 disposition des donn\u00e9es d\u2019authentification Apache s\u00e9pare conceptuellement le processus d\u2019authentification en deux, \u00e0 savoir les m\u00e9canismes permettant de r\u00e9cup\u00e9rer les donn\u00e9es d\u2019identification fournies par un navigateur web d\u2019une part, et la comparaison avec des fournisseurs d\u2019authentification d\u2019autre part. Fournisseur Authnz External En ce qui concerne le fournisseur d\u2019authentification, Apache propose plusieurs m\u00e9thodes. Malheureusement, aucune m\u00e9thode \u00ab native \u00bb ne convient, car la m\u00e9thode reposant sur l\u2019exploitation d\u2019une base de donn\u00e9es suppose la connaissance de la m\u00e9thode de hash pour que le hash puisse \u00eatre calcul\u00e9 sur les donn\u00e9es brutes. En ce qui concerne le support FastCGI, bien que celui-ci soit s\u00e9duisant sur le papier, le support FastCGI propos\u00e9 par php (php-cgi) et par fpm (php-fpm) n\u2019a pas permis d\u2019obtenir un fonctionnement tel qu\u2019un script d\u00e9fini sur la ligne de commande soit ex\u00e9cut\u00e9 et que le fastcgi ne soit utilis\u00e9 que pour fournir les donn\u00e9es d\u2019authentification. Il aurait donc fallu se tourner vers d\u2019autres impl\u00e9mentations FastCGI, ce qui aurait suppos\u00e9 des d\u00e9veloppements et donc la maintenance de ces d\u00e9veloppements. En revanche, il existe un fournisseur tiers qui est le module authnz_external . Ce module tiers est disponible directement dans les packages de Ubuntu LTS, et de ce fait son support est assur\u00e9 via la distribution. Ce module permet l\u2019ex\u00e9cution d\u2019un programme externe, auquel on peut fournir parplusieurs moyens les donn\u00e9es d\u2019identification. Le module utilisera le code de retour du programme pour d\u00e9terminer si l\u2019authentification a r\u00e9ussi (code de retour \u00e0 z\u00e9ro) ou \u00e9chou\u00e9 (code de retour diff\u00e9rent de z\u00e9ro). Comme on l\u2019a vu pr\u00e9c\u00e9demment dans le SSO d\u2019Apache vers Drupal, en envoyant une requ\u00eate HTTP vers Drupal avec de l\u2019authentification Basic fournira un code de retour qui indiquera si l\u2019authentification a r\u00e9ussi ou non. Il va donc s\u2019agir d\u2019utiliser un programme tiers pour r\u00e9cup\u00e9rer les identifiants, effectuer la requ\u00eate, et renvoyer le bon code de retour, en s\u2019assurant que l\u2019identifiant et le mot de passe soient toujours sett\u00e9s dans la requ\u00eate. Script shell principal, wget, script askpass La commande wget est une commande d\u2019utilisation assez commune, qui permet d\u2019effectuer en particulier une requ\u00eate HTTP. Cette commande supporte le HTTPS (en authentification et en v\u00e9rification du certificat serveur), et propose via l\u2019option \u2013use-askpass l\u2019utilisation d\u2019un programme \u00ab askpass \u00bb tiers pour fournir les informations d\u2019identification via STDOUT (une ex\u00e9cution du programme tiers pour le nom d\u2019utilisateur, une autre pour le mot de passe). Charge au programme askpass de r\u00e9cup\u00e9rer le mot de passe, de v\u00e9rifier sa longueur, et de le retransmettre via STDOUT s\u2019il est non vide. Ce programme askpass devra soigner son code de retour : 0 si tout va bien ou une valeur diff\u00e9rente s\u2019il y a un probl\u00e8me. D\u2019apr\u00e8s mes tests, le code de retour de askpass est pris en compte par wget, et s\u2019il est diff\u00e9rent de 0, wget r\u00e9agira \u00e9galement dans son code de retour . Ce point est d\u2019ailleurs plus ou moins confirm\u00e9 par la lecture du code source et l\u2019exemple dans la page man de posix_spawnp (utilis\u00e9 pour lancer le programme) : //Code source wget : main.c : argv [ 0 ] = opt . use_askpass ; argv [ 1 ] = question ; argv [ 2 ] = NULL ; status = posix_spawnp ( & pid , opt . use_askpass , & fa , NULL , argv , environ ); if ( status ) { fprintf ( stderr , \"Error spawning %s: %d \\n \" , opt . use_askpass , status ); exit ( WGET_EXIT_GENERIC_ERROR ); } Exemple dans la man page: The program below demonstrates the use of various functions in the POSIX spawn API. The program accepts command-line attributes that can be used to create file actions and attributes objects. The remaining command-line arguments are used as the executable name and command-line arguments of the program that is executed in the child. In the first run, the date(1) command is executed in the child, and the posix_spawn() call employs no file actions or attributes objects. $ ./a.out date PID of child: 7634 Tue Feb 1 19:47:50 CEST 2011 Child status: exited, status=0 In the next run, the -c command-line option is used to create a file actions object that closes standard output in the child. Consequently, date(1) fails when trying to perform output and exits with a status of 1. $ ./a.out -c date PID of child: 7636 date: write error: Bad file descriptor Child status: exited, status=1 Par ailleurs, wget permet via l\u2019option \u2013auth-no-challenge d\u2019envoyer directement l\u2019authentification HTTP Basic sans requ\u00e9rir le challenge initial : ce point est tr\u00e8s important,dans la mesure o\u00f9 une page sans authentification pourrait renvoyer \u00e9galement du code 200, comme vu pr\u00e9c\u00e9demment dans l\u2019impl\u00e9mentation SSO. On se souviendra qu\u2019\u00e9tant donn\u00e9 qu\u2019Unix cr\u00e9e des processus par fork, les descripteurs de fichiers disponibles dans un processus p\u00e8re sont \u00e9galement dupliqu\u00e9s dans un processus fils au niveau du fork. En l\u2019occurence, mod_authnz_external permet de transmettre via la m\u00e9thode \u00ab pipe \u00bb les donn\u00e9es via STDIN, et le fork effectu\u00e9 par mod_authnz_external, puis le script shell principal, puis par le script wget font que le script askpass pourra lire chaque donn\u00e9e sur STDIN. Cette mani\u00e8re de faire a un gros avantage : les donn\u00e9es d\u2019identification ne seront pas pr\u00e9sentes dans l\u2019environnement des applications, et de ce fait ne peuvent pas \u00eatre r\u00e9cup\u00e9r\u00e9es aussi facilement que via de l\u2019ex\u00e9cution de commande ps ou des balades dans /proc. On en arrive donc aux \u00e9bauches suivantes : #!/bin/bash # Script shell Askpass : read -s t if test -n \" $t \" then echo \" $t \" exit 0 else exit 1 fi #!/bin/bash #Script shell Principal : wget -d --use-askpass=\"/home/ubuntu/DRUPAL_COMPOSER2/AUTH/askpass.sh\" --auth-no-challenge -- certificate=\"/etc/apache2/KEYS/server.x509\" --private-key=\"/etc/apache2/KEYS/server.key\" --ca- certificate=\"/etc/apache2/KEYS/ca.x509\" https://drucomp2.test:444/civicrm/authx/id -O /dev/null exit $? Bien entendu, ces scripts peuvent encore \u00eatre am\u00e9lior\u00e9s (par exemple v\u00e9rifier le code de retour des read), rendus plus g\u00e9n\u00e9riques pour l\u2019installation automatique, utiliser des clefs sp\u00e9cifiques\u2026 Cible pour l\u2019authentification : authx A vrai dire, n\u2019importe quelle page authentifi\u00e9e pourrait faire l\u2019affaire en tant que cible (du moment qu\u2019elle ne modifie pas le syst\u00e8me). Pour autant, j\u2019ai vu deux cibles plus int\u00e9ressantes que les autres, en raison des informations qu\u2019elles peuvent fournir pour du d\u00e9bogage ; en effet, elles indiquent toutes les deux si l\u2019utilisateur est logu\u00e9 : civicrm/authx/id : int\u00e9gr\u00e9 dans CiviCRM user/login_status?_format=xml : int\u00e9gr\u00e9 dans Drupal. L\u2019int\u00e9r\u00eat de authx est qu\u2019il fournit des informations suppl\u00e9mentaires par rapport \u00e0 l\u2019\u00e9ventuel contact associ\u00e9 \u00e0 l\u2019utilisateur. En outre, il faut configurer authx, en fonction des indications donn\u00e9es dans le guide du d\u00e9veloppeur CiviCRM : cv.phar ev 'Civi::settings()->set(\"authx_guards\",[\"perm\"]);' cv.phar ev 'Civi::settings()->set(\"authx_param_cred\",[]);' cv.phar ev 'Civi::settings()->set(\"authx_param_user\",\"require\");' cv.phar ev 'Civi::settings()->set(\"authx_header_cred\",[\"pass\"]);' cv.phar ev 'Civi::settings()->set(\"authx_header_user\",\"require\");' cv.phar ev 'Civi::settings()->set(\"authx_xheader_cred\",[]);' cv.phar ev 'Civi::settings()->set(\"authx_xheader_user\",\"require\");' cv.phar ev 'Civi::settings()->set(\"authx_login_cred\",[]);' cv.phar ev 'Civi::settings()->set(\"authx_login_user\",\"require\");' cv.phar ev 'Civi::settings()->set(\"authx_auto_cred\",[]);' cv.phar ev 'Civi::settings()->set(\"authx_auto_user\",\"require\");' Configuration Apache : mise en \u0153uvre d\u2019un reverse proxy et authentification \u00e0 deux facteurs (SSL et basic) Les tests ont montr\u00e9 tr\u00e8s rapidement un probl\u00e8me \u00e0 r\u00e9soudre lorsqu\u2019on utilise qu\u2019un seul site : si Apache cherche \u00e0 s\u2019interroger lui-m\u00eame sur la validit\u00e9 d\u2019une page, on arrive \u00e0 une boucle r\u00e9cursive qui fait exploser le nombre de requ\u00eates wget, et la requ\u00eate ne peut donc pas aboutir. Le moyen le plus simple pour r\u00e9gler ce probl\u00e8me est de faire reposer l\u2019authentification SSO non pas directement sur le virtualhost de Drupal, mais plut\u00f4t sur un reverse proxy se pla\u00e7ant en amont : il suffit par exemple d\u2019ouvrir un autre port pour le virtualhost de Drupal, mais sur 127.0.0.1, de sorte \u00e0 ce que le virtualhost ne soit pas directement accessible depuis l\u2019ext\u00e9rieur (par exemple : 127.0.0.1:444/tcp). Le reverse proxy, lui, va \u00e9couter sur 0.0.0.0:443/tcp. Cette configuration, outre le fait de r\u00e9gler le probl\u00e8me de boucle, pourrait \u00e9galement se r\u00e9v\u00e9ler utile pour isoler le p\u00e9rim\u00e8tre d\u2019un probl\u00e8me : en effet, un administrateur pourra \u00e9ventuellement faire du port forwarding via SSH pour acc\u00e9der \u00e0 distance au port 444 si n\u00e9cessaire (\u00e0 condition qu\u2019il se connecte \u00e0 distance \u00e0 la machine). On peut \u00e9ventuellement chercher \u00e0 limiter cette possibilit\u00e9 en instaurant une authentification par certificat entre le reverse proxy et le virtualhost drupal. Par ailleurs, le fait d\u2019utiliser du SSL pour cette connexion interne permet \u00e9galement d\u2019\u00e9viter de laisser circuler en clair des mots de passe qui pourraient \u00eatre captur\u00e9s via tcpdump par exemple. Un autre type de solution technique qui aurait fait \u00e9galement l\u2019affaire aurait \u00e9t\u00e9 de l\u2019IPSEC en mode transport : n\u00e9anmoins, il semble plus maintenable d\u2019utiliser du SSL, tout simplement car des connaissances sur ce sujet sont plus ou moins d\u00e9j\u00e0 exig\u00e9es du fait de la n\u00e9cessit\u00e9 actuelle de la mise en \u0153uvre de HTTPS. On en arrive \u00e0 une \u00e9bauche de configuration telle que suit. Cette \u00e9bauche pourra \u00eatre am\u00e9lior\u00e9e en d\u00e9diant une autorit\u00e9 de certification d\u2019une part aux connexions des clients vers le reverse proxy et d\u2019autre part \u00e0 la connexion entre le reverse proxy et le vhost Drupal. Listen 127.0.0.1 :444 <VirtualHost 127.0.0.1:443 > #LogLevel debug #CustomLog \"/var/log/apache2/debug_jm.log\" \"REMOTE_USER: %{REMOTE_USER}x {SSL_CLIENT_S_DN_CN}x --- %v %h %l %u %t \\\"%r\\\" %>s %b\" ServerName drucomp2.test AddExternalAuth dea \"/home/ubuntu/DRUPAL_COMPOSER2/AUTH/externalauth.sh\" SetExternalAuthMethod dea pipe SSLEngine on SSLCACertificateFile \"/etc/apache2/KEYS/ca.x509\" SSLCertificateFile \"/etc/apache2/KEYS/drucomp2.x509\" SSLCertificateKeyFile \"/etc/apache2/KEYS/drucomp2.pem\" SSLCipherSuite HIGH:!aNULL:!MD5 SSLOptions +StrictRequire SSLProxyVerify require SSLProxyMachineCertificateFile \"/etc/apache2/KEYS/proxy_client.pem\" SSLProxyCACertificateFile \"/etc/apache2/KEYS/ca.x509\" <Location / > <RequireAll> Require ssl Require ssl-verify-client Require valid-user Require expr (%{REMOTE_USER} == %{SSL_CLIENT_S_DN_CN} ) && (-n %{REMOTE_USER}) </RequireAll> AuthType Basic AuthName \"Apache Level\" AuthBasicProvider external AuthExternal dea AuthBasicAuthoritative on ProxyPass \"https://drucomp2.test:444/\" ProxyPassReverse \"https://drucomp2.test:444/\" </Location> SSLProxyCheckPeerCN On SSLProxyCheckPeerName on SSLProxyVerify require SSLProxyEngine on SSLOptions +StrictRequire SSLVerifyClient require </VirtualHost> <VirtualHost 127.0.0.1:444 > #LogLevel debug DocumentRoot /home/ubuntu/DRUPAL_COMPOSER2 ServerName drucomp2.test php_admin_value sendmail_path \"/usr/bin/env catchmail -f test@mailcatcher.test\" php_admin_value CIVICRM_DB_CACHE_CLASS NoCache <Directory /home/ubuntu/DRUPAL_COMPOSER2 > SSLRequireSSL Require all granted AllowOverride All </Directory> SSLEngine on SSLCACertificateFile \"/etc/apache2/KEYS/ca.x509\" SSLCertificateFile \"/etc/apache2/KEYS/drucomp2.x509\" SSLCertificateKeyFile \"/etc/apache2/KEYS/drucomp2.pem\" SSLCipherSuite HIGH:!aNULL:!MD5 SSLOptions +StrictRequire SSLVerifyClient require </VirtualHost> Cette configuration pr\u00e9sente par ailleurs d\u00e9j\u00e0 une configuration pour forcer une authentification par certificat SSL, avec une v\u00e9rification particuli\u00e8re : la v\u00e9rification de la correspondance entre l\u2019utilisateur authentifi\u00e9 via mod_external ( dans REMOTE_USER ) et le common name du distinguished name du certificat SSL du client ( SSL_CLIENT_S_DN_CN ). A nouveau, on prend la pr\u00e9caution de v\u00e9rifier que l\u2019identifiant n\u2019est pas vide, m\u00eame si cela ne devrait pas arriver vu les pr\u00e9cautions prises dans le askpass. A l\u2019usage, avec les caches d\u00e9sactiv\u00e9s, on constate imm\u00e9diatement une grosse augmentation de charge syst\u00e8me lors de la mise en \u0153uvre : en effet, pour toute requ\u00eate entrante, il y a en r\u00e9alit\u00e9 trois requ\u00eates ex\u00e9cut\u00e9es (requ\u00eate entrante, requ\u00eate d\u2019autorisation, requ\u00eate de traitement). Il faut voir que cette configuration emp\u00eache \u00e9galement certaines mises en cache au niveau de Drupal, mises en caches qui sont interdites nativement en raison de l\u2019authentification basique. Authentification par clef priv\u00e9e (et certificat SSL) sur HSM L\u2019authentification par clef priv\u00e9e et certificat SSL sur Hardware Security Module est un moyen pour fournir une authentification mat\u00e9rielle, dans la mesure o\u00f9, en g\u00e9n\u00e9ral, les modules de s\u00e9curit\u00e9 permettent de g\u00e9n\u00e9rer des clefs priv\u00e9es, mais ne permettent pas de les exporter (certains modules permettent toutefois une sauvegarde chiffr\u00e9e de la clef priv\u00e9e). Le module peut prendre plusieurs formes, dont usuellement la forme d\u2019un token USB, similaire \u00e0 une clef USB. Les fonctionnalit\u00e9s qui seront utilis\u00e9es sur ces clefs sont les fonctionnalit\u00e9s PIV (Personnal Identity Verification). G\u00e9n\u00e9ralement, les constructeurs de telles clefs fournissent des API pour acc\u00e9der au mat\u00e9riel, qui impl\u00e9mentent le support de PKCS11. C\u2019est justement sur la mise en \u0153uvre de PKCS11 dans le serveur web que va reposer en grande partie l\u2019authentification par clef, \u00e0 la place des fichiers de clefs. Une contrainte lourde : la gestion d\u2019une autorit\u00e9 de certification Cette authentification par clef et certificat suppose une gestion des clefs rigoureuse, et implique une contrainte relativement forte : la mise en \u0153uvre d\u2019une infrastructure \u00e0 clefs publiques (Public Key Infrastructure). Cette infrastructure suppose au minimum la pr\u00e9sence d\u2019une autorit\u00e9 de certification (CA) qui est un tiers de confiance qui va attester de l\u2019identit\u00e9 li\u00e9e \u00e0 une clef publique. L\u2019autorit\u00e9 de certification doit \u00eatre g\u00e9r\u00e9e de mani\u00e8re rigoureuse pour que la confiance subsiste, et requiert donc la mise en \u0153uvre de processus organisationnels formalis\u00e9s, compris, et accept\u00e9s par toutes les parties. Le travail de l\u2019autorit\u00e9 de certification est non seulement la signature des certificats, mais \u00e9galement la r\u00e9vocation des clefs compromises (Certificate Revocation List, accessible soit sous forme de fichier, soit sous forme de service de r\u00e9pondeur OCSP Online Certificate Status Protocol) ). Ce travail de r\u00e9vocation n\u00e9cessite une disponibilit\u00e9 tr\u00e8s rapide de l\u2019autorit\u00e9, en plus de la coop\u00e9ration des utilisateurs. La mise en \u0153uvre d\u2019une autorit\u00e9 de certification internalis\u00e9e est donc un pr\u00e9requis lourd qu\u2019il ne faut pas sous-estimer. Il existe de la litt\u00e9rature sp\u00e9cialis\u00e9e \u00e0 ce sujet. Il y a \u00e9ventuellement une autre piste compl\u00e9mentaire : s\u2019adresser \u00e0 l\u2019ANSSI (ex : https://www.ssi.gouv.fr/uploads/2015/07/catalogue-cfssi-anssi_2020-2021.pdf ) ou aux services du minist\u00e8re de l\u2019int\u00e9rieur si une \u00ab externalisation \u00bb pourrait \u00eatre envisag\u00e9e. Pr\u00e9paration d\u2019un HSM : deux exemples Deux exemples peuvent \u00eatre explor\u00e9s : l\u2019utilisation d\u2019une clef usb Yubikey (ex:Yubikey 4), et l\u2019utilisation d\u2019une impl\u00e9mentation d\u2019\u00e9mulation logicielle : SoftHSM(v2). L\u2019int\u00e9r\u00eat de l\u2019\u00e9mulation est qu\u2019il peut servir \u00e0 mod\u00e9liser les services sur les machines de d\u00e9velopp ement sans disposer de mat\u00e9riel particulier. Clef Yubikey L\u2019exemple de la clef Yubikey n\u2019est pas un exemple \u00ab anodin \u00bb, dans la mesure o\u00f9 Yubico ( https://www.yubico.com/?lang=fr ) supporte l\u2019environnement Linux (les packages de gestion des Yubikeys sont disponibles en standard dans Ubuntu) et fournit une documentation sur son site web ( https://developers.yubico.com/PIV/ ). Les prix des clefs sur le site de Yubico semblent accessibles ( https://www.yubico.com/fr/store/ : \u00e0 partir de 45\u20acHT pour une clef). J\u2019ai une clef Yubikey 4 que j\u2019avais achet\u00e9e il y a plusieurs ann\u00e9es pour exp\u00e9rimenter. La premi\u00e8re chose \u00e0 faire serait d\u2019abord de personnaliser les codes d\u2019acc\u00e8s de la clef. Deux codes sont g\u00e9n\u00e9ralement utilisables : le PIN utilisateur et le PIN de l\u2019officier de s\u00e9curit\u00e9 (ou code PUK). Par ailleurs, dans le cadre de la clef Yubikey, personnaliser la clef de Management serait \u00e9galement judicieux (voir https://developers.yubico.com/PIV/Introduction/Admin_access.html ). Je n\u2019ai n\u00e9anmoins pas effectu\u00e9 ces t\u00e2ches. Les fonctionnalit\u00e9s PIV sont g\u00e9r\u00e9es par un outil sp\u00e9cifique : yubico-piv-tool , qui est un outil en ligne de commande. La premi\u00e8re chose est de g\u00e9n\u00e9rer un couple clef publique / clef priv\u00e9e pour l\u2019usage d\u2019authentification. Ces clefs \u00e9tant multi-usages, il convient tout d\u2019abord de d\u00e9terminer l'emplacement m\u00e9moire (slot) qui devra \u00eatre utilis\u00e9, en se r\u00e9f\u00e9rant \u00e0 la documentation ( https://developers.yubico.com/PIV/Introduction/Certificate_slots.html ) : ledit slot est le 9a. L\u2019outil yubico-piv-tool permettrait par ailleurs \u00e9galement de changer pin, puk et clef de management. Un autre outil permet de configurer les fonctionnalit\u00e9s disponibles : ykman , et permet explicitement de lister les p\u00e9riph\u00e9riques et les services activ\u00e9s. yubico-piv-tool -a generate -s 9a -A RSA2048 La commande affiche ensuite la clef publique g\u00e9n\u00e9r\u00e9e. On peut la retrouver via la g\u00e9n\u00e9ration d\u2019une requ\u00eate de certificat, qui est l\u2019\u00e9tape suivante : yubico-piv-tool -a verify-pin -a request-certificate -s 9a -S '/CN=admin/OU=test/O=drucomp2.test' -o cert.req On notera la syntaxe du sujet du certificat, qui utilise des slashes \u00e0 la place des virgules. On peut ensuite signer la requ\u00eate de certificat, comme par exemple avec : openssl x509 -req -in YUBICO/cert.req -out YUBICO/cert.x509 -days 365 -CA ca.x509 -CAkey ca.key -CAserial ca.srl Il n\u2019y a ensuite plus qu\u2019\u00e0 importer le certificat : yubico-piv-tool -s9a -aimport-certificate -i cert.x509 A ce moment, la clef est pr\u00eate pour attester d\u2019une identit\u00e9 \u2013 \u00e0 condition de faire confiance \u00e0 l\u2019autorit\u00e9 de certification qui a sign\u00e9 le certificat. SoftHSM2 SoftHSM2 permet de fournir une \u00e9mulation de mat\u00e9riel de s\u00e9curit\u00e9, utile pour apprendre. N\u00e9anmoins, le fait que ce soit une \u00e9mulation logicielle a un impact important : les droits sur les fichiers s\u2019appliquent, ce qui n\u2019est pas le cas avec du mat\u00e9riel : ceci a pos\u00e9 probl\u00e8me pour l\u2019acc\u00e8s aux clefs via apache, lorsque www-data n\u2019avait pas les droits sur les fichiers, en lan\u00e7ant une erreur assez g\u00e9n\u00e9rique (object invalid handle). Le d\u00e9buggage de ce probl\u00e8me a n\u00e9cessit\u00e9 l\u2019installation des symboles de d\u00e9buggage d\u2019apache, la modification du nombre de workers (pour passer \u00e0 1), et la r\u00e9cup\u00e9ration des codes sources des librairies (via apt source) pour pouvoir attacher \u00e0 gdb le worker apache et faire du pas \u00e0 pas dans le code source pour arriver jusqu\u2019\u00e0 la source du probl\u00e8me. La mise en \u0153uvre de SoftHSM2 est assez ressemblante \u00e0 celle de la Yubikey. La premi\u00e8re des choses est d\u2019identifier les slots disponibles : softhsm2-util--show-slots De l\u00e0, il faut initialiser les pins de l\u2019utilisateur et du security officer : softhsm2-util --init-token --slot 0 --so-pin 12345678 --pin 123456 --label serverhsm G\u00e9n\u00e9rer la paire de clefs : on utilise pkcs11-tool (package opensc) pkcs11-tool --module /usr/lib/arm-linux-gnueabihf/softhsm/libsofthsm2.so --login --keypairgen --key-type rsa:2048 --usage-sign --token-label serverhsm --label serverkey De l\u00e0, il faut trouver l\u2019URI PKCS11 de la clef utilis\u00e9e : p11tool (package gnutls-bin) : on r\u00e9cup\u00e8re d\u2019abord la liste des tokens, avec leur URI, puis on liste celles du support qui nous int\u00e9resse p11tool --list-tokens p11tool --login --list-all pkcs11:model = SoftHSM%20v2 ; manufacturer = SoftHSM%20project ; serial = 75bb53774ddd60dc ; token = serverhsm G\u00e9n\u00e9rer la requ\u00eate de certificat : openssl req -new -engine pkcs11 -keyform engine -key \"pkcs11:model=SoftHSM%20v2;manufacturer=SoftHSM%20project;serial=75bb53774ddd60dc;token=serverhsm;object=serverkey;type=private\" -subj \"/C=FR/ST=France/L=Strasbourg/O=TEST/OU=INFRA/CN=drucomp2.test\" -out serverhsm.req Il ne reste plus que la signature du certificat : openssl x509 -req -in serverhsm.req -out serverhsm.x509 -extfile ext -ext ext -CA ca.x509 -CAkey ca.key -CAserial ca.srl -sha256 -days 365 Et l\u2019import du certificat : pkcs11-tool --module /usr/lib/arm-linux-gnueabihf/softhsm/libsofthsm2.so serverhsm --label servercert --write-object serverhsm.x509 --type cert --login --token-label Comme indiqu\u00e9 pr\u00e9c\u00e9demment, il faudra faire attention \u00e0 ce que les fichiers soient accessibles par l\u2019utilisateur qui les utilisera. Mise en \u0153uvre du HSM pour les connexions web Le HSM va \u00eatre utilis\u00e9 \u00e0 deux endroits : au niveau du serveur web, et au niveau du navigateur web. Prise en charge par Apache Apache dispose de deux supports pour la prise en charge de PKCS11 : le premier support est le module gnutls. Ce module est d\u00e9j\u00e0 ancien, et les tests effectu\u00e9s montrent que ce module ne met pas \u00e0 disposition les donn\u00e9es comme le DN du sujet du certificat au niveau des directives Require : de ce fait, ce module ne peut pas faire l\u2019affaire. Le deuxi\u00e8me module est le module ssl : ce module a vu un d\u00e9but de support de PKCS11 depuis la version 2.4.42. Ce support est donc r\u00e9cent, car la version d\u2019Apache fournie par Ubuntu 20.04 LTS est la version 2.4.41, ne permettant pas le support de la fonctionnalit\u00e9. De ce fait, il est n\u00e9cessaire de passer temporairement \u00e0 la version 21.04 d\u2019Ubuntu, qui embarque Apache 2.4.46 ; passer \u00e0 la version normale signifie \u00e9galement disposer d\u2019une dur\u00e9e de support r\u00e9duite \u00e0 9 mois, au lieu de 5 ans. Le support est minimaliste : il concerne le certificat et la clef du serveur : les directives de configuration peuvent accepter depuis 2.4.42 de la possibilit\u00e9 de saisir des URI PKCS11, URI que l\u2019on peut d\u00e9terminer via p11tool. Ce point est probl\u00e9matique pour le reverse proxy, qui, lui, ne supporte pas d\u2019URI PKCS11 au niveau de la directive SSLProxyMachineCertificateFile . On arrive \u00e0 comprendre ce non-support en raison de l\u2019approche de cette directive : stocker l\u2019ensemble des certificats dans un path ou dans un fichier pour permettre au proxy de s\u2019authentifier aupr\u00e8s des serveurs distants, ce qui est incompatible avec les URI PKCS11, qui, elles, sont plut\u00f4t utilis\u00e9es pour adresser des ressources sp\u00e9cifiques. Dans le cas pr\u00e9sent, un contournement est possible via iptables : en effet, on peut supposer que l\u2019instance qui h\u00e9bergera le reverse proxy et le site seront situ\u00e9s dans une m\u00eame instance d\u2019Apache, et donc auront \u00e0 disposition le m\u00eame kernel. De ce fait, on peut mettre \u00e0 profit une fonctionnalit\u00e9 de marquage des paquets r\u00e9seaux d\u2019iptables, associ\u00e9e \u00e0 une condition sur l\u2019origine des paquets : on marquera sur la cha\u00eene OUTPUT, sur le loopback, les paquets issus de www-data destin\u00e9s au site drupal proprement dit, et on n\u2019acceptera sur la cha\u00eene INPUT, \u00e0 l\u2019entr\u00e9e du loopback et \u00e0 destination du site drupal, que des paquets d\u00fbment marqu\u00e9s. Un exemple de configuration est tel que suit : iptables -A OUTPUT -o lo -p tcp --dst 127 .0.0.1 --src 127 .0.0.1 --dport 444 -m owner --uid-owner www-data -j MARK --set-mark 33 iptables -A INPUT -i lo -p tcp --dst 127 .0.0.1 --src 127 .0.0.1 --dport 444 -m mark --mark 33 -j ACCEPT iptables -A INPUT -p tcp --dport 444 -j DROP Les paquets qui arrivent au serveur Drupal seront donc identifi\u00e9s indirectement, ce qui permet ne plus avoir besoin du certificat SSL pour l\u2019authentification au niveau de Drupal. En revanche, le chiffrement des donn\u00e9es reste toutefois requis. On en arrive donc \u00e0 une configuration d\u2019exemple comme la suivante : Listen 127.0.0.1 :444 <VirtualHost 127.0.0.1:443 > LogLevel debug CustomLog \"/var/log/apache2/debug_jm.log\" \"REMOTE_USER: %{REMOTE_USER}x SUBJECT_CN: % {SSL_CLIENT_S_DN_CN}x --- %v %h %l %u %t \\\"%r\\\" %>s %b\" ServerName drucomp2.test AddExternalAuth dea \"/home/ubuntu/DRUPAL_COMPOSER2/AUTH/externalauth.sh\" SetExternalAuthMethod dea pipe SSLEngine on SSLCACertificateFile \"/etc/apache2/KEYS/ca.x509\" SSLCertificateFile \"pkcs11:model=SoftHSM%20v2;manufacturer=SoftHSM%20project;serial=75bb53774ddd60dc;token=serverhsm;object=servercert;type=cert\" SSLCertificateKeyFile \"pkcs11:model=SoftHSM%20v2;manufacturer=SoftHSM%20project;serial=75bb53774ddd60dc;token=serverhsm;object=serverkey;type=private\" SSLCipherSuite HIGH:!aNULL:!MD5 SSLOptions +StrictRequire SSLProxyVerify require #SSLProxyMachineCertificateFile \"/etc/apache2/KEYS/proxy_client.pem\" SSLProxyCACertificateFile \"/etc/apache2/KEYS/ca.x509\" <Location / > <RequireAll> Require ssl Require ssl-verify-client Require valid-user Require expr (%{REMOTE_USER} == %{SSL_CLIENT_S_DN_CN} ) && (-n %{REMOTE_USER}) </RequireAll> AuthType Basic AuthName \"Apache Level\" AuthBasicProvider external AuthExternal dea AuthBasicAuthoritative on ProxyPass \"https://drucomp2.test:444/\" ProxyPassReverse \"https://drucomp2.test:444/\" </Location> SSLProxyCheckPeerCN On SSLProxyCheckPeerName on SSLProxyVerify require SSLProxyEngine on SSLOptions +StrictRequire SSLVerifyClient require </VirtualHost> <VirtualHost 127.0.0.1:444 > CustomLog \"/var/log/apache2/debug_jm_core.log\" \"REMOTE_USER: %{REMOTE_USER}x SUBJECT_CN:%{SSL_CLIENT_S_DN_CN}x --- %v %h %l %u %t \\\"%r\\\" %>s %b\" LogLevel debug DocumentRoot /home/ubuntu/DRUPAL_COMPOSER2 ServerName drucomp2.test php_admin_value sendmail_path \"/usr/bin/env catchmail -f test@mailcatcher.test\" php_admin_value CIVICRM_DB_CACHE_CLASS NoCache <Directory /home/ubuntu/DRUPAL_COMPOSER2 > SSLRequireSSL Require all granted AllowOverride All </Directory> SSLEngine on SSLCACertificateFile \"/etc/apache2/KEYS/ca.x509\" SSLCertificateFile \"pkcs11:model=SoftHSM%20v2;manufacturer=SoftHSM%20project;serial=75bb53774ddd60dc;token=serverhsm;object=servercert;type=cert\" SSLCertificateKeyFile \"pkcs11:model=SoftHSM%20v2;manufacturer=SoftHSM%20project;serial=75bb53774ddd60dc;token=serverhsm;object=serverkey;type=private\" SSLCipherSuite HIGH:!aNULL:!MD5 SSLOptions +StrictRequire #SSLVerifyClient require </VirtualHost> Prise en charge HSM au niveau du navigateur Firefox, dans ses pr\u00e9f\u00e9rences, dispose d\u2019un bouton pour appeler une interface de gestion des p\u00e9riph\u00e9riques de s\u00e9curit\u00e9. Il suffit ensuite de pr\u00e9ciser les modules d\u2019interfa\u00e7age PKCS11 \u00e0 charger (par exemple /usr/lib/arm-linux-gnueabihf/softhsm/libsofthsm2.so ou /usr/lib/arm-linux-gnueabihf/libykcs11.so ). Ensuite, les certificats sont rendus disponibles du moment que l\u2019utilisateur se connecte aux tokens. En ce qui concerne chromium, la situation est plus compliqu\u00e9e : en th\u00e9orie, chromium chercherait des informations dans une base NSS situ\u00e9e dans $HOME/.pki/nssdb. Cette base peut \u00eatre g\u00e9r\u00e9e par l\u2019utilitaire modutil (package libnss3-tools), pour demander \u00e0 chromium de charger les m\u00eames modules que ceux pr\u00e9sent\u00e9s \u00e0 firefox. N\u00e9anmoins, la version de chromium livr\u00e9e avec Ubuntu est une version dans le format \u00ab snap \u00bb ; et le package, tel que configur\u00e9, ne permet pas d\u2019acc\u00e9der au r\u00e9pertoire nssdb. Ce probl\u00e8me est r\u00e9pertori\u00e9 chez Ubuntu ( https://bugs.launchpad.net/ubuntu/+source/chromium-browser/+bug/1899478 et https://bugs.launchpad.net/ubuntu/+source/chromium-browser/+bug/1859643 ). De plus, le montage de l\u2019interface home dans un snap devrait se limiter aux fichiers non cach\u00e9s (donc qui ne commence pas par un point ) ; du coup, cela rend le probl\u00e8me plus difficile \u00e0 r\u00e9soudre, car le chemin de la BD NSS semble \u00eatre en dur dans le code de chromium ( https://github.com/chromium/chromium/blob/master/crypto/nss_util.cc ). En conclusion, on remarque que les b\u00e9n\u00e9fices de l\u2019identification par certificat peuvent \u00eatre appr\u00e9ciables, mais que ces b\u00e9n\u00e9fices ne peuvent \u00eatre acquis qu\u2019en mettant les ressources techniques, humaines, et mat\u00e9rielles en face. Enfin, on n\u2019oubliera pas que l\u2019authentification par certificat peut \u00e9galement \u00eatre mise en \u0153uvre dans certaines solutions VPN, ce qui signifie que cette technologie peut servir \u00e0 plusieurs niveaux. Des recherches compl\u00e9mentaires sur la gestion de CA et sur les VPN (au sens large) pourraient donc \u00eatre judicieuses. Addendum : mise en cache de l'authentification L'int\u00e9gration de l'authentification issue de Drupal avec Apache est co\u00fbteuse : pour toute requ\u00eate envoy\u00e9e au reverse-proxy, deux requ\u00eates peuvent \u00eatre envoy\u00e9es au serveur web interne : la requ\u00eate pour v\u00e9rifier les identifiants si l'authentification est valide, la requ\u00eate de base pour effectuer le travail proprement dit. En pratique, le maquettage a montr\u00e9 que ce syst\u00e8me est particuli\u00e8rement impactant pour le bon fonctionnement du syst\u00e8me, car il ne faut pas oublier que toute ressource va \u00eatre soumise \u00e0 authentification - dont les images. Il arrive donc que plus de resources soient n\u00e9cessaires pour l'authentification que pour le travail demand\u00e9. Il ne faut par ailleurs pas oublier que dans le cadre d'un d\u00e9ploiement \u00e0 grande \u00e9chelle, cette consommation de ressources va impliquer plus de ressources n\u00e9cessaires au fonctionnement du syst\u00e8me, et donc des co\u00fbts plus importants. Il s'av\u00e8re que mod_authnz_external dispose d'un n\u00e9cessaire pour utiliser mod_authn_socache pour disposer d'un cache d'identifiants. Le cache utilis\u00e9 peut par exemple \u00eatre mod_socache_shmcb , qui va stocker les identifiants dans de la m\u00e9moire partag\u00e9e. V\u00e9rification faite dans le code de authnz_external , une fonction de la libapr est utilis\u00e9e pour g\u00e9n\u00e9rer l'entr\u00e9e en cache. Au niveau du cache, ce sera une empreinte SHA1 qui va \u00eatre stock\u00e9e. La libapr permettrait quatre types d'identifiants : en clair bcrypt md5 sha1 L'utilisation de SHA1 n'est plus consid\u00e9r\u00e9e comme s\u00fbre,ce qui am\u00e8ne \u00e0 d\u00e9conseiller l'utilisation du cache \u00e0 cause de ce stockage du mot de passe. Toutefois, si l'authentification r\u00e9alis\u00e9e est une authentification \u00e0 facteurs multiples (dont une authentification forte), on pourrait toutefois consid\u00e9rer que l'importante du mot de passe n'est plus aussi forte, et que le risque devient un peu plus acceptable - m\u00eame si une d\u00e9cision politique doit clairement \u00eatre prise \u00e0 ce sujet avant mise en production. En ce qui concerne la mise en cache de l'authentification, on peut consid\u00e9rer l'exemple suivant : AuthnCacheEnable on AuthnCacheSOCache shmcb <VirtualHost 0.0.0.0:443 > ServerName ${SERVERNAME} AddExternalAuth dea \"/AUTH/externalauth.sh\" SetExternalAuthMethod dea pipe SSLEngine on SSLCertificateFile ${SERVER_CERT} SSLCertificateKeyFile ${SERVER_KEY} SSLCipherSuite HIGH:!aNULL:!MD5 SSLOptions +StrictRequire SSLProxyVerify require SSLProxyMachineCertificateFile ${PROXY_MACHINE_CERT} SSLProxyCACertificateFile ${PROXY_CA} SSLProxyCheckPeerCN on SSLProxyCheckPeerName on SSLProxyVerify require SSLProxyEngine on SSLOptions +StrictRequire SSLVerifyClient none <Location \"/\" > AuthExternalContext ${AUTH_CONTEXT} <RequireAll> Require ssl Require valid-user </RequireAll> AuthType Basic AuthName \"Civiparoisse\" AuthBasicProvider socache external AuthnCacheProvideFor external AuthExternalProvideCache on AuthnCacheContext server AuthnCacheTimeout 300 AuthExternal dea AuthBasicAuthoritative on </Location> ProxyPass \"/\" \"https://${INTERN_SERVERNAME}:444/\" </VirtualHost> On constate la directive AuthExternalProvideCache qui va demander \u00e0 authnz_external de remplir le cache, et on constate qu'on a un provider d'authentification suppl\u00e9mentaire : socache, avec un timeout de 300secondes. Le contexte va agir sur la clef. On a encore deux directives globales qui d\u00e9finissent le backend de cache utilis\u00e9, et l'activation du cache.","title":"Authentification"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#etude-authentification-apache-civicrm","text":"L\u2019authentification de CiviCRM peut correspondre \u00e0 deux notions, qui ne se recoupent pas forc\u00e9ment : l\u2019utilisateur qui est logu\u00e9 dans le CMS : on se base alors sur les m\u00e9canismes du CMS, qui peuvent \u00eatre diff\u00e9rents en fonction des CMS le contact enregistr\u00e9 dans le CRM : ce protocole permet \u00e9galement de reconna\u00eetre comme utilisateur CiviCRM un contact. Par ailleurs, Authx dispose \u00e9galement d\u2019une page qui expose l\u2019identification de l\u2019utilisateur courant (/civicrm/authx/id), page qui a \u00e9galement l\u2019avantage d\u2019\u00eatre l\u00e9g\u00e8re \u00e0 charger. Dans le cadre du projet CiviParoisse, il n\u2019est pas souhaitable, pour des questions de s\u00e9curit\u00e9 et de confidentialit\u00e9 des donn\u00e9es, qu\u2019un contact sans compte dans le CMS puisse interagir avec le CRM. Il s\u2019agira donc de faire en sorte que seuls les utilisateurs logu\u00e9s dans le CMS puissent avoir un acc\u00e8s au syst\u00e8me. L\u2019acc\u00e8s au CMS devra d\u2019ailleurs \u00eatre compris de mani\u00e8re assez large : en effet, si on consid\u00e8re des documents qui sont stock\u00e9s sous formes de fichiers directement accessibles via Apache, le CMS ne sera pas charg\u00e9 pour l\u2019acc\u00e8s \u00e0 ces fichiers et donc le contr\u00f4le d\u2019acc\u00e8s que pourrait effectuer le CMS ne se fera pas. Or, les contr\u00f4les sont \u00e9galement requis sur ces fichiers. Il s\u2019agit donc d\u2019effectuer une authentification directement au niveau du serveur web. Pour autant, le processus doit rester simple pour les utilisateurs finaux : il s\u2019agit donc de ne pas leur demander de retenir trop de mots de passe : il faut donc que l\u2019authentification effectu\u00e9e au niveau de Apache puisse \u00eatre propag\u00e9e au CMS. Toutefois, \u00e9tant donn\u00e9 que les utilisateurs pourraient choisir des mots de passe simple (ou les \u00e9crire sur des morceaux de papier), il convient de proposer une authentification \u00e0 2 facteurs, par exemple en se basant non seulement sur une connaissance (le mot de passe), mais \u00e9galement une possession (un certificat SSL, voire un token de s\u00e9curit\u00e9). Le travail \u00e0 effectuer est donc assez complexe, et a n\u00e9cessit\u00e9 des recherches pouss\u00e9es. Ce travail peut se diviser en deux parties, l\u2019une concernant l\u2019authentification par mot de passe, et l\u2019autre concernant l\u2019authentification par certificat SSL et HSM ; en revanche, il faudra \u00e9galement veiller \u00e0 la correspondance des identit\u00e9s entre les deux m\u00e9thodes (ne pas autoriser le certificat d\u2019un utilisateur A et le mot de passe d\u2019un utilisateur B lors d\u2019un seul login).","title":"Etude : Authentification Apache / CiviCRM"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#authentification-par-mot-de-passe","text":"","title":"Authentification par mot de passe"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#le-choix-du-cms-drupal","text":"L\u2019authentification par mot de passe est g\u00e9r\u00e9e par le CMS. CiviCRM propose un support de 4 CMS (Drupal, Backdrop, Wordpress et Joomla). Ces CMS proposent tous nativement une authentification par nom d\u2019utilisateur et mot de passe, avec un hash sal\u00e9 du mot de passe stock\u00e9 en base de donn\u00e9es. De la sorte, si la base de donn\u00e9es fuite, les mots de passe ne sont pas pour autant pr\u00e9sents, car les fonctions de hash cherchent \u00e0 \u00eatre des fonctions \u00e0 sens unique qui ne permettent pas de pr\u00e9dire des collisions de hashes (lorsque cela arrive, la fonction ne peut plus \u00eatre utilis\u00e9e comme fonction de s\u00e9curit\u00e9). Les fonctions de hashes utilis\u00e9es peuvent diff\u00e9rer, mais il semble que la plupart des CMS supportent les hashes calcul\u00e9s par le code du projet phpass ( https://www.openwall.com/phpass/ ). On notera toutefois que la page du projet indique qu\u2019il faudrait pr\u00e9f\u00e9rer l\u2019utilisation des fonctions natives de PHP 5.5 et ult\u00e9rieur. M\u00eame si l\u2019on observe une certaine unicit\u00e9 de mani\u00e8re de faire chez les CMS support\u00e9s, la n\u00e9cessit\u00e9 de d\u00e9finir le CMS qui sera utilis\u00e9 arrive quand m\u00eame rapidement, puisqu\u2019il s\u2019agira d\u2019impl\u00e9menter un SSO entre le serveur web et le CMS. Les recherches effectu\u00e9es ont conduit \u00e0 privil\u00e9gier Drupal, pour plusieurs raisons : les recherches sur les proc\u00e9dures d\u2019installation ont montr\u00e9 l\u2019int\u00e9r\u00eat, pour l\u2019automatisation de l\u2019installation et la mise \u00e0 jour des syst\u00e8mes, de disposer d\u2019un gestionnaire de versions. Or, CiviCRM utilise Composer, qui est \u00e9galement utilis\u00e9 par Drupal. A l\u2019inverse, Backdrop et Wordpress ne semblent pas int\u00e9grer officiellement la gestion des d\u00e9pendances via Composer. Au niveau de Joomla, le support de Composer est souhait\u00e9 et int\u00e9gr\u00e9 dans la feuille de route, mais n\u2019est pas encore atteint. Drupal utilise le framework Symfony, et ce framework dispose d\u2019un support d\u2019authentification HTTP Basic : le syst\u00e8me int\u00e8gre donc d\u00e9j\u00e0 des composants qui faciliteront le SSO entre le serveur web et le CMS le projet CiviParoisse est historiquement bas\u00e9 sur le CMS Drupal ; les b\u00e9n\u00e9voles qui travaillent sur les aspects techniques ont de ce fait cherch\u00e9 \u00e0 remonter en local des instances Drupal + CiviCRM, d\u2019o\u00f9 une \u00e9ventuelle r\u00e9utilisation ou mont\u00e9e en comp\u00e9tences sur ce CMS il semblerait que CiviCRM ait des affinit\u00e9s avec Drupal (comme par exemple les conventions de code qui ont \u00e9t\u00e9 r\u00e9utilis\u00e9es).","title":"Le choix du CMS : Drupal"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#le-choix-du-serveur-web-apache","text":"Le choix du serveur web est \u00e9galement un choix important, car il en existe un grand nombre (Apache, Nginx, Jetty, Lighttpd pour ne citer qu\u2019eux). Apache est le serveur web qui est traditionnellement employ\u00e9 \u00ab par d\u00e9faut \u00bb dans les sites web PHP (stack LAMP ou WAMP, avec A pour Apache), et de ce fait est susceptible d\u2019\u00eatre mieux connu par les b\u00e9n\u00e9voles que les autres solutions. De ce fait, m\u00eame si d\u2019autres serveurs pourraient \u00e9ventuellement \u00eatre employ\u00e9s, la recherche s\u2019est concentr\u00e9e sur l\u2019interfa\u00e7age avec Apache. Toutefois, si le besoin se fait sentir, on pourra chercher \u00e0 se tourner vers d\u2019autres solutions (dont Nginx).","title":"Le choix du serveur web : Apache"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#strategie-dinterfacage","text":"La strat\u00e9gie d\u2019interfa\u00e7age va chercher \u00e0 utiliser au maximum les codes existants pour d\u00e9velopper (et maintenir) un minimum de m\u00e9canismes sp\u00e9cifiques. De ce fait, deux axes vont \u00eatre mis en \u0153uvre : la consommation des identifiants pr\u00e9sent\u00e9s par Apache \u00e0 Drupal pour disposer d\u2019un m\u00e9canisme SSO. la mise \u00e0 disposition \u00e0 Apache d\u2019un m\u00e9canisme de validation des donn\u00e9es d\u2019authentification, m\u00e9canisme fourni par Drupal ou CiviCRM (authx)","title":"Strat\u00e9gie d\u2019interfa\u00e7age"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#consommation-des-identifiants-presentes-par-apache-a-drupal","text":"La consommation des donn\u00e9es d\u2019authentification pr\u00e9sent\u00e9es par Apache \u00e0 du code PHP est assez standardis\u00e9e : traditionnellement, le serveur Apache peut fournir une variable d\u2019environnement REMOTE_USER pour indiquer l\u2019identifiant d\u2019un utilisateur, si l\u2019authentification a \u00e9t\u00e9 effectu\u00e9e au niveau d\u2019Apache. Lorsqu\u2019il s\u2019agit d\u2019une authentification de type HTTP Basic, les donn\u00e9es sont pr\u00e9sent\u00e9es \u00e9galement \u00e0 PHP via les variables $_SERVER['PHP_AUTH_USER'] et $_SERVER[\u2018PHP_AUTH_PW\u2019] . Comme on le verra plus tard, Apache n\u2019est pas en mesure de v\u00e9rifier de fa\u00e7on autonome les donn\u00e9es d\u2019identification, et devra se reposer sur Drupal et PHP pour faire le travail via de l\u2019authentification de type HTTP Basic. Cette authentification de type HTTP Basic sera transmise avec chaque requ\u00eate de page. Le HTTP Basic est support\u00e9 via Symfony, mais n\u2019est pas consid\u00e9r\u00e9 comme une m\u00e9thode d\u2019authentification globale (utilisable tout le temps par d\u00e9faut, \u00e0 l\u2019inverse de l\u2019authentification par cookie). Il s\u2019agit donc au niveau de Drupal de cr\u00e9er un petit module qui permet d\u2019injecter le fournisseur HTTP Basic comme un fournisseur global via un fichier .services.yml : services : basic_auth.authentication.basic_auth : class : Drupal\\basic_auth\\Authentication\\Provider\\BasicAuth arguments : [ '@config.factory' , '@user.auth' , '@flood' , '@entity_type.manager' ] tags : - { name : authentication_provider , provider_id : 'basic_auth' , priority : 100 , global : TRUE } C\u2019est le seul r\u00e9glage \u00e0 effectuer pour consommer les donn\u00e9es. Si les donn\u00e9es d\u2019authentification ne sont pas juste, une erreur de type 4XX est renvoy\u00e9e. En revanche, il reste \u00e0 la charge d\u2019Apache de toujours envoyer les donn\u00e9es d\u2019identification pour qu\u2019elles soient consomm\u00e9es (le header HTTP Authorization : Basic devra \u00eatre pr\u00e9sent dans toutes les requ\u00eates), sans quoi un code 200 pourrait \u00eatre renvoy\u00e9 \u00e0 tort.","title":"Consommation des identifiants pr\u00e9sent\u00e9s par Apache \u00e0 Drupal"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#mise-a-disposition-des-donnees-dauthentification","text":"Apache s\u00e9pare conceptuellement le processus d\u2019authentification en deux, \u00e0 savoir les m\u00e9canismes permettant de r\u00e9cup\u00e9rer les donn\u00e9es d\u2019identification fournies par un navigateur web d\u2019une part, et la comparaison avec des fournisseurs d\u2019authentification d\u2019autre part.","title":"Mise \u00e0 disposition des donn\u00e9es d\u2019authentification"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#fournisseur-authnz-external","text":"En ce qui concerne le fournisseur d\u2019authentification, Apache propose plusieurs m\u00e9thodes. Malheureusement, aucune m\u00e9thode \u00ab native \u00bb ne convient, car la m\u00e9thode reposant sur l\u2019exploitation d\u2019une base de donn\u00e9es suppose la connaissance de la m\u00e9thode de hash pour que le hash puisse \u00eatre calcul\u00e9 sur les donn\u00e9es brutes. En ce qui concerne le support FastCGI, bien que celui-ci soit s\u00e9duisant sur le papier, le support FastCGI propos\u00e9 par php (php-cgi) et par fpm (php-fpm) n\u2019a pas permis d\u2019obtenir un fonctionnement tel qu\u2019un script d\u00e9fini sur la ligne de commande soit ex\u00e9cut\u00e9 et que le fastcgi ne soit utilis\u00e9 que pour fournir les donn\u00e9es d\u2019authentification. Il aurait donc fallu se tourner vers d\u2019autres impl\u00e9mentations FastCGI, ce qui aurait suppos\u00e9 des d\u00e9veloppements et donc la maintenance de ces d\u00e9veloppements. En revanche, il existe un fournisseur tiers qui est le module authnz_external . Ce module tiers est disponible directement dans les packages de Ubuntu LTS, et de ce fait son support est assur\u00e9 via la distribution. Ce module permet l\u2019ex\u00e9cution d\u2019un programme externe, auquel on peut fournir parplusieurs moyens les donn\u00e9es d\u2019identification. Le module utilisera le code de retour du programme pour d\u00e9terminer si l\u2019authentification a r\u00e9ussi (code de retour \u00e0 z\u00e9ro) ou \u00e9chou\u00e9 (code de retour diff\u00e9rent de z\u00e9ro). Comme on l\u2019a vu pr\u00e9c\u00e9demment dans le SSO d\u2019Apache vers Drupal, en envoyant une requ\u00eate HTTP vers Drupal avec de l\u2019authentification Basic fournira un code de retour qui indiquera si l\u2019authentification a r\u00e9ussi ou non. Il va donc s\u2019agir d\u2019utiliser un programme tiers pour r\u00e9cup\u00e9rer les identifiants, effectuer la requ\u00eate, et renvoyer le bon code de retour, en s\u2019assurant que l\u2019identifiant et le mot de passe soient toujours sett\u00e9s dans la requ\u00eate.","title":"Fournisseur Authnz External"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#script-shell-principal-wget-script-askpass","text":"La commande wget est une commande d\u2019utilisation assez commune, qui permet d\u2019effectuer en particulier une requ\u00eate HTTP. Cette commande supporte le HTTPS (en authentification et en v\u00e9rification du certificat serveur), et propose via l\u2019option \u2013use-askpass l\u2019utilisation d\u2019un programme \u00ab askpass \u00bb tiers pour fournir les informations d\u2019identification via STDOUT (une ex\u00e9cution du programme tiers pour le nom d\u2019utilisateur, une autre pour le mot de passe). Charge au programme askpass de r\u00e9cup\u00e9rer le mot de passe, de v\u00e9rifier sa longueur, et de le retransmettre via STDOUT s\u2019il est non vide. Ce programme askpass devra soigner son code de retour : 0 si tout va bien ou une valeur diff\u00e9rente s\u2019il y a un probl\u00e8me. D\u2019apr\u00e8s mes tests, le code de retour de askpass est pris en compte par wget, et s\u2019il est diff\u00e9rent de 0, wget r\u00e9agira \u00e9galement dans son code de retour . Ce point est d\u2019ailleurs plus ou moins confirm\u00e9 par la lecture du code source et l\u2019exemple dans la page man de posix_spawnp (utilis\u00e9 pour lancer le programme) : //Code source wget : main.c : argv [ 0 ] = opt . use_askpass ; argv [ 1 ] = question ; argv [ 2 ] = NULL ; status = posix_spawnp ( & pid , opt . use_askpass , & fa , NULL , argv , environ ); if ( status ) { fprintf ( stderr , \"Error spawning %s: %d \\n \" , opt . use_askpass , status ); exit ( WGET_EXIT_GENERIC_ERROR ); } Exemple dans la man page: The program below demonstrates the use of various functions in the POSIX spawn API. The program accepts command-line attributes that can be used to create file actions and attributes objects. The remaining command-line arguments are used as the executable name and command-line arguments of the program that is executed in the child. In the first run, the date(1) command is executed in the child, and the posix_spawn() call employs no file actions or attributes objects. $ ./a.out date PID of child: 7634 Tue Feb 1 19:47:50 CEST 2011 Child status: exited, status=0 In the next run, the -c command-line option is used to create a file actions object that closes standard output in the child. Consequently, date(1) fails when trying to perform output and exits with a status of 1. $ ./a.out -c date PID of child: 7636 date: write error: Bad file descriptor Child status: exited, status=1 Par ailleurs, wget permet via l\u2019option \u2013auth-no-challenge d\u2019envoyer directement l\u2019authentification HTTP Basic sans requ\u00e9rir le challenge initial : ce point est tr\u00e8s important,dans la mesure o\u00f9 une page sans authentification pourrait renvoyer \u00e9galement du code 200, comme vu pr\u00e9c\u00e9demment dans l\u2019impl\u00e9mentation SSO. On se souviendra qu\u2019\u00e9tant donn\u00e9 qu\u2019Unix cr\u00e9e des processus par fork, les descripteurs de fichiers disponibles dans un processus p\u00e8re sont \u00e9galement dupliqu\u00e9s dans un processus fils au niveau du fork. En l\u2019occurence, mod_authnz_external permet de transmettre via la m\u00e9thode \u00ab pipe \u00bb les donn\u00e9es via STDIN, et le fork effectu\u00e9 par mod_authnz_external, puis le script shell principal, puis par le script wget font que le script askpass pourra lire chaque donn\u00e9e sur STDIN. Cette mani\u00e8re de faire a un gros avantage : les donn\u00e9es d\u2019identification ne seront pas pr\u00e9sentes dans l\u2019environnement des applications, et de ce fait ne peuvent pas \u00eatre r\u00e9cup\u00e9r\u00e9es aussi facilement que via de l\u2019ex\u00e9cution de commande ps ou des balades dans /proc. On en arrive donc aux \u00e9bauches suivantes : #!/bin/bash # Script shell Askpass : read -s t if test -n \" $t \" then echo \" $t \" exit 0 else exit 1 fi #!/bin/bash #Script shell Principal : wget -d --use-askpass=\"/home/ubuntu/DRUPAL_COMPOSER2/AUTH/askpass.sh\" --auth-no-challenge -- certificate=\"/etc/apache2/KEYS/server.x509\" --private-key=\"/etc/apache2/KEYS/server.key\" --ca- certificate=\"/etc/apache2/KEYS/ca.x509\" https://drucomp2.test:444/civicrm/authx/id -O /dev/null exit $? Bien entendu, ces scripts peuvent encore \u00eatre am\u00e9lior\u00e9s (par exemple v\u00e9rifier le code de retour des read), rendus plus g\u00e9n\u00e9riques pour l\u2019installation automatique, utiliser des clefs sp\u00e9cifiques\u2026","title":"Script shell principal, wget, script askpass"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#cible-pour-lauthentification-authx","text":"A vrai dire, n\u2019importe quelle page authentifi\u00e9e pourrait faire l\u2019affaire en tant que cible (du moment qu\u2019elle ne modifie pas le syst\u00e8me). Pour autant, j\u2019ai vu deux cibles plus int\u00e9ressantes que les autres, en raison des informations qu\u2019elles peuvent fournir pour du d\u00e9bogage ; en effet, elles indiquent toutes les deux si l\u2019utilisateur est logu\u00e9 : civicrm/authx/id : int\u00e9gr\u00e9 dans CiviCRM user/login_status?_format=xml : int\u00e9gr\u00e9 dans Drupal. L\u2019int\u00e9r\u00eat de authx est qu\u2019il fournit des informations suppl\u00e9mentaires par rapport \u00e0 l\u2019\u00e9ventuel contact associ\u00e9 \u00e0 l\u2019utilisateur. En outre, il faut configurer authx, en fonction des indications donn\u00e9es dans le guide du d\u00e9veloppeur CiviCRM : cv.phar ev 'Civi::settings()->set(\"authx_guards\",[\"perm\"]);' cv.phar ev 'Civi::settings()->set(\"authx_param_cred\",[]);' cv.phar ev 'Civi::settings()->set(\"authx_param_user\",\"require\");' cv.phar ev 'Civi::settings()->set(\"authx_header_cred\",[\"pass\"]);' cv.phar ev 'Civi::settings()->set(\"authx_header_user\",\"require\");' cv.phar ev 'Civi::settings()->set(\"authx_xheader_cred\",[]);' cv.phar ev 'Civi::settings()->set(\"authx_xheader_user\",\"require\");' cv.phar ev 'Civi::settings()->set(\"authx_login_cred\",[]);' cv.phar ev 'Civi::settings()->set(\"authx_login_user\",\"require\");' cv.phar ev 'Civi::settings()->set(\"authx_auto_cred\",[]);' cv.phar ev 'Civi::settings()->set(\"authx_auto_user\",\"require\");'","title":"Cible pour l\u2019authentification : authx"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#configuration-apache-mise-en-uvre-dun-reverse-proxy-et-authentification-a-deux-facteurs-ssl-et-basic","text":"Les tests ont montr\u00e9 tr\u00e8s rapidement un probl\u00e8me \u00e0 r\u00e9soudre lorsqu\u2019on utilise qu\u2019un seul site : si Apache cherche \u00e0 s\u2019interroger lui-m\u00eame sur la validit\u00e9 d\u2019une page, on arrive \u00e0 une boucle r\u00e9cursive qui fait exploser le nombre de requ\u00eates wget, et la requ\u00eate ne peut donc pas aboutir. Le moyen le plus simple pour r\u00e9gler ce probl\u00e8me est de faire reposer l\u2019authentification SSO non pas directement sur le virtualhost de Drupal, mais plut\u00f4t sur un reverse proxy se pla\u00e7ant en amont : il suffit par exemple d\u2019ouvrir un autre port pour le virtualhost de Drupal, mais sur 127.0.0.1, de sorte \u00e0 ce que le virtualhost ne soit pas directement accessible depuis l\u2019ext\u00e9rieur (par exemple : 127.0.0.1:444/tcp). Le reverse proxy, lui, va \u00e9couter sur 0.0.0.0:443/tcp. Cette configuration, outre le fait de r\u00e9gler le probl\u00e8me de boucle, pourrait \u00e9galement se r\u00e9v\u00e9ler utile pour isoler le p\u00e9rim\u00e8tre d\u2019un probl\u00e8me : en effet, un administrateur pourra \u00e9ventuellement faire du port forwarding via SSH pour acc\u00e9der \u00e0 distance au port 444 si n\u00e9cessaire (\u00e0 condition qu\u2019il se connecte \u00e0 distance \u00e0 la machine). On peut \u00e9ventuellement chercher \u00e0 limiter cette possibilit\u00e9 en instaurant une authentification par certificat entre le reverse proxy et le virtualhost drupal. Par ailleurs, le fait d\u2019utiliser du SSL pour cette connexion interne permet \u00e9galement d\u2019\u00e9viter de laisser circuler en clair des mots de passe qui pourraient \u00eatre captur\u00e9s via tcpdump par exemple. Un autre type de solution technique qui aurait fait \u00e9galement l\u2019affaire aurait \u00e9t\u00e9 de l\u2019IPSEC en mode transport : n\u00e9anmoins, il semble plus maintenable d\u2019utiliser du SSL, tout simplement car des connaissances sur ce sujet sont plus ou moins d\u00e9j\u00e0 exig\u00e9es du fait de la n\u00e9cessit\u00e9 actuelle de la mise en \u0153uvre de HTTPS. On en arrive \u00e0 une \u00e9bauche de configuration telle que suit. Cette \u00e9bauche pourra \u00eatre am\u00e9lior\u00e9e en d\u00e9diant une autorit\u00e9 de certification d\u2019une part aux connexions des clients vers le reverse proxy et d\u2019autre part \u00e0 la connexion entre le reverse proxy et le vhost Drupal. Listen 127.0.0.1 :444 <VirtualHost 127.0.0.1:443 > #LogLevel debug #CustomLog \"/var/log/apache2/debug_jm.log\" \"REMOTE_USER: %{REMOTE_USER}x {SSL_CLIENT_S_DN_CN}x --- %v %h %l %u %t \\\"%r\\\" %>s %b\" ServerName drucomp2.test AddExternalAuth dea \"/home/ubuntu/DRUPAL_COMPOSER2/AUTH/externalauth.sh\" SetExternalAuthMethod dea pipe SSLEngine on SSLCACertificateFile \"/etc/apache2/KEYS/ca.x509\" SSLCertificateFile \"/etc/apache2/KEYS/drucomp2.x509\" SSLCertificateKeyFile \"/etc/apache2/KEYS/drucomp2.pem\" SSLCipherSuite HIGH:!aNULL:!MD5 SSLOptions +StrictRequire SSLProxyVerify require SSLProxyMachineCertificateFile \"/etc/apache2/KEYS/proxy_client.pem\" SSLProxyCACertificateFile \"/etc/apache2/KEYS/ca.x509\" <Location / > <RequireAll> Require ssl Require ssl-verify-client Require valid-user Require expr (%{REMOTE_USER} == %{SSL_CLIENT_S_DN_CN} ) && (-n %{REMOTE_USER}) </RequireAll> AuthType Basic AuthName \"Apache Level\" AuthBasicProvider external AuthExternal dea AuthBasicAuthoritative on ProxyPass \"https://drucomp2.test:444/\" ProxyPassReverse \"https://drucomp2.test:444/\" </Location> SSLProxyCheckPeerCN On SSLProxyCheckPeerName on SSLProxyVerify require SSLProxyEngine on SSLOptions +StrictRequire SSLVerifyClient require </VirtualHost> <VirtualHost 127.0.0.1:444 > #LogLevel debug DocumentRoot /home/ubuntu/DRUPAL_COMPOSER2 ServerName drucomp2.test php_admin_value sendmail_path \"/usr/bin/env catchmail -f test@mailcatcher.test\" php_admin_value CIVICRM_DB_CACHE_CLASS NoCache <Directory /home/ubuntu/DRUPAL_COMPOSER2 > SSLRequireSSL Require all granted AllowOverride All </Directory> SSLEngine on SSLCACertificateFile \"/etc/apache2/KEYS/ca.x509\" SSLCertificateFile \"/etc/apache2/KEYS/drucomp2.x509\" SSLCertificateKeyFile \"/etc/apache2/KEYS/drucomp2.pem\" SSLCipherSuite HIGH:!aNULL:!MD5 SSLOptions +StrictRequire SSLVerifyClient require </VirtualHost> Cette configuration pr\u00e9sente par ailleurs d\u00e9j\u00e0 une configuration pour forcer une authentification par certificat SSL, avec une v\u00e9rification particuli\u00e8re : la v\u00e9rification de la correspondance entre l\u2019utilisateur authentifi\u00e9 via mod_external ( dans REMOTE_USER ) et le common name du distinguished name du certificat SSL du client ( SSL_CLIENT_S_DN_CN ). A nouveau, on prend la pr\u00e9caution de v\u00e9rifier que l\u2019identifiant n\u2019est pas vide, m\u00eame si cela ne devrait pas arriver vu les pr\u00e9cautions prises dans le askpass. A l\u2019usage, avec les caches d\u00e9sactiv\u00e9s, on constate imm\u00e9diatement une grosse augmentation de charge syst\u00e8me lors de la mise en \u0153uvre : en effet, pour toute requ\u00eate entrante, il y a en r\u00e9alit\u00e9 trois requ\u00eates ex\u00e9cut\u00e9es (requ\u00eate entrante, requ\u00eate d\u2019autorisation, requ\u00eate de traitement). Il faut voir que cette configuration emp\u00eache \u00e9galement certaines mises en cache au niveau de Drupal, mises en caches qui sont interdites nativement en raison de l\u2019authentification basique.","title":"Configuration Apache : mise en \u0153uvre d\u2019un reverse proxy et authentification \u00e0 deux facteurs (SSL et basic)"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#authentification-par-clef-privee-et-certificat-ssl-sur-hsm","text":"L\u2019authentification par clef priv\u00e9e et certificat SSL sur Hardware Security Module est un moyen pour fournir une authentification mat\u00e9rielle, dans la mesure o\u00f9, en g\u00e9n\u00e9ral, les modules de s\u00e9curit\u00e9 permettent de g\u00e9n\u00e9rer des clefs priv\u00e9es, mais ne permettent pas de les exporter (certains modules permettent toutefois une sauvegarde chiffr\u00e9e de la clef priv\u00e9e). Le module peut prendre plusieurs formes, dont usuellement la forme d\u2019un token USB, similaire \u00e0 une clef USB. Les fonctionnalit\u00e9s qui seront utilis\u00e9es sur ces clefs sont les fonctionnalit\u00e9s PIV (Personnal Identity Verification). G\u00e9n\u00e9ralement, les constructeurs de telles clefs fournissent des API pour acc\u00e9der au mat\u00e9riel, qui impl\u00e9mentent le support de PKCS11. C\u2019est justement sur la mise en \u0153uvre de PKCS11 dans le serveur web que va reposer en grande partie l\u2019authentification par clef, \u00e0 la place des fichiers de clefs.","title":"Authentification par clef priv\u00e9e (et certificat SSL) sur HSM"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#une-contrainte-lourde-la-gestion-dune-autorite-de-certification","text":"Cette authentification par clef et certificat suppose une gestion des clefs rigoureuse, et implique une contrainte relativement forte : la mise en \u0153uvre d\u2019une infrastructure \u00e0 clefs publiques (Public Key Infrastructure). Cette infrastructure suppose au minimum la pr\u00e9sence d\u2019une autorit\u00e9 de certification (CA) qui est un tiers de confiance qui va attester de l\u2019identit\u00e9 li\u00e9e \u00e0 une clef publique. L\u2019autorit\u00e9 de certification doit \u00eatre g\u00e9r\u00e9e de mani\u00e8re rigoureuse pour que la confiance subsiste, et requiert donc la mise en \u0153uvre de processus organisationnels formalis\u00e9s, compris, et accept\u00e9s par toutes les parties. Le travail de l\u2019autorit\u00e9 de certification est non seulement la signature des certificats, mais \u00e9galement la r\u00e9vocation des clefs compromises (Certificate Revocation List, accessible soit sous forme de fichier, soit sous forme de service de r\u00e9pondeur OCSP Online Certificate Status Protocol) ). Ce travail de r\u00e9vocation n\u00e9cessite une disponibilit\u00e9 tr\u00e8s rapide de l\u2019autorit\u00e9, en plus de la coop\u00e9ration des utilisateurs. La mise en \u0153uvre d\u2019une autorit\u00e9 de certification internalis\u00e9e est donc un pr\u00e9requis lourd qu\u2019il ne faut pas sous-estimer. Il existe de la litt\u00e9rature sp\u00e9cialis\u00e9e \u00e0 ce sujet. Il y a \u00e9ventuellement une autre piste compl\u00e9mentaire : s\u2019adresser \u00e0 l\u2019ANSSI (ex : https://www.ssi.gouv.fr/uploads/2015/07/catalogue-cfssi-anssi_2020-2021.pdf ) ou aux services du minist\u00e8re de l\u2019int\u00e9rieur si une \u00ab externalisation \u00bb pourrait \u00eatre envisag\u00e9e.","title":"Une contrainte lourde : la gestion d\u2019une autorit\u00e9 de certification"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#preparation-dun-hsm-deux-exemples","text":"Deux exemples peuvent \u00eatre explor\u00e9s : l\u2019utilisation d\u2019une clef usb Yubikey (ex:Yubikey 4), et l\u2019utilisation d\u2019une impl\u00e9mentation d\u2019\u00e9mulation logicielle : SoftHSM(v2). L\u2019int\u00e9r\u00eat de l\u2019\u00e9mulation est qu\u2019il peut servir \u00e0 mod\u00e9liser les services sur les machines de d\u00e9velopp ement sans disposer de mat\u00e9riel particulier.","title":"Pr\u00e9paration d\u2019un HSM : deux exemples"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#clef-yubikey","text":"L\u2019exemple de la clef Yubikey n\u2019est pas un exemple \u00ab anodin \u00bb, dans la mesure o\u00f9 Yubico ( https://www.yubico.com/?lang=fr ) supporte l\u2019environnement Linux (les packages de gestion des Yubikeys sont disponibles en standard dans Ubuntu) et fournit une documentation sur son site web ( https://developers.yubico.com/PIV/ ). Les prix des clefs sur le site de Yubico semblent accessibles ( https://www.yubico.com/fr/store/ : \u00e0 partir de 45\u20acHT pour une clef). J\u2019ai une clef Yubikey 4 que j\u2019avais achet\u00e9e il y a plusieurs ann\u00e9es pour exp\u00e9rimenter. La premi\u00e8re chose \u00e0 faire serait d\u2019abord de personnaliser les codes d\u2019acc\u00e8s de la clef. Deux codes sont g\u00e9n\u00e9ralement utilisables : le PIN utilisateur et le PIN de l\u2019officier de s\u00e9curit\u00e9 (ou code PUK). Par ailleurs, dans le cadre de la clef Yubikey, personnaliser la clef de Management serait \u00e9galement judicieux (voir https://developers.yubico.com/PIV/Introduction/Admin_access.html ). Je n\u2019ai n\u00e9anmoins pas effectu\u00e9 ces t\u00e2ches. Les fonctionnalit\u00e9s PIV sont g\u00e9r\u00e9es par un outil sp\u00e9cifique : yubico-piv-tool , qui est un outil en ligne de commande. La premi\u00e8re chose est de g\u00e9n\u00e9rer un couple clef publique / clef priv\u00e9e pour l\u2019usage d\u2019authentification. Ces clefs \u00e9tant multi-usages, il convient tout d\u2019abord de d\u00e9terminer l'emplacement m\u00e9moire (slot) qui devra \u00eatre utilis\u00e9, en se r\u00e9f\u00e9rant \u00e0 la documentation ( https://developers.yubico.com/PIV/Introduction/Certificate_slots.html ) : ledit slot est le 9a. L\u2019outil yubico-piv-tool permettrait par ailleurs \u00e9galement de changer pin, puk et clef de management. Un autre outil permet de configurer les fonctionnalit\u00e9s disponibles : ykman , et permet explicitement de lister les p\u00e9riph\u00e9riques et les services activ\u00e9s. yubico-piv-tool -a generate -s 9a -A RSA2048 La commande affiche ensuite la clef publique g\u00e9n\u00e9r\u00e9e. On peut la retrouver via la g\u00e9n\u00e9ration d\u2019une requ\u00eate de certificat, qui est l\u2019\u00e9tape suivante : yubico-piv-tool -a verify-pin -a request-certificate -s 9a -S '/CN=admin/OU=test/O=drucomp2.test' -o cert.req On notera la syntaxe du sujet du certificat, qui utilise des slashes \u00e0 la place des virgules. On peut ensuite signer la requ\u00eate de certificat, comme par exemple avec : openssl x509 -req -in YUBICO/cert.req -out YUBICO/cert.x509 -days 365 -CA ca.x509 -CAkey ca.key -CAserial ca.srl Il n\u2019y a ensuite plus qu\u2019\u00e0 importer le certificat : yubico-piv-tool -s9a -aimport-certificate -i cert.x509 A ce moment, la clef est pr\u00eate pour attester d\u2019une identit\u00e9 \u2013 \u00e0 condition de faire confiance \u00e0 l\u2019autorit\u00e9 de certification qui a sign\u00e9 le certificat.","title":"Clef Yubikey"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#softhsm2","text":"SoftHSM2 permet de fournir une \u00e9mulation de mat\u00e9riel de s\u00e9curit\u00e9, utile pour apprendre. N\u00e9anmoins, le fait que ce soit une \u00e9mulation logicielle a un impact important : les droits sur les fichiers s\u2019appliquent, ce qui n\u2019est pas le cas avec du mat\u00e9riel : ceci a pos\u00e9 probl\u00e8me pour l\u2019acc\u00e8s aux clefs via apache, lorsque www-data n\u2019avait pas les droits sur les fichiers, en lan\u00e7ant une erreur assez g\u00e9n\u00e9rique (object invalid handle). Le d\u00e9buggage de ce probl\u00e8me a n\u00e9cessit\u00e9 l\u2019installation des symboles de d\u00e9buggage d\u2019apache, la modification du nombre de workers (pour passer \u00e0 1), et la r\u00e9cup\u00e9ration des codes sources des librairies (via apt source) pour pouvoir attacher \u00e0 gdb le worker apache et faire du pas \u00e0 pas dans le code source pour arriver jusqu\u2019\u00e0 la source du probl\u00e8me. La mise en \u0153uvre de SoftHSM2 est assez ressemblante \u00e0 celle de la Yubikey. La premi\u00e8re des choses est d\u2019identifier les slots disponibles : softhsm2-util--show-slots De l\u00e0, il faut initialiser les pins de l\u2019utilisateur et du security officer : softhsm2-util --init-token --slot 0 --so-pin 12345678 --pin 123456 --label serverhsm G\u00e9n\u00e9rer la paire de clefs : on utilise pkcs11-tool (package opensc) pkcs11-tool --module /usr/lib/arm-linux-gnueabihf/softhsm/libsofthsm2.so --login --keypairgen --key-type rsa:2048 --usage-sign --token-label serverhsm --label serverkey De l\u00e0, il faut trouver l\u2019URI PKCS11 de la clef utilis\u00e9e : p11tool (package gnutls-bin) : on r\u00e9cup\u00e8re d\u2019abord la liste des tokens, avec leur URI, puis on liste celles du support qui nous int\u00e9resse p11tool --list-tokens p11tool --login --list-all pkcs11:model = SoftHSM%20v2 ; manufacturer = SoftHSM%20project ; serial = 75bb53774ddd60dc ; token = serverhsm G\u00e9n\u00e9rer la requ\u00eate de certificat : openssl req -new -engine pkcs11 -keyform engine -key \"pkcs11:model=SoftHSM%20v2;manufacturer=SoftHSM%20project;serial=75bb53774ddd60dc;token=serverhsm;object=serverkey;type=private\" -subj \"/C=FR/ST=France/L=Strasbourg/O=TEST/OU=INFRA/CN=drucomp2.test\" -out serverhsm.req Il ne reste plus que la signature du certificat : openssl x509 -req -in serverhsm.req -out serverhsm.x509 -extfile ext -ext ext -CA ca.x509 -CAkey ca.key -CAserial ca.srl -sha256 -days 365 Et l\u2019import du certificat : pkcs11-tool --module /usr/lib/arm-linux-gnueabihf/softhsm/libsofthsm2.so serverhsm --label servercert --write-object serverhsm.x509 --type cert --login --token-label Comme indiqu\u00e9 pr\u00e9c\u00e9demment, il faudra faire attention \u00e0 ce que les fichiers soient accessibles par l\u2019utilisateur qui les utilisera.","title":"SoftHSM2"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#mise-en-uvre-du-hsm-pour-les-connexions-web","text":"Le HSM va \u00eatre utilis\u00e9 \u00e0 deux endroits : au niveau du serveur web, et au niveau du navigateur web.","title":"Mise en \u0153uvre du HSM pour les connexions web"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#prise-en-charge-par-apache","text":"Apache dispose de deux supports pour la prise en charge de PKCS11 : le premier support est le module gnutls. Ce module est d\u00e9j\u00e0 ancien, et les tests effectu\u00e9s montrent que ce module ne met pas \u00e0 disposition les donn\u00e9es comme le DN du sujet du certificat au niveau des directives Require : de ce fait, ce module ne peut pas faire l\u2019affaire. Le deuxi\u00e8me module est le module ssl : ce module a vu un d\u00e9but de support de PKCS11 depuis la version 2.4.42. Ce support est donc r\u00e9cent, car la version d\u2019Apache fournie par Ubuntu 20.04 LTS est la version 2.4.41, ne permettant pas le support de la fonctionnalit\u00e9. De ce fait, il est n\u00e9cessaire de passer temporairement \u00e0 la version 21.04 d\u2019Ubuntu, qui embarque Apache 2.4.46 ; passer \u00e0 la version normale signifie \u00e9galement disposer d\u2019une dur\u00e9e de support r\u00e9duite \u00e0 9 mois, au lieu de 5 ans. Le support est minimaliste : il concerne le certificat et la clef du serveur : les directives de configuration peuvent accepter depuis 2.4.42 de la possibilit\u00e9 de saisir des URI PKCS11, URI que l\u2019on peut d\u00e9terminer via p11tool. Ce point est probl\u00e9matique pour le reverse proxy, qui, lui, ne supporte pas d\u2019URI PKCS11 au niveau de la directive SSLProxyMachineCertificateFile . On arrive \u00e0 comprendre ce non-support en raison de l\u2019approche de cette directive : stocker l\u2019ensemble des certificats dans un path ou dans un fichier pour permettre au proxy de s\u2019authentifier aupr\u00e8s des serveurs distants, ce qui est incompatible avec les URI PKCS11, qui, elles, sont plut\u00f4t utilis\u00e9es pour adresser des ressources sp\u00e9cifiques. Dans le cas pr\u00e9sent, un contournement est possible via iptables : en effet, on peut supposer que l\u2019instance qui h\u00e9bergera le reverse proxy et le site seront situ\u00e9s dans une m\u00eame instance d\u2019Apache, et donc auront \u00e0 disposition le m\u00eame kernel. De ce fait, on peut mettre \u00e0 profit une fonctionnalit\u00e9 de marquage des paquets r\u00e9seaux d\u2019iptables, associ\u00e9e \u00e0 une condition sur l\u2019origine des paquets : on marquera sur la cha\u00eene OUTPUT, sur le loopback, les paquets issus de www-data destin\u00e9s au site drupal proprement dit, et on n\u2019acceptera sur la cha\u00eene INPUT, \u00e0 l\u2019entr\u00e9e du loopback et \u00e0 destination du site drupal, que des paquets d\u00fbment marqu\u00e9s. Un exemple de configuration est tel que suit : iptables -A OUTPUT -o lo -p tcp --dst 127 .0.0.1 --src 127 .0.0.1 --dport 444 -m owner --uid-owner www-data -j MARK --set-mark 33 iptables -A INPUT -i lo -p tcp --dst 127 .0.0.1 --src 127 .0.0.1 --dport 444 -m mark --mark 33 -j ACCEPT iptables -A INPUT -p tcp --dport 444 -j DROP Les paquets qui arrivent au serveur Drupal seront donc identifi\u00e9s indirectement, ce qui permet ne plus avoir besoin du certificat SSL pour l\u2019authentification au niveau de Drupal. En revanche, le chiffrement des donn\u00e9es reste toutefois requis. On en arrive donc \u00e0 une configuration d\u2019exemple comme la suivante : Listen 127.0.0.1 :444 <VirtualHost 127.0.0.1:443 > LogLevel debug CustomLog \"/var/log/apache2/debug_jm.log\" \"REMOTE_USER: %{REMOTE_USER}x SUBJECT_CN: % {SSL_CLIENT_S_DN_CN}x --- %v %h %l %u %t \\\"%r\\\" %>s %b\" ServerName drucomp2.test AddExternalAuth dea \"/home/ubuntu/DRUPAL_COMPOSER2/AUTH/externalauth.sh\" SetExternalAuthMethod dea pipe SSLEngine on SSLCACertificateFile \"/etc/apache2/KEYS/ca.x509\" SSLCertificateFile \"pkcs11:model=SoftHSM%20v2;manufacturer=SoftHSM%20project;serial=75bb53774ddd60dc;token=serverhsm;object=servercert;type=cert\" SSLCertificateKeyFile \"pkcs11:model=SoftHSM%20v2;manufacturer=SoftHSM%20project;serial=75bb53774ddd60dc;token=serverhsm;object=serverkey;type=private\" SSLCipherSuite HIGH:!aNULL:!MD5 SSLOptions +StrictRequire SSLProxyVerify require #SSLProxyMachineCertificateFile \"/etc/apache2/KEYS/proxy_client.pem\" SSLProxyCACertificateFile \"/etc/apache2/KEYS/ca.x509\" <Location / > <RequireAll> Require ssl Require ssl-verify-client Require valid-user Require expr (%{REMOTE_USER} == %{SSL_CLIENT_S_DN_CN} ) && (-n %{REMOTE_USER}) </RequireAll> AuthType Basic AuthName \"Apache Level\" AuthBasicProvider external AuthExternal dea AuthBasicAuthoritative on ProxyPass \"https://drucomp2.test:444/\" ProxyPassReverse \"https://drucomp2.test:444/\" </Location> SSLProxyCheckPeerCN On SSLProxyCheckPeerName on SSLProxyVerify require SSLProxyEngine on SSLOptions +StrictRequire SSLVerifyClient require </VirtualHost> <VirtualHost 127.0.0.1:444 > CustomLog \"/var/log/apache2/debug_jm_core.log\" \"REMOTE_USER: %{REMOTE_USER}x SUBJECT_CN:%{SSL_CLIENT_S_DN_CN}x --- %v %h %l %u %t \\\"%r\\\" %>s %b\" LogLevel debug DocumentRoot /home/ubuntu/DRUPAL_COMPOSER2 ServerName drucomp2.test php_admin_value sendmail_path \"/usr/bin/env catchmail -f test@mailcatcher.test\" php_admin_value CIVICRM_DB_CACHE_CLASS NoCache <Directory /home/ubuntu/DRUPAL_COMPOSER2 > SSLRequireSSL Require all granted AllowOverride All </Directory> SSLEngine on SSLCACertificateFile \"/etc/apache2/KEYS/ca.x509\" SSLCertificateFile \"pkcs11:model=SoftHSM%20v2;manufacturer=SoftHSM%20project;serial=75bb53774ddd60dc;token=serverhsm;object=servercert;type=cert\" SSLCertificateKeyFile \"pkcs11:model=SoftHSM%20v2;manufacturer=SoftHSM%20project;serial=75bb53774ddd60dc;token=serverhsm;object=serverkey;type=private\" SSLCipherSuite HIGH:!aNULL:!MD5 SSLOptions +StrictRequire #SSLVerifyClient require </VirtualHost>","title":"Prise en charge par Apache"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#prise-en-charge-hsm-au-niveau-du-navigateur","text":"Firefox, dans ses pr\u00e9f\u00e9rences, dispose d\u2019un bouton pour appeler une interface de gestion des p\u00e9riph\u00e9riques de s\u00e9curit\u00e9. Il suffit ensuite de pr\u00e9ciser les modules d\u2019interfa\u00e7age PKCS11 \u00e0 charger (par exemple /usr/lib/arm-linux-gnueabihf/softhsm/libsofthsm2.so ou /usr/lib/arm-linux-gnueabihf/libykcs11.so ). Ensuite, les certificats sont rendus disponibles du moment que l\u2019utilisateur se connecte aux tokens. En ce qui concerne chromium, la situation est plus compliqu\u00e9e : en th\u00e9orie, chromium chercherait des informations dans une base NSS situ\u00e9e dans $HOME/.pki/nssdb. Cette base peut \u00eatre g\u00e9r\u00e9e par l\u2019utilitaire modutil (package libnss3-tools), pour demander \u00e0 chromium de charger les m\u00eames modules que ceux pr\u00e9sent\u00e9s \u00e0 firefox. N\u00e9anmoins, la version de chromium livr\u00e9e avec Ubuntu est une version dans le format \u00ab snap \u00bb ; et le package, tel que configur\u00e9, ne permet pas d\u2019acc\u00e9der au r\u00e9pertoire nssdb. Ce probl\u00e8me est r\u00e9pertori\u00e9 chez Ubuntu ( https://bugs.launchpad.net/ubuntu/+source/chromium-browser/+bug/1899478 et https://bugs.launchpad.net/ubuntu/+source/chromium-browser/+bug/1859643 ). De plus, le montage de l\u2019interface home dans un snap devrait se limiter aux fichiers non cach\u00e9s (donc qui ne commence pas par un point ) ; du coup, cela rend le probl\u00e8me plus difficile \u00e0 r\u00e9soudre, car le chemin de la BD NSS semble \u00eatre en dur dans le code de chromium ( https://github.com/chromium/chromium/blob/master/crypto/nss_util.cc ). En conclusion, on remarque que les b\u00e9n\u00e9fices de l\u2019identification par certificat peuvent \u00eatre appr\u00e9ciables, mais que ces b\u00e9n\u00e9fices ne peuvent \u00eatre acquis qu\u2019en mettant les ressources techniques, humaines, et mat\u00e9rielles en face. Enfin, on n\u2019oubliera pas que l\u2019authentification par certificat peut \u00e9galement \u00eatre mise en \u0153uvre dans certaines solutions VPN, ce qui signifie que cette technologie peut servir \u00e0 plusieurs niveaux. Des recherches compl\u00e9mentaires sur la gestion de CA et sur les VPN (au sens large) pourraient donc \u00eatre judicieuses.","title":"Prise en charge HSM au niveau du navigateur"},{"location":"TECHNIQUE/INTEGRATION/etude_authentification.html#addendum-mise-en-cache-de-lauthentification","text":"L'int\u00e9gration de l'authentification issue de Drupal avec Apache est co\u00fbteuse : pour toute requ\u00eate envoy\u00e9e au reverse-proxy, deux requ\u00eates peuvent \u00eatre envoy\u00e9es au serveur web interne : la requ\u00eate pour v\u00e9rifier les identifiants si l'authentification est valide, la requ\u00eate de base pour effectuer le travail proprement dit. En pratique, le maquettage a montr\u00e9 que ce syst\u00e8me est particuli\u00e8rement impactant pour le bon fonctionnement du syst\u00e8me, car il ne faut pas oublier que toute ressource va \u00eatre soumise \u00e0 authentification - dont les images. Il arrive donc que plus de resources soient n\u00e9cessaires pour l'authentification que pour le travail demand\u00e9. Il ne faut par ailleurs pas oublier que dans le cadre d'un d\u00e9ploiement \u00e0 grande \u00e9chelle, cette consommation de ressources va impliquer plus de ressources n\u00e9cessaires au fonctionnement du syst\u00e8me, et donc des co\u00fbts plus importants. Il s'av\u00e8re que mod_authnz_external dispose d'un n\u00e9cessaire pour utiliser mod_authn_socache pour disposer d'un cache d'identifiants. Le cache utilis\u00e9 peut par exemple \u00eatre mod_socache_shmcb , qui va stocker les identifiants dans de la m\u00e9moire partag\u00e9e. V\u00e9rification faite dans le code de authnz_external , une fonction de la libapr est utilis\u00e9e pour g\u00e9n\u00e9rer l'entr\u00e9e en cache. Au niveau du cache, ce sera une empreinte SHA1 qui va \u00eatre stock\u00e9e. La libapr permettrait quatre types d'identifiants : en clair bcrypt md5 sha1 L'utilisation de SHA1 n'est plus consid\u00e9r\u00e9e comme s\u00fbre,ce qui am\u00e8ne \u00e0 d\u00e9conseiller l'utilisation du cache \u00e0 cause de ce stockage du mot de passe. Toutefois, si l'authentification r\u00e9alis\u00e9e est une authentification \u00e0 facteurs multiples (dont une authentification forte), on pourrait toutefois consid\u00e9rer que l'importante du mot de passe n'est plus aussi forte, et que le risque devient un peu plus acceptable - m\u00eame si une d\u00e9cision politique doit clairement \u00eatre prise \u00e0 ce sujet avant mise en production. En ce qui concerne la mise en cache de l'authentification, on peut consid\u00e9rer l'exemple suivant : AuthnCacheEnable on AuthnCacheSOCache shmcb <VirtualHost 0.0.0.0:443 > ServerName ${SERVERNAME} AddExternalAuth dea \"/AUTH/externalauth.sh\" SetExternalAuthMethod dea pipe SSLEngine on SSLCertificateFile ${SERVER_CERT} SSLCertificateKeyFile ${SERVER_KEY} SSLCipherSuite HIGH:!aNULL:!MD5 SSLOptions +StrictRequire SSLProxyVerify require SSLProxyMachineCertificateFile ${PROXY_MACHINE_CERT} SSLProxyCACertificateFile ${PROXY_CA} SSLProxyCheckPeerCN on SSLProxyCheckPeerName on SSLProxyVerify require SSLProxyEngine on SSLOptions +StrictRequire SSLVerifyClient none <Location \"/\" > AuthExternalContext ${AUTH_CONTEXT} <RequireAll> Require ssl Require valid-user </RequireAll> AuthType Basic AuthName \"Civiparoisse\" AuthBasicProvider socache external AuthnCacheProvideFor external AuthExternalProvideCache on AuthnCacheContext server AuthnCacheTimeout 300 AuthExternal dea AuthBasicAuthoritative on </Location> ProxyPass \"/\" \"https://${INTERN_SERVERNAME}:444/\" </VirtualHost> On constate la directive AuthExternalProvideCache qui va demander \u00e0 authnz_external de remplir le cache, et on constate qu'on a un provider d'authentification suppl\u00e9mentaire : socache, avec un timeout de 300secondes. Le contexte va agir sur la clef. On a encore deux directives globales qui d\u00e9finissent le backend de cache utilis\u00e9, et l'activation du cache.","title":"Addendum : mise en cache de l'authentification"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/authenticator.html","text":"Authenticateur L'authenticateur a pour vocation de v\u00e9rifier si les identifiants transmis par un utilisateur (au travers du reverse proxy) sont valides, en les testant vers une URL sp\u00e9cifique. L'authentification en elle-m\u00eame a \u00e9t\u00e9 trait\u00e9e dans une \u00e9tude sp\u00e9cifique . Un utilisateur et un groupe authenticator ont \u00e9t\u00e9 rajout\u00e9s de sorte \u00e0 faire tourner le script d'authentification via cet utilisateur. Le propri\u00e9taire des fichiers reste root, de sorte que ce soient les droits du groupe qui soient (normalement) utilis\u00e9s pour ex\u00e9cuter le script shell d'authentification. Pour le m\u00eame syst\u00e8me a \u00e9t\u00e9 utilis\u00e9 pour la mise \u00e0 disposition de la socket : l'owner est paroisse, et www-data y acc\u00e8de gr\u00e2ce au positionnement du groupe. RAF Voir s'il y a moyen de simplifier / factoriser les comptes tout en gardant le m\u00eame niveau de protection induit par les diff\u00e9renciations. FROM ubuntu LABEL uepal.name = \"authenticator\" uepal.version = \"0.0.1\" ENV INTERN_SERVERNAME = \"intern.civicrm.test\" AUTH_CLIENT_CERT = \"/var/run/secrets/KEYS/auth_client.x509\" AUTH_CLIENT_KEY = \"/var/run/secrets/KEYS/auth_client.pem\" AUTH_CLIENT_CA = \"/var/run/secrets/KEYS/ca.x509\" AUTH_CONTEXT = \"/var/run/AUTH_CLIENT_CONFIG\" CONTEXT = \"/var/run/AUTH_CLIENT_CONFIG\" RUN groupadd -g 1000 -f paroisse && useradd -d /nonexistent -e 1 -g 1000 -u 1000 -M -N -s /usr/sbin/nologin paroisse && usermod -L paroisse && groupadd -g 1001 -f authenticator && useradd -d /nonexistent -e 1 -g 1001 -u 1001 -M -N -s /usr/sbin/nologin authenticator && usermod -L authenticator && mkdir /exec && mkdir /var/run/AUTH_CLIENT_CONFIG && apt-get update && apt-get full-upgrade -y && export DEBIAN_FRONTEND = noninteractive && ln -fs /usr/share/zoneinfo/Europe/Paris /etc/localtime && apt-get install -y tzdata && dpkg-reconfigure --frontend noninteractive tzdata && apt-get install -y wget socat && apt-get remove --purge --auto-remove -y && rm -rf /var/lib/apt/lists && mkdir /app && mkdir /AUTH && install -d /var/run/secrets/KEYS && chmod 550 /var/run/secrets && chmod 550 /var/run/secrets/KEYS && chown root:authenticator -R /var/run/secrets COPY exec.sh /exec/ COPY AUTH/* AUTH/ COPY AUTH_CLIENT_CONFIG/* /var/run/AUTH_CLIENT_CONFIG/ COPY --from = uepal_test/selfkeys /KEYS/USAGE/auth_client* /var/run/secrets/KEYS/ COPY --from = uepal_test/selfkeys /KEYS/USAGE/ca.x509 /var/run/secrets/KEYS/ RUN chown root:authenticator /var/run/secrets/KEYS/* && chmod 440 /var/run/secrets/KEYS/* && chown root:authenticator -R /exec && chmod -R 550 /exec VOLUME /authentication CMD [ \"/exec/exec.sh\" ] Variables d'environnement Variable Description Valeur par d\u00e9faut INTERN_SERVERNAME Nom du serveur interne \"intern.civicrm.test\" AUTH_CLIENT_CERT chemin du certificat client authenticateur \"/var/run/secrets/KEYS/auth_client.x509\" AUTH_CLIENT_KEY chemin de la clef pour le client authenticateur \"/var/run/secrets/KEYS/auth_client.pem\" AUTH_CLIENT_CA chemin du CA \"/var/run/secrets/KEYS/ca.x509\" AUTH_CONTEXT chemin du r\u00e9pertoire de configuration \"/var/run/AUTH_CLIENT_CONFIG\" CONTEXT chemin du r\u00e9pertoire de configuration \"/var/run/AUTH_CLIENT_CONFIG\" Ecoute sur socket unix L'authenticateur \u00e9coute sur une socket Unix, car c'est un bon moyen de faire des communications entre containers d'un m\u00eame pod sans passer par le r\u00e9seau. Etant donn\u00e9 que l'authenticateur vient \u00e0 la base d'une image unifi\u00e9 entre authenticateur, serveur web interne et reverse proxy, le plus simple a \u00e9t\u00e9 d'utiliser socat pour brancher une socket unix sur un script d\u00e9j\u00e0 existant : #!/bin/bash socat -d -d -d -D -t 50 -T 50 -lf /tmp/socat.txt UNIX-LISTEN:/authentication/authenticator,fork,user = paroisse,group = www-data,mode = 0660 ,unlink-early EXEC:/AUTH/externalauth.sh,su = authenticator","title":"authenticator"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/authenticator.html#authenticateur","text":"L'authenticateur a pour vocation de v\u00e9rifier si les identifiants transmis par un utilisateur (au travers du reverse proxy) sont valides, en les testant vers une URL sp\u00e9cifique. L'authentification en elle-m\u00eame a \u00e9t\u00e9 trait\u00e9e dans une \u00e9tude sp\u00e9cifique . Un utilisateur et un groupe authenticator ont \u00e9t\u00e9 rajout\u00e9s de sorte \u00e0 faire tourner le script d'authentification via cet utilisateur. Le propri\u00e9taire des fichiers reste root, de sorte que ce soient les droits du groupe qui soient (normalement) utilis\u00e9s pour ex\u00e9cuter le script shell d'authentification. Pour le m\u00eame syst\u00e8me a \u00e9t\u00e9 utilis\u00e9 pour la mise \u00e0 disposition de la socket : l'owner est paroisse, et www-data y acc\u00e8de gr\u00e2ce au positionnement du groupe.","title":"Authenticateur"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/authenticator.html#raf","text":"Voir s'il y a moyen de simplifier / factoriser les comptes tout en gardant le m\u00eame niveau de protection induit par les diff\u00e9renciations. FROM ubuntu LABEL uepal.name = \"authenticator\" uepal.version = \"0.0.1\" ENV INTERN_SERVERNAME = \"intern.civicrm.test\" AUTH_CLIENT_CERT = \"/var/run/secrets/KEYS/auth_client.x509\" AUTH_CLIENT_KEY = \"/var/run/secrets/KEYS/auth_client.pem\" AUTH_CLIENT_CA = \"/var/run/secrets/KEYS/ca.x509\" AUTH_CONTEXT = \"/var/run/AUTH_CLIENT_CONFIG\" CONTEXT = \"/var/run/AUTH_CLIENT_CONFIG\" RUN groupadd -g 1000 -f paroisse && useradd -d /nonexistent -e 1 -g 1000 -u 1000 -M -N -s /usr/sbin/nologin paroisse && usermod -L paroisse && groupadd -g 1001 -f authenticator && useradd -d /nonexistent -e 1 -g 1001 -u 1001 -M -N -s /usr/sbin/nologin authenticator && usermod -L authenticator && mkdir /exec && mkdir /var/run/AUTH_CLIENT_CONFIG && apt-get update && apt-get full-upgrade -y && export DEBIAN_FRONTEND = noninteractive && ln -fs /usr/share/zoneinfo/Europe/Paris /etc/localtime && apt-get install -y tzdata && dpkg-reconfigure --frontend noninteractive tzdata && apt-get install -y wget socat && apt-get remove --purge --auto-remove -y && rm -rf /var/lib/apt/lists && mkdir /app && mkdir /AUTH && install -d /var/run/secrets/KEYS && chmod 550 /var/run/secrets && chmod 550 /var/run/secrets/KEYS && chown root:authenticator -R /var/run/secrets COPY exec.sh /exec/ COPY AUTH/* AUTH/ COPY AUTH_CLIENT_CONFIG/* /var/run/AUTH_CLIENT_CONFIG/ COPY --from = uepal_test/selfkeys /KEYS/USAGE/auth_client* /var/run/secrets/KEYS/ COPY --from = uepal_test/selfkeys /KEYS/USAGE/ca.x509 /var/run/secrets/KEYS/ RUN chown root:authenticator /var/run/secrets/KEYS/* && chmod 440 /var/run/secrets/KEYS/* && chown root:authenticator -R /exec && chmod -R 550 /exec VOLUME /authentication CMD [ \"/exec/exec.sh\" ]","title":"RAF"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/authenticator.html#variables-denvironnement","text":"Variable Description Valeur par d\u00e9faut INTERN_SERVERNAME Nom du serveur interne \"intern.civicrm.test\" AUTH_CLIENT_CERT chemin du certificat client authenticateur \"/var/run/secrets/KEYS/auth_client.x509\" AUTH_CLIENT_KEY chemin de la clef pour le client authenticateur \"/var/run/secrets/KEYS/auth_client.pem\" AUTH_CLIENT_CA chemin du CA \"/var/run/secrets/KEYS/ca.x509\" AUTH_CONTEXT chemin du r\u00e9pertoire de configuration \"/var/run/AUTH_CLIENT_CONFIG\" CONTEXT chemin du r\u00e9pertoire de configuration \"/var/run/AUTH_CLIENT_CONFIG\"","title":"Variables d'environnement"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/authenticator.html#ecoute-sur-socket-unix","text":"L'authenticateur \u00e9coute sur une socket Unix, car c'est un bon moyen de faire des communications entre containers d'un m\u00eame pod sans passer par le r\u00e9seau. Etant donn\u00e9 que l'authenticateur vient \u00e0 la base d'une image unifi\u00e9 entre authenticateur, serveur web interne et reverse proxy, le plus simple a \u00e9t\u00e9 d'utiliser socat pour brancher une socket unix sur un script d\u00e9j\u00e0 existant : #!/bin/bash socat -d -d -d -D -t 50 -T 50 -lf /tmp/socat.txt UNIX-LISTEN:/authentication/authenticator,fork,user = paroisse,group = www-data,mode = 0660 ,unlink-early EXEC:/AUTH/externalauth.sh,su = authenticator","title":"Ecoute sur socket unix"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/composer_base.html","text":"Image composer_base Cette image est une des images de base du syst\u00e8me. De ce fait, cette image contient le n\u00e9cessaire commun n\u00e9cessaire aux images d\u00e9riv\u00e9es. Son but principal est de fournir une version utilisable de composer. Contenu n\u00e9cessaire commun aux images d\u00e9riv\u00e9es Le n\u00e9cessaire int\u00e8gre la mise \u00e0 jour de l'image, la mise au bon fuseau horaire, l'installation d'outils comme wget et php et les utilitaires xml. De m\u00eame il y a la cr\u00e9ation de l'utilisateur et du groupe paroisse. Bug de compatibilit\u00e9 composer/symfony/civicrm Cette image est une image qui a \u00e9t\u00e9 construite pour r\u00e9gler une probl\u00e9matique technique li\u00e9e \u00e0 une interaction entre les d\u00e9pendances de composer et le code source natif de civicrm : PHP Fatal error: Uncaught TypeError: Return value of \"Civi\\CompilePlugin\\Command\\CompileCommand::execute()\" must be of the type int, \"null\" returned. in /composer/vendor/symfony/console/Command/Command.php:301 Stack trace: #0 /composer/vendor/symfony/console/Application.php(1015): Symfony\\Component\\Console\\Command\\Command->run() #1 /composer/vendor/symfony/console/Application.php(299): Symfony\\Component\\Console\\Application->doRunCommand() #2 /composer/vendor/composer/composer/src/Composer/Console/Application.php(336): Symfony\\Component\\Console\\Application->doRun() #3 /composer/vendor/symfony/console/Application.php(171): Composer\\Console\\Application->doRun() #4 /composer/vendor/composer/composer/src/Composer/Console/Application.php(131): Symfony\\Component\\Console\\Application->run() #5 /composer/vendor/composer/composer/bin/composer(84): Composer\\Console\\Application->run() #6 {main} thrown in /composer/vendor/symfony/console/Command/Command.php on line 301 Composer a une d\u00e9pendance sur symfony/console ; si composer est packag\u00e9 avec une version 5.4 ou plus, la d\u00e9pendance requiert que la m\u00e9thode execute de https://github.com/civicrm/composer-compile-plugin/blob/master/src/Command/CompileCommand.php retourne un entier (cf https://github.com/symfony/console/blob/5.4/Command/Command.php ligne 301). Avec l'image composer \"officielle\" je n'ai pas le probl\u00e8me car le code de la d\u00e9pendance n'inclut pas l'exception. En revanche, elle est d\u00e9clench\u00e9e par le composer packag\u00e9 par ubuntu dans la 21.10. La solution est donc de pr\u00e9parer un composer en utilisant une version inf\u00e9rieure de symfony : via composer.json, on peut pr\u00e9parer cette version en utilisant le composer fourni par le syst\u00e8me : { \"require\" :{ \"composer/composer\" : \"^2\" , \"symfony/console\" : \"^4\" } }","title":"Composer_base"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/composer_base.html#image-composer_base","text":"Cette image est une des images de base du syst\u00e8me. De ce fait, cette image contient le n\u00e9cessaire commun n\u00e9cessaire aux images d\u00e9riv\u00e9es. Son but principal est de fournir une version utilisable de composer.","title":"Image composer_base"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/composer_base.html#contenu-necessaire-commun-aux-images-derivees","text":"Le n\u00e9cessaire int\u00e8gre la mise \u00e0 jour de l'image, la mise au bon fuseau horaire, l'installation d'outils comme wget et php et les utilitaires xml. De m\u00eame il y a la cr\u00e9ation de l'utilisateur et du groupe paroisse.","title":"Contenu n\u00e9cessaire commun aux images d\u00e9riv\u00e9es"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/composer_base.html#bug-de-compatibilite-composersymfonycivicrm","text":"Cette image est une image qui a \u00e9t\u00e9 construite pour r\u00e9gler une probl\u00e9matique technique li\u00e9e \u00e0 une interaction entre les d\u00e9pendances de composer et le code source natif de civicrm : PHP Fatal error: Uncaught TypeError: Return value of \"Civi\\CompilePlugin\\Command\\CompileCommand::execute()\" must be of the type int, \"null\" returned. in /composer/vendor/symfony/console/Command/Command.php:301 Stack trace: #0 /composer/vendor/symfony/console/Application.php(1015): Symfony\\Component\\Console\\Command\\Command->run() #1 /composer/vendor/symfony/console/Application.php(299): Symfony\\Component\\Console\\Application->doRunCommand() #2 /composer/vendor/composer/composer/src/Composer/Console/Application.php(336): Symfony\\Component\\Console\\Application->doRun() #3 /composer/vendor/symfony/console/Application.php(171): Composer\\Console\\Application->doRun() #4 /composer/vendor/composer/composer/src/Composer/Console/Application.php(131): Symfony\\Component\\Console\\Application->run() #5 /composer/vendor/composer/composer/bin/composer(84): Composer\\Console\\Application->run() #6 {main} thrown in /composer/vendor/symfony/console/Command/Command.php on line 301 Composer a une d\u00e9pendance sur symfony/console ; si composer est packag\u00e9 avec une version 5.4 ou plus, la d\u00e9pendance requiert que la m\u00e9thode execute de https://github.com/civicrm/composer-compile-plugin/blob/master/src/Command/CompileCommand.php retourne un entier (cf https://github.com/symfony/console/blob/5.4/Command/Command.php ligne 301). Avec l'image composer \"officielle\" je n'ai pas le probl\u00e8me car le code de la d\u00e9pendance n'inclut pas l'exception. En revanche, elle est d\u00e9clench\u00e9e par le composer packag\u00e9 par ubuntu dans la 21.10. La solution est donc de pr\u00e9parer un composer en utilisant une version inf\u00e9rieure de symfony : via composer.json, on peut pr\u00e9parer cette version en utilisant le composer fourni par le syst\u00e8me : { \"require\" :{ \"composer/composer\" : \"^2\" , \"symfony/console\" : \"^4\" } }","title":"Bug de compatibilit\u00e9 composer/symfony/civicrm"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/composer_files.html","text":"Composer_files L'image composer_files permet de figer les fichiers \u00e0 d\u00e9ployer pour une instance CiviCRM, ce qui permet de comprendre les inclusions effectu\u00e9es depuis le Dockerfile ( COPY --from , pr\u00e9sents notamment dans tools, et indirectement init et cron, ainsi que dans httpd). { \"config\":{ \"allow-plugins\":true, \"store-auths\":false }, \"repositories\":[{ \"type\":\"git\", \"url\":\"/composer_registry/DRUPAROISSE\" },{ \"type\":\"git\", \"url\":\"/composer_registry/CIVIPAROISSE\" },{ \"type\":\"git\", \"url\":\"/composer_registry/SETUP\" },{ \"type\":\"package\", \"package\":[{ \"name\":\"eileenmcnaughton/org.wikimedia.geocoder\", \"version\":\"1.8\", \"source\":{ \"type\":\"git\", \"url\":\"https://github.com/eileenmcnaughton/org.wikimedia.geocoder.git\", \"reference\":\"1.8\" } },{ \"name\":\"systopia/de.systopia.birthdays\", \"version\":\"1.4\", \"source\":{ \"type\":\"git\", \"url\":\"https://github.com/systopia/de.systopia.birthdays.git\", \"reference\":\"1.4\" } },{ \"name\":\"civicrm/org.civicrm.recentmenu\", \"version\":\"1.3\", \"source\":{ \"type\":\"git\", \"url\":\"https://github.com/civicrm/org.civicrm.recentmenu.git\", \"reference\":\"1.3\" } }] } ], \"extra\":{ \"installer-paths\": { \"web/core\": [\"type:drupal-core\"], \"web/libraries/{$name}\": [\"type:drupal-library\"], \"web/modules/contrib/{$name}\": [\"type:drupal-module\"], \"web/profiles/contrib/{$name}\": [\"type:drupal-profile\"], \"web/themes/contrib/{$name}\": [\"type:drupal-theme\"], \"drush/Commands/contrib/{$name}\": [\"type:drupal-drush\"], \"web/modules/custom/{$name}\": [\"type:drupal-custom-module\"], \"web/profiles/custom/{$name}\": [\"type:drupal-custom-profile\"], \"web/themes/custom/{$name}\": [\"type:drupal-custom-theme\"] }, \"drupal-scaffold\":{ \"locations\":{ \"web-root\":\"web/\" }, \"allowed-packages\":[\"drupal/recommended-project\"] }, \"compile-mode\":\"all\", \"compile-passthru\":\"always\", \"enable-patching\":true, \"compile-whitelist\": [\"civicrm/civicrm-core\", \"civicrm/composer-compile-lib\"], \"drupal-l10n\":{ \"languages\":[\"fr\"] }, \"compile\":[ {\"run\":\"@sh /bin/bash -c pwd ; export VERSION=`xmllint -xpath '/version/version_no/text()' vendor/civicrm/civicrm-core/xml/version.xml`; wget -O- https://download.civicrm.org/civicrm-${VERSION}-l10n.tar.gz|tar -z -f- -C vendor/civicrm/civicrm-core -x --strip-components=1\"} ], \"patches\":{ \"systopia/de.systopia.birthdays\":{ \"Curly brace adjustement\":\"patches/birthdays.patch\" } } }, \"require\":{ \"drush/drush\":\"~11\", \"drupal/recommended-project\":\"~9.2\", \"drupal-composer/drupal-l10n\":\"~2\", \"cweagans/composer-patches\":\"~1.7\", \"eileenmcnaughton/org.wikimedia.geocoder\":\"1.8\", \"systopia/de.systopia.birthdays\":\"1.4\", \"civicrm/org.civicrm.recentmenu\":\"1.3\", \"civicrm/civicrm-core\":\"~5.47.0\", \"civicrm/civicrm-packages\":\"~5.47.0\", \"civicrm/civicrm-drupal-8\":\"~5.47.0\", \"civicrm/civicrm-asset-plugin\":\"~1.1\", \"civicrm/composer-downloads-plugin\":\"~3\", \"civicrm/composer-compile-plugin\":\"~0.17\", \"uepal/fr.uepalparoisse.civiparoisse\":\"0.0.1\", \"uepal/fr.uepalparoisse.druparoisse\":\"0.0.1\", \"uepal/civisetup\":\"0.0.1\" }, \"minimum-stability\":\"dev\", \"prefer-stable\":true } Allow plugins Pour le moment, la directive allow plugins a \u00e9t\u00e9 plac\u00e9e \u00e0 true, ce qui autorise l'ex\u00e9cution des plugins sans avoir besoin de les sp\u00e9cifier. Toutefois, on pourrait pr\u00e9f\u00e9rer une liste de plugins explicitement d\u00e9clar\u00e9s. Ce param\u00e8tre a \u00e9t\u00e9 mis \u00e0 true pour le moment car la valeur par d\u00e9faut de ce param\u00e8tre va passer en juillet 2022 de null \u00e0 {} : autorisation implicite \u00e0 aucun plugin autoris\u00e9 (voir https://getcomposer.org/doc/06-config.md#allow-plugins ) Diversit\u00e9 des sources Plusieurs types de sources sont utilis\u00e9es : les packages de Packagist : pour les packages \"standards\" les packages qui viennent de d\u00e9p\u00f4t Git qui disposent d'un n\u00e9cessaire pour composer (composer.json) et de versionning (via des tags notamment) : type git les packages qui viennent de d\u00e9p\u00f4t Git mais qui n'ont pas le n\u00e9cessaire pour composer : ces packages sont d\u00e9clar\u00e9s de mani\u00e8re explicite, avec la r\u00e9f\u00e9rence vers la source : type package Les packages de sources locales de Civiparoisse sont destin\u00e9s \u00e0 \u00eatre remplac\u00e9 par les d\u00e9p\u00f4ts publics git une fois qu'une version aura \u00e9t\u00e9 stabilis\u00e9e et distribu\u00e9e. Pr\u00e9sence de drush dans les packages requis Drush est pr\u00e9sent dans les packages requis. Ceci peut surprendre a priori, mais l'exp\u00e9rimentation montre qu'il est r\u00e9ellement n\u00e9cessaire : en effet, Drush est utilis\u00e9 pour ex\u00e9cuter les appels de cron, mais en ayant acc\u00e8s aux volumes de fichiers du serveur web interne ainsi qu'\u00e0 la base de donn\u00e9es. Lors de son ex\u00e9cution, Drush supplante dans certains services (notamment les logs) les classes qu'il fournit. Si lors de l'ex\u00e9cution de Drush les caches sont reg\u00e9n\u00e9r\u00e9s, les supplantations de Drush seront pr\u00e9sents dans les caches. Lorsque le cache est r\u00e9utilis\u00e9 sur le serveur web interne, le serveur doit avoir acc\u00e8s aux classes de Drush pour ne pas tomber sur une erreur. On retiendra donc que Drush est n\u00e9cessaire pour ces classes, mais qu'on peut envisager de ne pas laisser les droits en ex\u00e9cution sur les ex\u00e9cutables dans les fichiers. Patches Le package cweagans/composer-patches permet d'indiquer des fichiers de patches \u00e0 d\u00e9ployer : un fichier du package systopia/de.systopia.birthdays devait \u00eatre mis \u00e0 jour pour r\u00e9gler un probl\u00e8me de syntaxe d\u00e9pr\u00e9ci\u00e9. Scaffolding Le scaffolding est le fait de r\u00e9partir les fichiers entre le DocumentRoot du site et un autre lieu hors du DocumentRoot. Cette r\u00e9partition est pr\u00e9vue par le package drupal/recommended-project ; toutefois, il a fallu reprendre la majorit\u00e9 de cette configuration dans le fichier composer.json de l'image pour que ce scaffolding puisse avoir lieu, car il est n\u00e9cessaire que cette configuration se situe dans le composer.json principal. Traductions Les traductions ont deux sources : * pour Drupal, il s'agit du package drupal-composer/drupal-l10n * pour CiviCRM, les traductions sont r\u00e9cup\u00e9r\u00e9es via une \u00e9tape de (post)-compilation, o\u00f9 l'on va r\u00e9cup\u00e9rer d'abord la version de CiviCRM depuis un fichier XML pr\u00e9sent dans les sources, puis r\u00e9cup\u00e9rer sur le net les traductions, et enfin les d\u00e9compresser au bon endroit.","title":"Composer_files"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/composer_files.html#composer_files","text":"L'image composer_files permet de figer les fichiers \u00e0 d\u00e9ployer pour une instance CiviCRM, ce qui permet de comprendre les inclusions effectu\u00e9es depuis le Dockerfile ( COPY --from , pr\u00e9sents notamment dans tools, et indirectement init et cron, ainsi que dans httpd). { \"config\":{ \"allow-plugins\":true, \"store-auths\":false }, \"repositories\":[{ \"type\":\"git\", \"url\":\"/composer_registry/DRUPAROISSE\" },{ \"type\":\"git\", \"url\":\"/composer_registry/CIVIPAROISSE\" },{ \"type\":\"git\", \"url\":\"/composer_registry/SETUP\" },{ \"type\":\"package\", \"package\":[{ \"name\":\"eileenmcnaughton/org.wikimedia.geocoder\", \"version\":\"1.8\", \"source\":{ \"type\":\"git\", \"url\":\"https://github.com/eileenmcnaughton/org.wikimedia.geocoder.git\", \"reference\":\"1.8\" } },{ \"name\":\"systopia/de.systopia.birthdays\", \"version\":\"1.4\", \"source\":{ \"type\":\"git\", \"url\":\"https://github.com/systopia/de.systopia.birthdays.git\", \"reference\":\"1.4\" } },{ \"name\":\"civicrm/org.civicrm.recentmenu\", \"version\":\"1.3\", \"source\":{ \"type\":\"git\", \"url\":\"https://github.com/civicrm/org.civicrm.recentmenu.git\", \"reference\":\"1.3\" } }] } ], \"extra\":{ \"installer-paths\": { \"web/core\": [\"type:drupal-core\"], \"web/libraries/{$name}\": [\"type:drupal-library\"], \"web/modules/contrib/{$name}\": [\"type:drupal-module\"], \"web/profiles/contrib/{$name}\": [\"type:drupal-profile\"], \"web/themes/contrib/{$name}\": [\"type:drupal-theme\"], \"drush/Commands/contrib/{$name}\": [\"type:drupal-drush\"], \"web/modules/custom/{$name}\": [\"type:drupal-custom-module\"], \"web/profiles/custom/{$name}\": [\"type:drupal-custom-profile\"], \"web/themes/custom/{$name}\": [\"type:drupal-custom-theme\"] }, \"drupal-scaffold\":{ \"locations\":{ \"web-root\":\"web/\" }, \"allowed-packages\":[\"drupal/recommended-project\"] }, \"compile-mode\":\"all\", \"compile-passthru\":\"always\", \"enable-patching\":true, \"compile-whitelist\": [\"civicrm/civicrm-core\", \"civicrm/composer-compile-lib\"], \"drupal-l10n\":{ \"languages\":[\"fr\"] }, \"compile\":[ {\"run\":\"@sh /bin/bash -c pwd ; export VERSION=`xmllint -xpath '/version/version_no/text()' vendor/civicrm/civicrm-core/xml/version.xml`; wget -O- https://download.civicrm.org/civicrm-${VERSION}-l10n.tar.gz|tar -z -f- -C vendor/civicrm/civicrm-core -x --strip-components=1\"} ], \"patches\":{ \"systopia/de.systopia.birthdays\":{ \"Curly brace adjustement\":\"patches/birthdays.patch\" } } }, \"require\":{ \"drush/drush\":\"~11\", \"drupal/recommended-project\":\"~9.2\", \"drupal-composer/drupal-l10n\":\"~2\", \"cweagans/composer-patches\":\"~1.7\", \"eileenmcnaughton/org.wikimedia.geocoder\":\"1.8\", \"systopia/de.systopia.birthdays\":\"1.4\", \"civicrm/org.civicrm.recentmenu\":\"1.3\", \"civicrm/civicrm-core\":\"~5.47.0\", \"civicrm/civicrm-packages\":\"~5.47.0\", \"civicrm/civicrm-drupal-8\":\"~5.47.0\", \"civicrm/civicrm-asset-plugin\":\"~1.1\", \"civicrm/composer-downloads-plugin\":\"~3\", \"civicrm/composer-compile-plugin\":\"~0.17\", \"uepal/fr.uepalparoisse.civiparoisse\":\"0.0.1\", \"uepal/fr.uepalparoisse.druparoisse\":\"0.0.1\", \"uepal/civisetup\":\"0.0.1\" }, \"minimum-stability\":\"dev\", \"prefer-stable\":true }","title":"Composer_files"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/composer_files.html#allow-plugins","text":"Pour le moment, la directive allow plugins a \u00e9t\u00e9 plac\u00e9e \u00e0 true, ce qui autorise l'ex\u00e9cution des plugins sans avoir besoin de les sp\u00e9cifier. Toutefois, on pourrait pr\u00e9f\u00e9rer une liste de plugins explicitement d\u00e9clar\u00e9s. Ce param\u00e8tre a \u00e9t\u00e9 mis \u00e0 true pour le moment car la valeur par d\u00e9faut de ce param\u00e8tre va passer en juillet 2022 de null \u00e0 {} : autorisation implicite \u00e0 aucun plugin autoris\u00e9 (voir https://getcomposer.org/doc/06-config.md#allow-plugins )","title":"Allow plugins"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/composer_files.html#diversite-des-sources","text":"Plusieurs types de sources sont utilis\u00e9es : les packages de Packagist : pour les packages \"standards\" les packages qui viennent de d\u00e9p\u00f4t Git qui disposent d'un n\u00e9cessaire pour composer (composer.json) et de versionning (via des tags notamment) : type git les packages qui viennent de d\u00e9p\u00f4t Git mais qui n'ont pas le n\u00e9cessaire pour composer : ces packages sont d\u00e9clar\u00e9s de mani\u00e8re explicite, avec la r\u00e9f\u00e9rence vers la source : type package Les packages de sources locales de Civiparoisse sont destin\u00e9s \u00e0 \u00eatre remplac\u00e9 par les d\u00e9p\u00f4ts publics git une fois qu'une version aura \u00e9t\u00e9 stabilis\u00e9e et distribu\u00e9e.","title":"Diversit\u00e9 des sources"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/composer_files.html#presence-de-drush-dans-les-packages-requis","text":"Drush est pr\u00e9sent dans les packages requis. Ceci peut surprendre a priori, mais l'exp\u00e9rimentation montre qu'il est r\u00e9ellement n\u00e9cessaire : en effet, Drush est utilis\u00e9 pour ex\u00e9cuter les appels de cron, mais en ayant acc\u00e8s aux volumes de fichiers du serveur web interne ainsi qu'\u00e0 la base de donn\u00e9es. Lors de son ex\u00e9cution, Drush supplante dans certains services (notamment les logs) les classes qu'il fournit. Si lors de l'ex\u00e9cution de Drush les caches sont reg\u00e9n\u00e9r\u00e9s, les supplantations de Drush seront pr\u00e9sents dans les caches. Lorsque le cache est r\u00e9utilis\u00e9 sur le serveur web interne, le serveur doit avoir acc\u00e8s aux classes de Drush pour ne pas tomber sur une erreur. On retiendra donc que Drush est n\u00e9cessaire pour ces classes, mais qu'on peut envisager de ne pas laisser les droits en ex\u00e9cution sur les ex\u00e9cutables dans les fichiers.","title":"Pr\u00e9sence de drush dans les packages requis"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/composer_files.html#patches","text":"Le package cweagans/composer-patches permet d'indiquer des fichiers de patches \u00e0 d\u00e9ployer : un fichier du package systopia/de.systopia.birthdays devait \u00eatre mis \u00e0 jour pour r\u00e9gler un probl\u00e8me de syntaxe d\u00e9pr\u00e9ci\u00e9.","title":"Patches"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/composer_files.html#scaffolding","text":"Le scaffolding est le fait de r\u00e9partir les fichiers entre le DocumentRoot du site et un autre lieu hors du DocumentRoot. Cette r\u00e9partition est pr\u00e9vue par le package drupal/recommended-project ; toutefois, il a fallu reprendre la majorit\u00e9 de cette configuration dans le fichier composer.json de l'image pour que ce scaffolding puisse avoir lieu, car il est n\u00e9cessaire que cette configuration se situe dans le composer.json principal.","title":"Scaffolding"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/composer_files.html#traductions","text":"Les traductions ont deux sources : * pour Drupal, il s'agit du package drupal-composer/drupal-l10n * pour CiviCRM, les traductions sont r\u00e9cup\u00e9r\u00e9es via une \u00e9tape de (post)-compilation, o\u00f9 l'on va r\u00e9cup\u00e9rer d'abord la version de CiviCRM depuis un fichier XML pr\u00e9sent dans les sources, puis r\u00e9cup\u00e9rer sur le net les traductions, et enfin les d\u00e9compresser au bon endroit.","title":"Traductions"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/cron.html","text":"Cron Cette image est tr\u00e8s simple : elle est pr\u00e9vue pour ex\u00e9cuter les t\u00e2ches cron \u00e0 la fois de civicrm et drupal. Elle est pr\u00e9vue pour qu'on y connecte les volumes via montage, mais elle doit acc\u00e9der les BD mysql de l'instance. Sa planification d'ex\u00e9cution doit \u00eatre pr\u00e9vue dans Kubernetes. #!/bin/bash sudo www-data cv --cwd = /app api job.execute sudo www-data drush --no-interaction --quiet --root /app core:cron FROM uepal_test/tools COPY exec.sh /exec/exec.sh RUN chown -R root:root /exec && chmod -R 500 /exec","title":"cron"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/cron.html#cron","text":"Cette image est tr\u00e8s simple : elle est pr\u00e9vue pour ex\u00e9cuter les t\u00e2ches cron \u00e0 la fois de civicrm et drupal. Elle est pr\u00e9vue pour qu'on y connecte les volumes via montage, mais elle doit acc\u00e9der les BD mysql de l'instance. Sa planification d'ex\u00e9cution doit \u00eatre pr\u00e9vue dans Kubernetes. #!/bin/bash sudo www-data cv --cwd = /app api job.execute sudo www-data drush --no-interaction --quiet --root /app core:cron FROM uepal_test/tools COPY exec.sh /exec/exec.sh RUN chown -R root:root /exec && chmod -R 500 /exec","title":"Cron"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/db_tls_client.html","text":"DB_TLS_CLIENT : proxy pour le tunnel SSL Cette image permet de fournir un point de terminaison de tunnel SSL pour chiffrer le trafic BD entre un client et un serveur. Le client se connecte \u00e0 une socket unix (en PHP, en tant que client qui va vouloir passer par le tunnel, et en premier lieu par la socket.on va profiter pour r\u00e9gler correctement le chemin de la socket par d\u00e9faut, et on pourra utiliser le nom localhost pour passer pr\u00e9f\u00e9rablement par la socket unix). L'image exploite socat pour pr\u00e9parer le tunnel : #!/bin/bash socat -d -d -d -D -t 50 -T 50 -lf /tmp/socat.txt UNIX-LISTEN:/SOCK/mysqld.sock,fork,user = paroisse,group = www-data,mode = 0660 ,unlink-early OPENSSL: ${ DEST_HOST } : ${ DEST_PORT } ,certificate = ${ CLIENT_CERT } ,key = ${ CLIENT_KEY } ,cafile = ${ CAFILE } ,verify = 1 ,cipher = TLSv1.2,pf = ip4,commonname = ${ DEST_CN } echo \"socat client exit code : \" $? exit 0 En ce qui concerne la n\u00e9gociation TLS, on se reportera aux \u00e9l\u00e9ments mentionn\u00e9s au niveau du serveur proxy . Tout au plus, on remarque que le nom que doit pr\u00e9senter le serveur est mentionn\u00e9 sp\u00e9cifiquement dans la ligne de commande. La socket unix est pr\u00e9vue pour \u00eatre utilisable par les membres du groupe www-data, donc par Apache. La particularit\u00e9 que pr\u00e9sente dans ce script est la pr\u00e9sence du echo et du exit. Le code de retour d'un script bash est normalement le code de retour de la derni\u00e8re commande ex\u00e9cut\u00e9e. Pour qu'un pod de job soit termin\u00e9 dans Kubernetes, il faut que l'ensemble des containers du pod aient termin\u00e9 leur ex\u00e9cution. Cette image \u00e9tant un sidecar , lorsqu'on utilise cette image via un cron, on partage sp\u00e9cifiquement l'espace des processus entre les containeurs du pod du cron. De la sorte, lorsque le cron a termin\u00e9 sa \"charge utile\", il lance un pkill socat qui va d\u00e9clencher l'envoi d'un signal SIGTERM . A ce moment, socat va effectivement s'arr\u00eater, mais il va renvoyer un code de retour dit \"synth\u00e9tique\" : il indique qu'il a \u00e9t\u00e9 tu\u00e9 avec un SIGTERM, en utilisant le code 143=128 (tu\u00e9) + 15 (num\u00e9ro de signal SIGTERM), selon https://www.baeldung.com/linux/status-codes . Or, si Kubernetes remarque une sortie diff\u00e9rente de 0, il va consid\u00e9rer que le processus ne s'est pas termin\u00e9 normalement, donc il va relancer le container (\u00e0 v\u00e9rifier : s'il ne relance pas carr\u00e9ment tout le pod). On r\u00e9cup\u00e8re le code de sortie pour le logguer et on force le code de sortie pour contenter Kubernetes. Pour rappel : les num\u00e9ros de signaux : root@7107cbe21154:/app# kill -l 1 ) SIGHUP 2 ) SIGINT 3 ) SIGQUIT 4 ) SIGILL 5 ) SIGTRAP 6 ) SIGABRT 7 ) SIGBUS 8 ) SIGFPE 9 ) SIGKILL 10 ) SIGUSR1 11 ) SIGSEGV 12 ) SIGUSR2 13 ) SIGPIPE 14 ) SIGALRM 15 ) SIGTERM 16 ) SIGSTKFLT 17 ) SIGCHLD 18 ) SIGCONT 19 ) SIGSTOP 20 ) SIGTSTP 21 ) SIGTTIN 22 ) SIGTTOU 23 ) SIGURG 24 ) SIGXCPU 25 ) SIGXFSZ 26 ) SIGVTALRM 27 ) SIGPROF 28 ) SIGWINCH 29 ) SIGIO 30 ) SIGPWR 31 ) SIGSYS 34 ) SIGRTMIN 35 ) SIGRTMIN+1 36 ) SIGRTMIN+2 37 ) SIGRTMIN+3 38 ) SIGRTMIN+4 39 ) SIGRTMIN+5 40 ) SIGRTMIN+6 41 ) SIGRTMIN+7 42 ) SIGRTMIN+8 43 ) SIGRTMIN+9 44 ) SIGRTMIN+10 45 ) SIGRTMIN+11 46 ) SIGRTMIN+12 47 ) SIGRTMIN+13 48 ) SIGRTMIN+14 49 ) SIGRTMIN+15 50 ) SIGRTMAX-14 51 ) SIGRTMAX-13 52 ) SIGRTMAX-12 53 ) SIGRTMAX-11 54 ) SIGRTMAX-10 55 ) SIGRTMAX-9 56 ) SIGRTMAX-8 57 ) SIGRTMAX-7 58 ) SIGRTMAX-6 59 ) SIGRTMAX-5 60 ) SIGRTMAX-4 61 ) SIGRTMAX-3 62 ) SIGRTMAX-2 63 ) SIGRTMAX-1 64 ) SIGRTMAX Variables d'environnement Variable Signification Default Docker CAFILE Fichier d'autorit\u00e9 de certification /var/run/secrets/KEYS/db_ca.x509 CLIENT_CERT Fichier de certificat client /var/run/secrets/KEYS/db_intern_client.x509 CLIENT_KEY Fichier de clef client /var/run/secrets/KEYS/db_intern_client.pem DEST_HOST H\u00f4te de destination civicrmdbproxy DEST_PORT Port de destination 443 DEST_CN Common Name du serveur civicrmdbproxy","title":"db_tls_client"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/db_tls_client.html#db_tls_client-proxy-pour-le-tunnel-ssl","text":"Cette image permet de fournir un point de terminaison de tunnel SSL pour chiffrer le trafic BD entre un client et un serveur. Le client se connecte \u00e0 une socket unix (en PHP, en tant que client qui va vouloir passer par le tunnel, et en premier lieu par la socket.on va profiter pour r\u00e9gler correctement le chemin de la socket par d\u00e9faut, et on pourra utiliser le nom localhost pour passer pr\u00e9f\u00e9rablement par la socket unix). L'image exploite socat pour pr\u00e9parer le tunnel : #!/bin/bash socat -d -d -d -D -t 50 -T 50 -lf /tmp/socat.txt UNIX-LISTEN:/SOCK/mysqld.sock,fork,user = paroisse,group = www-data,mode = 0660 ,unlink-early OPENSSL: ${ DEST_HOST } : ${ DEST_PORT } ,certificate = ${ CLIENT_CERT } ,key = ${ CLIENT_KEY } ,cafile = ${ CAFILE } ,verify = 1 ,cipher = TLSv1.2,pf = ip4,commonname = ${ DEST_CN } echo \"socat client exit code : \" $? exit 0 En ce qui concerne la n\u00e9gociation TLS, on se reportera aux \u00e9l\u00e9ments mentionn\u00e9s au niveau du serveur proxy . Tout au plus, on remarque que le nom que doit pr\u00e9senter le serveur est mentionn\u00e9 sp\u00e9cifiquement dans la ligne de commande. La socket unix est pr\u00e9vue pour \u00eatre utilisable par les membres du groupe www-data, donc par Apache. La particularit\u00e9 que pr\u00e9sente dans ce script est la pr\u00e9sence du echo et du exit. Le code de retour d'un script bash est normalement le code de retour de la derni\u00e8re commande ex\u00e9cut\u00e9e. Pour qu'un pod de job soit termin\u00e9 dans Kubernetes, il faut que l'ensemble des containers du pod aient termin\u00e9 leur ex\u00e9cution. Cette image \u00e9tant un sidecar , lorsqu'on utilise cette image via un cron, on partage sp\u00e9cifiquement l'espace des processus entre les containeurs du pod du cron. De la sorte, lorsque le cron a termin\u00e9 sa \"charge utile\", il lance un pkill socat qui va d\u00e9clencher l'envoi d'un signal SIGTERM . A ce moment, socat va effectivement s'arr\u00eater, mais il va renvoyer un code de retour dit \"synth\u00e9tique\" : il indique qu'il a \u00e9t\u00e9 tu\u00e9 avec un SIGTERM, en utilisant le code 143=128 (tu\u00e9) + 15 (num\u00e9ro de signal SIGTERM), selon https://www.baeldung.com/linux/status-codes . Or, si Kubernetes remarque une sortie diff\u00e9rente de 0, il va consid\u00e9rer que le processus ne s'est pas termin\u00e9 normalement, donc il va relancer le container (\u00e0 v\u00e9rifier : s'il ne relance pas carr\u00e9ment tout le pod). On r\u00e9cup\u00e8re le code de sortie pour le logguer et on force le code de sortie pour contenter Kubernetes. Pour rappel : les num\u00e9ros de signaux : root@7107cbe21154:/app# kill -l 1 ) SIGHUP 2 ) SIGINT 3 ) SIGQUIT 4 ) SIGILL 5 ) SIGTRAP 6 ) SIGABRT 7 ) SIGBUS 8 ) SIGFPE 9 ) SIGKILL 10 ) SIGUSR1 11 ) SIGSEGV 12 ) SIGUSR2 13 ) SIGPIPE 14 ) SIGALRM 15 ) SIGTERM 16 ) SIGSTKFLT 17 ) SIGCHLD 18 ) SIGCONT 19 ) SIGSTOP 20 ) SIGTSTP 21 ) SIGTTIN 22 ) SIGTTOU 23 ) SIGURG 24 ) SIGXCPU 25 ) SIGXFSZ 26 ) SIGVTALRM 27 ) SIGPROF 28 ) SIGWINCH 29 ) SIGIO 30 ) SIGPWR 31 ) SIGSYS 34 ) SIGRTMIN 35 ) SIGRTMIN+1 36 ) SIGRTMIN+2 37 ) SIGRTMIN+3 38 ) SIGRTMIN+4 39 ) SIGRTMIN+5 40 ) SIGRTMIN+6 41 ) SIGRTMIN+7 42 ) SIGRTMIN+8 43 ) SIGRTMIN+9 44 ) SIGRTMIN+10 45 ) SIGRTMIN+11 46 ) SIGRTMIN+12 47 ) SIGRTMIN+13 48 ) SIGRTMIN+14 49 ) SIGRTMIN+15 50 ) SIGRTMAX-14 51 ) SIGRTMAX-13 52 ) SIGRTMAX-12 53 ) SIGRTMAX-11 54 ) SIGRTMAX-10 55 ) SIGRTMAX-9 56 ) SIGRTMAX-8 57 ) SIGRTMAX-7 58 ) SIGRTMAX-6 59 ) SIGRTMAX-5 60 ) SIGRTMAX-4 61 ) SIGRTMAX-3 62 ) SIGRTMAX-2 63 ) SIGRTMAX-1 64 ) SIGRTMAX","title":"DB_TLS_CLIENT : proxy pour le tunnel SSL"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/db_tls_client.html#variables-denvironnement","text":"Variable Signification Default Docker CAFILE Fichier d'autorit\u00e9 de certification /var/run/secrets/KEYS/db_ca.x509 CLIENT_CERT Fichier de certificat client /var/run/secrets/KEYS/db_intern_client.x509 CLIENT_KEY Fichier de clef client /var/run/secrets/KEYS/db_intern_client.pem DEST_HOST H\u00f4te de destination civicrmdbproxy DEST_PORT Port de destination 443 DEST_CN Common Name du serveur civicrmdbproxy","title":"Variables d'environnement"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/db_tls_server.html","text":"DB_TLS_SERVER : ambassadeur pour connexion TLS Le r\u00f4le de cette image est de fournir une terminaison de tunnel TLS vers un serveur MySQL. On utilise socat \u00e0 cet effet. #!/bin/bash socat -d -d -d -D -t 50 -T 50 -lf /tmp/socat.txt OPENSSL-LISTEN: ${ SERVER_PORT } ,certificate = ${ SERVER_CERT } ,key = ${ SERVER_KEY } ,cafile = ${ CAFILE } ,verify = 1 ,fork,bind = 0 .0.0.0,pf = ip4,cipher = TLSv1.2 UNIX-CONNECT: ${ SOCK } Au niveau de la configuration, on retrouve des \u00e9l\u00e9ments connus comme les temporisations, et le d\u00e9buggage. En ce qui concerne la n\u00e9gociation TLS, on constate qu'une autorit\u00e9 de certification est utilis\u00e9e et que les certificats pr\u00e9sent\u00e9s au serveur doivent \u00eatre valides. Le choix du cipher TLSv1.2 n'est pas anodin : en effet, le choix du cipher conditionne les algorithmes utilisables lors de la connexion SSL, et les algorithmes de TLSv1.2 et support\u00e9s par openssl requi\u00e8reraient tous une authentification \u00e0 clef publique, si l'on s'en r\u00e9f\u00e8re \u00e0 la sortie de openssl ciphers , pour voir les ciphers support\u00e9s en tls1_2 : root@6883307658b0:/app# openssl ciphers -tls1_2 -V -stdname -s 0xC0,0x2C - TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 - ECDHE-ECDSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH Au=ECDSA Enc=AESGCM(256) Mac=AEAD 0xC0,0x30 - TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 - ECDHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH Au=RSA Enc=AESGCM(256) Mac=AEAD 0x00,0x9F - TLS_DHE_RSA_WITH_AES_256_GCM_SHA384 - DHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=DH Au=RSA Enc=AESGCM(256) Mac=AEAD 0xCC,0xA9 - TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 - ECDHE-ECDSA-CHACHA20-POLY1305 TLSv1.2 Kx=ECDH Au=ECDSA Enc=CHACHA20/POLY1305(256) Mac=AEAD 0xCC,0xA8 - TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256 - ECDHE-RSA-CHACHA20-POLY1305 TLSv1.2 Kx=ECDH Au=RSA Enc=CHACHA20/POLY1305(256) Mac=AEAD 0xCC,0xAA - TLS_DHE_RSA_WITH_CHACHA20_POLY1305_SHA256 - DHE-RSA-CHACHA20-POLY1305 TLSv1.2 Kx=DH Au=RSA Enc=CHACHA20/POLY1305(256) Mac=AEAD 0xC0,0x2B - TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 - ECDHE-ECDSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH Au=ECDSA Enc=AESGCM(128) Mac=AEAD 0xC0,0x2F - TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 - ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH Au=RSA Enc=AESGCM(128) Mac=AEAD 0x00,0x9E - TLS_DHE_RSA_WITH_AES_128_GCM_SHA256 - DHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=DH Au=RSA Enc=AESGCM(128) Mac=AEAD 0xC0,0x24 - TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384 - ECDHE-ECDSA-AES256-SHA384 TLSv1.2 Kx=ECDH Au=ECDSA Enc=AES(256) Mac=SHA384 0xC0,0x28 - TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 - ECDHE-RSA-AES256-SHA384 TLSv1.2 Kx=ECDH Au=RSA Enc=AES(256) Mac=SHA384 0x00,0x6B - TLS_DHE_RSA_WITH_AES_256_CBC_SHA256 - DHE-RSA-AES256-SHA256 TLSv1.2 Kx=DH Au=RSA Enc=AES(256) Mac=SHA256 0xC0,0x23 - TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256 - ECDHE-ECDSA-AES128-SHA256 TLSv1.2 Kx=ECDH Au=ECDSA Enc=AES(128) Mac=SHA256 0xC0,0x27 - TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 - ECDHE-RSA-AES128-SHA256 TLSv1.2 Kx=ECDH Au=RSA Enc=AES(128) Mac=SHA256 0x00,0x67 - TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 - DHE-RSA-AES128-SHA256 TLSv1.2 Kx=DH Au=RSA Enc=AES(128) Mac=SHA256 0xC0,0x0A - TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA - ECDHE-ECDSA-AES256-SHA TLSv1 Kx=ECDH Au=ECDSA Enc=AES(256) Mac=SHA1 0xC0,0x14 - TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - ECDHE-RSA-AES256-SHA TLSv1 Kx=ECDH Au=RSA Enc=AES(256) Mac=SHA1 0x00,0x39 - TLS_DHE_RSA_WITH_AES_256_CBC_SHA - DHE-RSA-AES256-SHA SSLv3 Kx=DH Au=RSA Enc=AES(256) Mac=SHA1 0xC0,0x09 - TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA - ECDHE-ECDSA-AES128-SHA TLSv1 Kx=ECDH Au=ECDSA Enc=AES(128) Mac=SHA1 0xC0,0x13 - TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - ECDHE-RSA-AES128-SHA TLSv1 Kx=ECDH Au=RSA Enc=AES(128) Mac=SHA1 0x00,0x33 - TLS_DHE_RSA_WITH_AES_128_CBC_SHA - DHE-RSA-AES128-SHA SSLv3 Kx=DH Au=RSA Enc=AES(128) Mac=SHA1 0x00,0x9D - TLS_RSA_WITH_AES_256_GCM_SHA384 - AES256-GCM-SHA384 TLSv1.2 Kx=RSA Au=RSA Enc=AESGCM(256) Mac=AEAD 0x00,0x9C - TLS_RSA_WITH_AES_128_GCM_SHA256 - AES128-GCM-SHA256 TLSv1.2 Kx=RSA Au=RSA Enc=AESGCM(128) Mac=AEAD 0x00,0x3D - TLS_RSA_WITH_AES_256_CBC_SHA256 - AES256-SHA256 TLSv1.2 Kx=RSA Au=RSA Enc=AES(256) Mac=SHA256 0x00,0x3C - TLS_RSA_WITH_AES_128_CBC_SHA256 - AES128-SHA256 TLSv1.2 Kx=RSA Au=RSA Enc=AES(128) Mac=SHA256 0x00,0x35 - TLS_RSA_WITH_AES_256_CBC_SHA - AES256-SHA SSLv3 Kx=RSA Au=RSA Enc=AES(256) Mac=SHA1 0x00,0x2F - TLS_RSA_WITH_AES_128_CBC_SHA - AES128-SHA SSLv3 Kx=RSA Au=RSA Enc=AES(128) Mac=SHA1 En TLS 1.3, les ciphers support\u00e9s ne pr\u00e9cisent le protocole d'authentification. Il a donc sembl\u00e9 plus judicieux de l'\u00e9viter : root@6883307658b0:/app# openssl ciphers -tls1_3 -V -stdname -s 0x13,0x02 - TLS_AES_256_GCM_SHA384 - TLS_AES_256_GCM_SHA384 TLSv1.3 Kx=any Au=any Enc=AESGCM(256) Mac=AEAD 0x13,0x03 - TLS_CHACHA20_POLY1305_SHA256 - TLS_CHACHA20_POLY1305_SHA256 TLSv1.3 Kx=any Au=any Enc=CHACHA20/POLY1305(256) Mac=AEAD 0x13,0x01 - TLS_AES_128_GCM_SHA256 - TLS_AES_128_GCM_SHA256 TLSv1.3 Kx=any Au=any Enc=AESGCM(128) Mac=AEAD Variables d'environnement Variable Signification Default Docker CAFILE certificat d'autorit\u00e9 /var/run/secrets/KEYS/db_ca.x509 SERVER_CERT certificat du serveur /var/run/secrets/KEYS/civicrmdbproxy.x509 SERVER_KEY clef du certificat serveur /var/run/secrets/KEYS/civicrmdbproxy.pem SOCK chemin local de la socket /SOCK/mysqld.sock SERVER_PORT port d'\u00e9coute du serveur 443","title":"db_tls_server"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/db_tls_server.html#db_tls_server-ambassadeur-pour-connexion-tls","text":"Le r\u00f4le de cette image est de fournir une terminaison de tunnel TLS vers un serveur MySQL. On utilise socat \u00e0 cet effet. #!/bin/bash socat -d -d -d -D -t 50 -T 50 -lf /tmp/socat.txt OPENSSL-LISTEN: ${ SERVER_PORT } ,certificate = ${ SERVER_CERT } ,key = ${ SERVER_KEY } ,cafile = ${ CAFILE } ,verify = 1 ,fork,bind = 0 .0.0.0,pf = ip4,cipher = TLSv1.2 UNIX-CONNECT: ${ SOCK } Au niveau de la configuration, on retrouve des \u00e9l\u00e9ments connus comme les temporisations, et le d\u00e9buggage. En ce qui concerne la n\u00e9gociation TLS, on constate qu'une autorit\u00e9 de certification est utilis\u00e9e et que les certificats pr\u00e9sent\u00e9s au serveur doivent \u00eatre valides. Le choix du cipher TLSv1.2 n'est pas anodin : en effet, le choix du cipher conditionne les algorithmes utilisables lors de la connexion SSL, et les algorithmes de TLSv1.2 et support\u00e9s par openssl requi\u00e8reraient tous une authentification \u00e0 clef publique, si l'on s'en r\u00e9f\u00e8re \u00e0 la sortie de openssl ciphers , pour voir les ciphers support\u00e9s en tls1_2 : root@6883307658b0:/app# openssl ciphers -tls1_2 -V -stdname -s 0xC0,0x2C - TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 - ECDHE-ECDSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH Au=ECDSA Enc=AESGCM(256) Mac=AEAD 0xC0,0x30 - TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 - ECDHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH Au=RSA Enc=AESGCM(256) Mac=AEAD 0x00,0x9F - TLS_DHE_RSA_WITH_AES_256_GCM_SHA384 - DHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=DH Au=RSA Enc=AESGCM(256) Mac=AEAD 0xCC,0xA9 - TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 - ECDHE-ECDSA-CHACHA20-POLY1305 TLSv1.2 Kx=ECDH Au=ECDSA Enc=CHACHA20/POLY1305(256) Mac=AEAD 0xCC,0xA8 - TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256 - ECDHE-RSA-CHACHA20-POLY1305 TLSv1.2 Kx=ECDH Au=RSA Enc=CHACHA20/POLY1305(256) Mac=AEAD 0xCC,0xAA - TLS_DHE_RSA_WITH_CHACHA20_POLY1305_SHA256 - DHE-RSA-CHACHA20-POLY1305 TLSv1.2 Kx=DH Au=RSA Enc=CHACHA20/POLY1305(256) Mac=AEAD 0xC0,0x2B - TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 - ECDHE-ECDSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH Au=ECDSA Enc=AESGCM(128) Mac=AEAD 0xC0,0x2F - TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 - ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH Au=RSA Enc=AESGCM(128) Mac=AEAD 0x00,0x9E - TLS_DHE_RSA_WITH_AES_128_GCM_SHA256 - DHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=DH Au=RSA Enc=AESGCM(128) Mac=AEAD 0xC0,0x24 - TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384 - ECDHE-ECDSA-AES256-SHA384 TLSv1.2 Kx=ECDH Au=ECDSA Enc=AES(256) Mac=SHA384 0xC0,0x28 - TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 - ECDHE-RSA-AES256-SHA384 TLSv1.2 Kx=ECDH Au=RSA Enc=AES(256) Mac=SHA384 0x00,0x6B - TLS_DHE_RSA_WITH_AES_256_CBC_SHA256 - DHE-RSA-AES256-SHA256 TLSv1.2 Kx=DH Au=RSA Enc=AES(256) Mac=SHA256 0xC0,0x23 - TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256 - ECDHE-ECDSA-AES128-SHA256 TLSv1.2 Kx=ECDH Au=ECDSA Enc=AES(128) Mac=SHA256 0xC0,0x27 - TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 - ECDHE-RSA-AES128-SHA256 TLSv1.2 Kx=ECDH Au=RSA Enc=AES(128) Mac=SHA256 0x00,0x67 - TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 - DHE-RSA-AES128-SHA256 TLSv1.2 Kx=DH Au=RSA Enc=AES(128) Mac=SHA256 0xC0,0x0A - TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA - ECDHE-ECDSA-AES256-SHA TLSv1 Kx=ECDH Au=ECDSA Enc=AES(256) Mac=SHA1 0xC0,0x14 - TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - ECDHE-RSA-AES256-SHA TLSv1 Kx=ECDH Au=RSA Enc=AES(256) Mac=SHA1 0x00,0x39 - TLS_DHE_RSA_WITH_AES_256_CBC_SHA - DHE-RSA-AES256-SHA SSLv3 Kx=DH Au=RSA Enc=AES(256) Mac=SHA1 0xC0,0x09 - TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA - ECDHE-ECDSA-AES128-SHA TLSv1 Kx=ECDH Au=ECDSA Enc=AES(128) Mac=SHA1 0xC0,0x13 - TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - ECDHE-RSA-AES128-SHA TLSv1 Kx=ECDH Au=RSA Enc=AES(128) Mac=SHA1 0x00,0x33 - TLS_DHE_RSA_WITH_AES_128_CBC_SHA - DHE-RSA-AES128-SHA SSLv3 Kx=DH Au=RSA Enc=AES(128) Mac=SHA1 0x00,0x9D - TLS_RSA_WITH_AES_256_GCM_SHA384 - AES256-GCM-SHA384 TLSv1.2 Kx=RSA Au=RSA Enc=AESGCM(256) Mac=AEAD 0x00,0x9C - TLS_RSA_WITH_AES_128_GCM_SHA256 - AES128-GCM-SHA256 TLSv1.2 Kx=RSA Au=RSA Enc=AESGCM(128) Mac=AEAD 0x00,0x3D - TLS_RSA_WITH_AES_256_CBC_SHA256 - AES256-SHA256 TLSv1.2 Kx=RSA Au=RSA Enc=AES(256) Mac=SHA256 0x00,0x3C - TLS_RSA_WITH_AES_128_CBC_SHA256 - AES128-SHA256 TLSv1.2 Kx=RSA Au=RSA Enc=AES(128) Mac=SHA256 0x00,0x35 - TLS_RSA_WITH_AES_256_CBC_SHA - AES256-SHA SSLv3 Kx=RSA Au=RSA Enc=AES(256) Mac=SHA1 0x00,0x2F - TLS_RSA_WITH_AES_128_CBC_SHA - AES128-SHA SSLv3 Kx=RSA Au=RSA Enc=AES(128) Mac=SHA1 En TLS 1.3, les ciphers support\u00e9s ne pr\u00e9cisent le protocole d'authentification. Il a donc sembl\u00e9 plus judicieux de l'\u00e9viter : root@6883307658b0:/app# openssl ciphers -tls1_3 -V -stdname -s 0x13,0x02 - TLS_AES_256_GCM_SHA384 - TLS_AES_256_GCM_SHA384 TLSv1.3 Kx=any Au=any Enc=AESGCM(256) Mac=AEAD 0x13,0x03 - TLS_CHACHA20_POLY1305_SHA256 - TLS_CHACHA20_POLY1305_SHA256 TLSv1.3 Kx=any Au=any Enc=CHACHA20/POLY1305(256) Mac=AEAD 0x13,0x01 - TLS_AES_128_GCM_SHA256 - TLS_AES_128_GCM_SHA256 TLSv1.3 Kx=any Au=any Enc=AESGCM(128) Mac=AEAD","title":"DB_TLS_SERVER : ambassadeur pour connexion TLS"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/db_tls_server.html#variables-denvironnement","text":"Variable Signification Default Docker CAFILE certificat d'autorit\u00e9 /var/run/secrets/KEYS/db_ca.x509 SERVER_CERT certificat du serveur /var/run/secrets/KEYS/civicrmdbproxy.x509 SERVER_KEY clef du certificat serveur /var/run/secrets/KEYS/civicrmdbproxy.pem SOCK chemin local de la socket /SOCK/mysqld.sock SERVER_PORT port d'\u00e9coute du serveur 443","title":"Variables d'environnement"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/httpd.html","text":"Image HTTPD Cette image a pour vocation de faire tourner le serveur web interne. Elle d\u00e9rive de ubuntu/apache2 et int\u00e8gre des \u00e9l\u00e9ments issus d'images tierces par copie ( COPY --from dans le Dockerfile). FROM ubuntu/apache2 LABEL uepal.name = \"httpd\" uepal.version = \"0.0.1\" ENV INTERN_SERVERNAME = \"intern.civicrm.test\" INTERN_CA = \"/var/run/secrets/KEYS/ca.x509\" INTERN_CERT = \"/var/run/secrets/KEYS/intern.civicrm.test.x509\" INTERN_KEY = \"/var/run/secrets/KEYS/intern.civicrm.test.pem\" AUTH_CLIENT_CN = \"auth_client\" PROXY_CLIENT_CN = \"proxy_client\" AUTH_CONTEXT = \"/var/run/AUTH_CLIENT_CONFIG\" RUN groupadd -g 1000 -f paroisse && useradd -d /nonexistent -e 1 -g 1000 -u 1000 -M -N -s /usr/sbin/nologin paroisse && usermod -L paroisse && mkdir /exec && mkdir /var/run/AUTH_CLIENT_CONFIG && apt-get update && apt-get full-upgrade -y && export DEBIAN_FRONTEND = noninteractive && ln -fs /usr/share/zoneinfo/Europe/Paris /etc/localtime && apt-get install -y tzdata && dpkg-reconfigure --frontend noninteractive tzdata && apt-get install -y php8.1 php8.1-cli php8.1-curl php8.1-gd php8.1-intl php8.1-mysql php8.1-opcache php8.1-xml php8.1-bcmath php8.1-mbstring php8.1-soap php8.1-xsl php8.1-zip && apt-get remove --purge --auto-remove -y && rm -rf /var/lib/apt/lists && mkdir /app && mkdir /AUTH && install -d /var/run/secrets/KEYS COPY --from = uepal_test/selfkeys /KEYS/USAGE/intern* /var/run/secrets/KEYS/ COPY --from = uepal_test/selfkeys /KEYS/USAGE/ca* /var/run/secrets/KEYS/ COPY --from = uepal_test/composer_files /app /app/ COPY civicrm.conf /etc/apache2/sites-available/ RUN service apache2 stop && a2enmod ssl && a2enmod rewrite && a2ensite civicrm && chown root:root /etc/apache2/sites-available/civicrm.conf && chmod 400 /etc/apache2/sites-available/civicrm.conf && chown -R root:root /var/run/secrets/KEYS && chgrp www-data /var/run/secrets/KEYS && chmod 510 /var/run/secrets/KEYS && chmod 440 /var/run/secrets/KEYS/* VOLUME /app/web/sites /app/private EXPOSE 444 Variables d'environnement Variable Description Valeur par d\u00e9faut INTERN_SERVERNAME Nom du serveur interne \"intern.civicrm.test\" INTERN_CA Chemin du CA interne \"/var/run/secrets/KEYS/ca.x509\" INTERN_KEY Chemin de la clef li\u00e9e au certificat \"/var/run/secrets/KEYS/intern.civicrm.test.pem\" AUTH_CLIENT_CN Common name de l'authenticateur \"auth_client\" PROXY_CLIENT_CN Common name du client du reverse-proxy \"proxy_client\" AUTH_CONTEXT Contexte pass\u00e9 \u00e0 l'authenticateur \"/var/run/AUTH_CLIENT_CONFIG\" Configuration d'Apache La configuration d'Apache a une particularit\u00e9 : la grande utilisation des variables d'environnements d\u00e9clar\u00e9es : on retrouve cette possibilit\u00e9 dans la documentation Apache ( https://httpd.apache.org/docs/current/fr/env.html ). On force une authentification via certificat SSL, et on force en plus que le common name du certificat soit dans une liste d\u00e9finie (certificat issu pour l'authenticateur ou le reverse-proxy partie client). Listen 0.0.0.0 :444 <VirtualHost 0.0.0.0:444 > ServerName ${INTERN_SERVERNAME} DocumentRoot /app/web <Directory /app/web > AllowOverride All SSLRequireSSL <RequireAll> Require ssl Require expr \"(%{SSL_CLIENT_S_DN_CN} in {%{ENV:AUTH_CLIENT_CN},%{ENV:PROXY_CLIENT_CN}})\" </RequireAll> </Directory> SSLEngine on SSLCACertificateFile ${INTERN_CA} SSLCertificateFile ${INTERN_CERT} SSLCertificateKeyFile ${INTERN_KEY} SSLCipherSuite HIGH:!aNULL:!MD5 SSLOptions +StrictRequire SSLVerifyClient require </VirtualHost>","title":"httpd"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/httpd.html#image-httpd","text":"Cette image a pour vocation de faire tourner le serveur web interne. Elle d\u00e9rive de ubuntu/apache2 et int\u00e8gre des \u00e9l\u00e9ments issus d'images tierces par copie ( COPY --from dans le Dockerfile). FROM ubuntu/apache2 LABEL uepal.name = \"httpd\" uepal.version = \"0.0.1\" ENV INTERN_SERVERNAME = \"intern.civicrm.test\" INTERN_CA = \"/var/run/secrets/KEYS/ca.x509\" INTERN_CERT = \"/var/run/secrets/KEYS/intern.civicrm.test.x509\" INTERN_KEY = \"/var/run/secrets/KEYS/intern.civicrm.test.pem\" AUTH_CLIENT_CN = \"auth_client\" PROXY_CLIENT_CN = \"proxy_client\" AUTH_CONTEXT = \"/var/run/AUTH_CLIENT_CONFIG\" RUN groupadd -g 1000 -f paroisse && useradd -d /nonexistent -e 1 -g 1000 -u 1000 -M -N -s /usr/sbin/nologin paroisse && usermod -L paroisse && mkdir /exec && mkdir /var/run/AUTH_CLIENT_CONFIG && apt-get update && apt-get full-upgrade -y && export DEBIAN_FRONTEND = noninteractive && ln -fs /usr/share/zoneinfo/Europe/Paris /etc/localtime && apt-get install -y tzdata && dpkg-reconfigure --frontend noninteractive tzdata && apt-get install -y php8.1 php8.1-cli php8.1-curl php8.1-gd php8.1-intl php8.1-mysql php8.1-opcache php8.1-xml php8.1-bcmath php8.1-mbstring php8.1-soap php8.1-xsl php8.1-zip && apt-get remove --purge --auto-remove -y && rm -rf /var/lib/apt/lists && mkdir /app && mkdir /AUTH && install -d /var/run/secrets/KEYS COPY --from = uepal_test/selfkeys /KEYS/USAGE/intern* /var/run/secrets/KEYS/ COPY --from = uepal_test/selfkeys /KEYS/USAGE/ca* /var/run/secrets/KEYS/ COPY --from = uepal_test/composer_files /app /app/ COPY civicrm.conf /etc/apache2/sites-available/ RUN service apache2 stop && a2enmod ssl && a2enmod rewrite && a2ensite civicrm && chown root:root /etc/apache2/sites-available/civicrm.conf && chmod 400 /etc/apache2/sites-available/civicrm.conf && chown -R root:root /var/run/secrets/KEYS && chgrp www-data /var/run/secrets/KEYS && chmod 510 /var/run/secrets/KEYS && chmod 440 /var/run/secrets/KEYS/* VOLUME /app/web/sites /app/private EXPOSE 444","title":"Image HTTPD"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/httpd.html#variables-denvironnement","text":"Variable Description Valeur par d\u00e9faut INTERN_SERVERNAME Nom du serveur interne \"intern.civicrm.test\" INTERN_CA Chemin du CA interne \"/var/run/secrets/KEYS/ca.x509\" INTERN_KEY Chemin de la clef li\u00e9e au certificat \"/var/run/secrets/KEYS/intern.civicrm.test.pem\" AUTH_CLIENT_CN Common name de l'authenticateur \"auth_client\" PROXY_CLIENT_CN Common name du client du reverse-proxy \"proxy_client\" AUTH_CONTEXT Contexte pass\u00e9 \u00e0 l'authenticateur \"/var/run/AUTH_CLIENT_CONFIG\"","title":"Variables d'environnement"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/httpd.html#configuration-dapache","text":"La configuration d'Apache a une particularit\u00e9 : la grande utilisation des variables d'environnements d\u00e9clar\u00e9es : on retrouve cette possibilit\u00e9 dans la documentation Apache ( https://httpd.apache.org/docs/current/fr/env.html ). On force une authentification via certificat SSL, et on force en plus que le common name du certificat soit dans une liste d\u00e9finie (certificat issu pour l'authenticateur ou le reverse-proxy partie client). Listen 0.0.0.0 :444 <VirtualHost 0.0.0.0:444 > ServerName ${INTERN_SERVERNAME} DocumentRoot /app/web <Directory /app/web > AllowOverride All SSLRequireSSL <RequireAll> Require ssl Require expr \"(%{SSL_CLIENT_S_DN_CN} in {%{ENV:AUTH_CLIENT_CN},%{ENV:PROXY_CLIENT_CN}})\" </RequireAll> </Directory> SSLEngine on SSLCACertificateFile ${INTERN_CA} SSLCertificateFile ${INTERN_CERT} SSLCertificateKeyFile ${INTERN_KEY} SSLCipherSuite HIGH:!aNULL:!MD5 SSLOptions +StrictRequire SSLVerifyClient require </VirtualHost>","title":"Configuration d'Apache"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/init.html","text":"Image init Description Cette image est pr\u00e9vue pour initialiser les volumes d'une instance. Elle est pr\u00e9vue pour effectuer les t\u00e2ches d'installation sp\u00e9cifi\u00e9es dans un script shell, utilisant grandement les variables d'environnement. Les secrets (dont mots de passe) sont sens\u00e9s \u00eatre pass\u00e9s via des fichiers mont\u00e9s dans l'environnement du container, comme ce qui est pr\u00e9vu dans Kubernetes pour la mise \u00e0 disposition des secrets, ce qui permet d'ailleurs la personnalisation des installations. A noter que si les volumes ne sont pas vides, le script est pr\u00e9vu pour ne rien faire. FROM uepal_test/tools LABEL uepal.name = \"init\" uepal.version = \"0.0.1\" ENV PAROISSE_NAME = \"Paroisse Uepal de test\" PAROISSE_ADDR = \"1b,quai Saint Thomas\" PAROISSE_CITY = \"Strasbourg\" PAROISSE_PHONE = \"0011223344\" PAROISSE_ZIPCODE = \"67000\" CIVI_DOMAIN = \"DomaineParoisse\" DBNAME_CIVICRM = \"civicrm\" DBNAME_DRUPAL = \"drupal\" DBNAME_CIVILOG = \"civilog\" DBHOST = \"civicrmdb\" DBUSER = \"exploitant\" DBSECRET = \"dbsecret\" DRUPAL_ADMIN_USER_SECRET = \"drupal_user\" DRUPAL_ADMIN_PASSWORD_SECRET = \"drupal_password\" SERVERNAME = \"civicrm.test\" TRUSTED_HOST_PATTERNS = \"['^civicrm\\\\.test $ ','^intern\\\\.civicrm\\\\.test $ ']\" MAILADMIN_ADDR = \"admin@civicrm.test\" MAILADMIN_NAME = \"Admin ADMIN\" MAILADMIN_DESCR = \"mail admin descr\" MAILDIR = \"/maildir\" SITENAME = \"Site de test civicrm\" RUN rsync -av /app/web/sites/ /app/web/sites_orig && rsync -av /var/lib/mysql/ /var/lib/mysql_orig && rm -Rf /app/web/sites/* && rm -Rf /var/lib/mysql/* COPY exec.sh /exec/exec.sh COPY secrets /var/run/secrets/ RUN chown -R root:root /exec && chmod -R 500 /exec && chown -R root:root /var/run/secrets && find /var/run/secrets -type f -exec chmod 400 '{}' \\; && find /var/run/secrets -type d -exec chmod 500 '{}' \\; Variables d'environnement Variable Signification Default Docker PAROISSE_NAME Nom de la paroisse \"Paroisse Uepal de test\" PAROISSE_ADDR Adresse de la paroisse \"1b,quai Saint Thomas\" PAROISSE_CITY Ville de la paroisse \"Strasbourg\" PAROISSE_PHONE Num\u00e9ro de t\u00e9l\u00e9phone de la paroisse \"0011223344\" PAROISSE_ZIPCODE Code postal de la paroisse \"67000\" CIVI_DOMAIN Nom du domaine civicrm \"DomaineParoisse\" DBNAME_CIVICRM Nom DB CiviCRM \"civicrm\" DBNAME_DRUPAL Nom DB Drupal \"drupal\" DBNAME_CIVILOG Nom DB Audit CiviCRM \"civilog\" DBHOST Hote base de donn\u00e9es \"civicrmdb\" DBUSER Utilisateur au niveau des BD mysql \"exploitant\" DBSECRET Nom du secret pour le mot de passe \"dbsecret\" DRUPAL_ADMIN_USER_SECRET Nom du secret pour l'utilisateur administrateur Drupal \"drupal_user\" DRUPAL_ADMIN_PASSWORD_SECRET Nom du secret pour le mot de passe administrateur Drupal \"drupal_password\" SERVERNAME Nom du serveur externe \"civicrm.test\" TRUSTED_HOST_PATTERNS Patterns de hosts autoris\u00e9s pour Drupal \"['^civicrm\\.test$','^intern\\.civicrm\\.test$']\" MAILADMIN_ADDR Adresse mail de l'administrateur \"admin@civicrm.test\" MAILADMIN_NAME Nom de l'administrateur pour l'adresse mail \"Admin ADMIN\" MAILADMIN_DESCR Description de l'adresse mail admin \"mail admin descr\" MAILDIR Path du r\u00e9pertoire de mails entrants (maildir) \"/maildir\" SITENAME Nom du site \"Site de test civicrm\" RAF Am\u00e9liorer les trusted_host_patterns, pour rajouter le \"intern\" en dur, en plus des autres patterns. S'occuper du MAILDIR (pas dans l'image init, mais dans le reste : Docker et Helm)","title":"init"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/init.html#image-init","text":"","title":"Image init"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/init.html#description","text":"Cette image est pr\u00e9vue pour initialiser les volumes d'une instance. Elle est pr\u00e9vue pour effectuer les t\u00e2ches d'installation sp\u00e9cifi\u00e9es dans un script shell, utilisant grandement les variables d'environnement. Les secrets (dont mots de passe) sont sens\u00e9s \u00eatre pass\u00e9s via des fichiers mont\u00e9s dans l'environnement du container, comme ce qui est pr\u00e9vu dans Kubernetes pour la mise \u00e0 disposition des secrets, ce qui permet d'ailleurs la personnalisation des installations. A noter que si les volumes ne sont pas vides, le script est pr\u00e9vu pour ne rien faire. FROM uepal_test/tools LABEL uepal.name = \"init\" uepal.version = \"0.0.1\" ENV PAROISSE_NAME = \"Paroisse Uepal de test\" PAROISSE_ADDR = \"1b,quai Saint Thomas\" PAROISSE_CITY = \"Strasbourg\" PAROISSE_PHONE = \"0011223344\" PAROISSE_ZIPCODE = \"67000\" CIVI_DOMAIN = \"DomaineParoisse\" DBNAME_CIVICRM = \"civicrm\" DBNAME_DRUPAL = \"drupal\" DBNAME_CIVILOG = \"civilog\" DBHOST = \"civicrmdb\" DBUSER = \"exploitant\" DBSECRET = \"dbsecret\" DRUPAL_ADMIN_USER_SECRET = \"drupal_user\" DRUPAL_ADMIN_PASSWORD_SECRET = \"drupal_password\" SERVERNAME = \"civicrm.test\" TRUSTED_HOST_PATTERNS = \"['^civicrm\\\\.test $ ','^intern\\\\.civicrm\\\\.test $ ']\" MAILADMIN_ADDR = \"admin@civicrm.test\" MAILADMIN_NAME = \"Admin ADMIN\" MAILADMIN_DESCR = \"mail admin descr\" MAILDIR = \"/maildir\" SITENAME = \"Site de test civicrm\" RUN rsync -av /app/web/sites/ /app/web/sites_orig && rsync -av /var/lib/mysql/ /var/lib/mysql_orig && rm -Rf /app/web/sites/* && rm -Rf /var/lib/mysql/* COPY exec.sh /exec/exec.sh COPY secrets /var/run/secrets/ RUN chown -R root:root /exec && chmod -R 500 /exec && chown -R root:root /var/run/secrets && find /var/run/secrets -type f -exec chmod 400 '{}' \\; && find /var/run/secrets -type d -exec chmod 500 '{}' \\;","title":"Description"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/init.html#variables-denvironnement","text":"Variable Signification Default Docker PAROISSE_NAME Nom de la paroisse \"Paroisse Uepal de test\" PAROISSE_ADDR Adresse de la paroisse \"1b,quai Saint Thomas\" PAROISSE_CITY Ville de la paroisse \"Strasbourg\" PAROISSE_PHONE Num\u00e9ro de t\u00e9l\u00e9phone de la paroisse \"0011223344\" PAROISSE_ZIPCODE Code postal de la paroisse \"67000\" CIVI_DOMAIN Nom du domaine civicrm \"DomaineParoisse\" DBNAME_CIVICRM Nom DB CiviCRM \"civicrm\" DBNAME_DRUPAL Nom DB Drupal \"drupal\" DBNAME_CIVILOG Nom DB Audit CiviCRM \"civilog\" DBHOST Hote base de donn\u00e9es \"civicrmdb\" DBUSER Utilisateur au niveau des BD mysql \"exploitant\" DBSECRET Nom du secret pour le mot de passe \"dbsecret\" DRUPAL_ADMIN_USER_SECRET Nom du secret pour l'utilisateur administrateur Drupal \"drupal_user\" DRUPAL_ADMIN_PASSWORD_SECRET Nom du secret pour le mot de passe administrateur Drupal \"drupal_password\" SERVERNAME Nom du serveur externe \"civicrm.test\" TRUSTED_HOST_PATTERNS Patterns de hosts autoris\u00e9s pour Drupal \"['^civicrm\\.test$','^intern\\.civicrm\\.test$']\" MAILADMIN_ADDR Adresse mail de l'administrateur \"admin@civicrm.test\" MAILADMIN_NAME Nom de l'administrateur pour l'adresse mail \"Admin ADMIN\" MAILADMIN_DESCR Description de l'adresse mail admin \"mail admin descr\" MAILDIR Path du r\u00e9pertoire de mails entrants (maildir) \"/maildir\" SITENAME Nom du site \"Site de test civicrm\"","title":"Variables d'environnement"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/init.html#raf","text":"Am\u00e9liorer les trusted_host_patterns, pour rajouter le \"intern\" en dur, en plus des autres patterns. S'occuper du MAILDIR (pas dans l'image init, mais dans le reste : Docker et Helm)","title":"RAF"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/proxy.html","text":"Reverse-proxy Le reverse proxy permet de requ\u00e9rir l'authentification sur l'ensemble des requ\u00eates entrantes. Il dispose d'un acc\u00e8s au serveur web interne via la un certificat (proxy client). Il est \u00e0 noter que l'utilisation de deux certificats diff\u00e9rents (authenticator pour l'authenticateur, et proxy pour le proxy) et de deux containers diff\u00e9rents se justifie : lorsqu'Apache d\u00e9marre, il utilise ses droits root pour la lecture des fichiers, dont les fichiers de clefs, tandis que les clefs sont ex\u00e9cut\u00e9es via www-data, qui n'a donc plus le droit aux fichiers de clefs (tant que les droits sont bien positionn\u00e9s). Le script d'authentification fonctionne \u00e9galement gr\u00e2ce au compte www-data ; or, on ne veut pas qu'un \u00e9ventuel attaquant qui aurait pris le contr\u00f4le de www-data puisse avoir acc\u00e8s au certificat : d'o\u00f9 l'utilisation de l'autre container et de la socket pour introduire une s\u00e9paration,et la protection du certificat de l'authenticateur. FROM ubuntu/apache2 LABEL uepal.name = \"proxy\" uepal.version = \"0.0.1\" ENV SERVERNAME = \"civicrm.test\" INTERN_SERVERNAME = \"intern.civicrm.test\" SERVER_CERT = \"/var/run/secrets/KEYS/civicrm.test.x509\" SERVER_KEY = \"/var/run/secrets/KEYS/civicrm.test.pem\" PROXY_MACHINE_CERT = \"/var/run/secrets/KEYS/proxy_client_unified.pem\" PROXY_CA = \"/var/run/secrets/KEYS/ca.x509\" AUTH_CONTEXT = \"/var/run/AUTH_CLIENT_CONFIG\" RUN groupadd -g 1000 -f paroisse && useradd -d /nonexistent -e 1 -g 1000 -u 1000 -M -N -s /usr/sbin/nologin paroisse && usermod -L paroisse && mkdir /exec && mkdir /var/run/AUTH_CLIENT_CONFIG && apt-get update && apt-get full-upgrade -y && export DEBIAN_FRONTEND = noninteractive && ln -fs /usr/share/zoneinfo/Europe/Paris /etc/localtime && apt-get install -y tzdata && dpkg-reconfigure --frontend noninteractive tzdata && apt-get install -y libapache2-mod-authnz-external socat && apt-get remove --purge --auto-remove -y && rm -rf /var/lib/apt/lists && mkdir /app && mkdir /AUTH && install -d /var/run/secrets/KEYS COPY AUTH/* AUTH/ COPY --from = uepal_test/selfkeys /KEYS/USAGE/civicrm.test.* /var/run/secrets/KEYS/ COPY --from = uepal_test/selfkeys /KEYS/USAGE/proxy_client_unified.pem /var/run/secrets/KEYS/ COPY --from = uepal_test/selfkeys /KEYS/USAGE/ca.x509 /var/run/secrets/KEYS/ COPY proxy.conf /etc/apache2/sites-available/ RUN service apache2 stop && a2enmod authnz_external && a2enmod proxy && a2enmod proxy_http && a2enmod ssl && a2enmod rewrite && a2ensite proxy RUN chown root:root /etc/apache2/sites-available/proxy.conf && chmod 400 /etc/apache2/sites-available/proxy.conf && chown -R paroisse:www-data /AUTH && chmod 550 -R /AUTH && chown -R root:root /var/run/secrets/KEYS && chmod 500 /var/run/secrets/KEYS && chmod 400 /var/run/secrets/KEYS/* EXPOSE 443 VOLUME /authenticator Variables d'environnement Nom Description Valeur par d\u00e9faut SERVERNAME nom externe du serveur \"civicrm.test\" INTERN_SERVERNAME nom du serveur interne \"intern.civicrm.test\" SERVER_CERT certificat du serveur externe \"/var/run/secrets/KEYS/civicrm.test.x509\" SERVER_KEY clef priv\u00e9e associ\u00e9e au certificat du serveure externe \"/var/run/secrets/KEYS/civicrm.test.pem\" PROXY_MACHINE_CERT certificat et clef pour la partie client interne vers le serveur interne \"/var/run/secrets/KEYS/proxy_client_unified.pem\" PROXY_CA CA vis \u00e0 vis de la communication vers le serveur interne \"/var/run/secrets/KEYS/ca.x509\" AUTH_CONTEXT contexte d'authentification : r\u00e9pertoire o\u00f9 se trouve la configuration \"/var/run/AUTH_CLIENT_CONFIG\" Configuration Apache La configuration Apache utilise les variables d'environnement (voir https://httpd.apache.org/docs/current/fr/env.html ). Pour le moment, l'utilisation du SSL est requise, mais une authentification par certificat n'a pas encore \u00e9t\u00e9 d\u00e9cid\u00e9e (m\u00eame si elle a \u00e9t\u00e9 \u00e9tudi\u00e9e dans l'\u00e9tude d'authentification ). Les ports ont \u00e9t\u00e9 forc\u00e9s : 443 pour le reverse proxy 444 pour le serveur interne Cela est encore un reste de la configuration en image unique regroupant reverse-proxy, authenticateur et serveur web interne. <VirtualHost 0.0.0.0:443 > ServerName ${SERVERNAME} AddExternalAuth dea \"/AUTH/externalauth.sh\" SetExternalAuthMethod dea pipe SSLEngine on SSLCertificateFile ${SERVER_CERT} SSLCertificateKeyFile ${SERVER_KEY} SSLCipherSuite HIGH:!aNULL:!MD5 SSLOptions +StrictRequire SSLProxyVerify require SSLProxyMachineCertificateFile ${PROXY_MACHINE_CERT} SSLProxyCACertificateFile ${PROXY_CA} SSLProxyCheckPeerCN on SSLProxyCheckPeerName on SSLProxyVerify require SSLProxyEngine on SSLOptions +StrictRequire SSLVerifyClient none <Location \"/\" > AuthExternalContext ${AUTH_CONTEXT} <RequireAll> Require ssl Require valid-user </RequireAll> AuthType Basic AuthName \"Civiparoisse\" AuthBasicProvider external AuthExternal dea AuthBasicAuthoritative on </Location> ProxyPass \"/\" \"https://${INTERN_SERVERNAME}:444/\" </VirtualHost> Script d'authentification L'import avec le script d'authentification est la valeur de sortie (z\u00e9ro ou diff\u00e9rent de z\u00e9ro). La valeur du retour \u00e0 utiliser est pass\u00e9e sur la communication socket vers l'authenticateur. Les timeouts avec des temps relativement \u00e9lev\u00e9s sont une pr\u00e9caution qui a permis de r\u00e9soudre un probl\u00e8me lors des tests, probl\u00e8me qui pourrait vraisemblablement se retrouver nettement moins fr\u00e9quemment en production : lorsqu'un c\u00f4t\u00e9 de la communication socket ferme son flux, une temporisation est d\u00e9clench\u00e9e par socat pour fermer l'autre c\u00f4t\u00e9 du flux : cette temporisation \u00e9tait insuffisante pour le traitement de la requ\u00eate pendant les tests, d'o\u00f9 l'augmentation de la temporisation \u00e0 une valeur haute (50 secondes). #!/bin/bash result = ` socat -d -d -d -D -t 50 -T 50 -lf /tmp/socat.txt STDIO UNIX-CONNECT:/authentication/authenticator ` echo \"BOF $result EOF\" if [[ \" $result \" = \"0\" ]] then exit 0 fi exit 8 RAF A voir si on conserve les logs et le niveau de d\u00e9bug. Voir aussi pour un Web Application Firewall","title":"proxy"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/proxy.html#reverse-proxy","text":"Le reverse proxy permet de requ\u00e9rir l'authentification sur l'ensemble des requ\u00eates entrantes. Il dispose d'un acc\u00e8s au serveur web interne via la un certificat (proxy client). Il est \u00e0 noter que l'utilisation de deux certificats diff\u00e9rents (authenticator pour l'authenticateur, et proxy pour le proxy) et de deux containers diff\u00e9rents se justifie : lorsqu'Apache d\u00e9marre, il utilise ses droits root pour la lecture des fichiers, dont les fichiers de clefs, tandis que les clefs sont ex\u00e9cut\u00e9es via www-data, qui n'a donc plus le droit aux fichiers de clefs (tant que les droits sont bien positionn\u00e9s). Le script d'authentification fonctionne \u00e9galement gr\u00e2ce au compte www-data ; or, on ne veut pas qu'un \u00e9ventuel attaquant qui aurait pris le contr\u00f4le de www-data puisse avoir acc\u00e8s au certificat : d'o\u00f9 l'utilisation de l'autre container et de la socket pour introduire une s\u00e9paration,et la protection du certificat de l'authenticateur. FROM ubuntu/apache2 LABEL uepal.name = \"proxy\" uepal.version = \"0.0.1\" ENV SERVERNAME = \"civicrm.test\" INTERN_SERVERNAME = \"intern.civicrm.test\" SERVER_CERT = \"/var/run/secrets/KEYS/civicrm.test.x509\" SERVER_KEY = \"/var/run/secrets/KEYS/civicrm.test.pem\" PROXY_MACHINE_CERT = \"/var/run/secrets/KEYS/proxy_client_unified.pem\" PROXY_CA = \"/var/run/secrets/KEYS/ca.x509\" AUTH_CONTEXT = \"/var/run/AUTH_CLIENT_CONFIG\" RUN groupadd -g 1000 -f paroisse && useradd -d /nonexistent -e 1 -g 1000 -u 1000 -M -N -s /usr/sbin/nologin paroisse && usermod -L paroisse && mkdir /exec && mkdir /var/run/AUTH_CLIENT_CONFIG && apt-get update && apt-get full-upgrade -y && export DEBIAN_FRONTEND = noninteractive && ln -fs /usr/share/zoneinfo/Europe/Paris /etc/localtime && apt-get install -y tzdata && dpkg-reconfigure --frontend noninteractive tzdata && apt-get install -y libapache2-mod-authnz-external socat && apt-get remove --purge --auto-remove -y && rm -rf /var/lib/apt/lists && mkdir /app && mkdir /AUTH && install -d /var/run/secrets/KEYS COPY AUTH/* AUTH/ COPY --from = uepal_test/selfkeys /KEYS/USAGE/civicrm.test.* /var/run/secrets/KEYS/ COPY --from = uepal_test/selfkeys /KEYS/USAGE/proxy_client_unified.pem /var/run/secrets/KEYS/ COPY --from = uepal_test/selfkeys /KEYS/USAGE/ca.x509 /var/run/secrets/KEYS/ COPY proxy.conf /etc/apache2/sites-available/ RUN service apache2 stop && a2enmod authnz_external && a2enmod proxy && a2enmod proxy_http && a2enmod ssl && a2enmod rewrite && a2ensite proxy RUN chown root:root /etc/apache2/sites-available/proxy.conf && chmod 400 /etc/apache2/sites-available/proxy.conf && chown -R paroisse:www-data /AUTH && chmod 550 -R /AUTH && chown -R root:root /var/run/secrets/KEYS && chmod 500 /var/run/secrets/KEYS && chmod 400 /var/run/secrets/KEYS/* EXPOSE 443 VOLUME /authenticator","title":"Reverse-proxy"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/proxy.html#variables-denvironnement","text":"Nom Description Valeur par d\u00e9faut SERVERNAME nom externe du serveur \"civicrm.test\" INTERN_SERVERNAME nom du serveur interne \"intern.civicrm.test\" SERVER_CERT certificat du serveur externe \"/var/run/secrets/KEYS/civicrm.test.x509\" SERVER_KEY clef priv\u00e9e associ\u00e9e au certificat du serveure externe \"/var/run/secrets/KEYS/civicrm.test.pem\" PROXY_MACHINE_CERT certificat et clef pour la partie client interne vers le serveur interne \"/var/run/secrets/KEYS/proxy_client_unified.pem\" PROXY_CA CA vis \u00e0 vis de la communication vers le serveur interne \"/var/run/secrets/KEYS/ca.x509\" AUTH_CONTEXT contexte d'authentification : r\u00e9pertoire o\u00f9 se trouve la configuration \"/var/run/AUTH_CLIENT_CONFIG\"","title":"Variables d'environnement"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/proxy.html#configuration-apache","text":"La configuration Apache utilise les variables d'environnement (voir https://httpd.apache.org/docs/current/fr/env.html ). Pour le moment, l'utilisation du SSL est requise, mais une authentification par certificat n'a pas encore \u00e9t\u00e9 d\u00e9cid\u00e9e (m\u00eame si elle a \u00e9t\u00e9 \u00e9tudi\u00e9e dans l'\u00e9tude d'authentification ). Les ports ont \u00e9t\u00e9 forc\u00e9s : 443 pour le reverse proxy 444 pour le serveur interne Cela est encore un reste de la configuration en image unique regroupant reverse-proxy, authenticateur et serveur web interne. <VirtualHost 0.0.0.0:443 > ServerName ${SERVERNAME} AddExternalAuth dea \"/AUTH/externalauth.sh\" SetExternalAuthMethod dea pipe SSLEngine on SSLCertificateFile ${SERVER_CERT} SSLCertificateKeyFile ${SERVER_KEY} SSLCipherSuite HIGH:!aNULL:!MD5 SSLOptions +StrictRequire SSLProxyVerify require SSLProxyMachineCertificateFile ${PROXY_MACHINE_CERT} SSLProxyCACertificateFile ${PROXY_CA} SSLProxyCheckPeerCN on SSLProxyCheckPeerName on SSLProxyVerify require SSLProxyEngine on SSLOptions +StrictRequire SSLVerifyClient none <Location \"/\" > AuthExternalContext ${AUTH_CONTEXT} <RequireAll> Require ssl Require valid-user </RequireAll> AuthType Basic AuthName \"Civiparoisse\" AuthBasicProvider external AuthExternal dea AuthBasicAuthoritative on </Location> ProxyPass \"/\" \"https://${INTERN_SERVERNAME}:444/\" </VirtualHost>","title":"Configuration Apache"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/proxy.html#script-dauthentification","text":"L'import avec le script d'authentification est la valeur de sortie (z\u00e9ro ou diff\u00e9rent de z\u00e9ro). La valeur du retour \u00e0 utiliser est pass\u00e9e sur la communication socket vers l'authenticateur. Les timeouts avec des temps relativement \u00e9lev\u00e9s sont une pr\u00e9caution qui a permis de r\u00e9soudre un probl\u00e8me lors des tests, probl\u00e8me qui pourrait vraisemblablement se retrouver nettement moins fr\u00e9quemment en production : lorsqu'un c\u00f4t\u00e9 de la communication socket ferme son flux, une temporisation est d\u00e9clench\u00e9e par socat pour fermer l'autre c\u00f4t\u00e9 du flux : cette temporisation \u00e9tait insuffisante pour le traitement de la requ\u00eate pendant les tests, d'o\u00f9 l'augmentation de la temporisation \u00e0 une valeur haute (50 secondes). #!/bin/bash result = ` socat -d -d -d -D -t 50 -T 50 -lf /tmp/socat.txt STDIO UNIX-CONNECT:/authentication/authenticator ` echo \"BOF $result EOF\" if [[ \" $result \" = \"0\" ]] then exit 0 fi exit 8","title":"Script d'authentification"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/proxy.html#raf","text":"A voir si on conserve les logs et le niveau de d\u00e9bug. Voir aussi pour un Web Application Firewall","title":"RAF"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/selfkeys.html","text":"Selfkeys Cette image permet uniquement de g\u00e9n\u00e9rer une hi\u00e9rarchie de certificats SSL pour faire un CA autosign\u00e9 et des certificats qui vont utiliser ce CA comme racine. La cr\u00e9ation de l'image Docker ne va pas cr\u00e9er les fichiers de clefs : le script keys.sh doit \u00eatre lanc\u00e9 pour g\u00e9n\u00e9rer les fichiers. Ceci est fait expr\u00e8s, pour pouvoir rebuilder une image avec les m\u00eames clefs. En effet, l'image a en plus le (bon) go\u00fbt de ne pas embarquer la clef priv\u00e9e CA : du coup, il n'est pas possible de g\u00e9n\u00e9rer d'autres certitificats avec le CA comme racine. A noter que les certificats pr\u00e9vus pour les serveurs sont d\u00f4t\u00e9s d'un subjectAltName, comme cela semble \u00eatre requis pour Chromium. FROM ubuntu LABEL uepal.name = \"keys\" uepal.version = \"0.0.1\" RUN mkdir /KEYS && mkdir /KEYS/USAGE && chmod -R 500 /KEYS && apt-get update && apt-get full-upgrade -y && apt-get remove --purge --auto-remove -y && rm -rf /var/lib/apt/lists COPY USAGE/* /KEYS/USAGE/ WORKDIR /KEYS CMD [ \"/bin/bash\" , \"-c\" , \"echo 'Hello KEYS'\" ] Certificats g\u00e9n\u00e9r\u00e9s Les certificats g\u00e9n\u00e9r\u00e9s sont les suivants : ca : certificat d'authorit\u00e9 intern.civicrm.test: certificat pour le serveur web interne (httpd) civicrm.test : certificat pour le reverse-proxy, pr\u00e9sent\u00e9 \u00e0 l'ext\u00e9rieur proxy_client : certificat pour le reverse-proxy, pr\u00e9sent\u00e9 au serveur web interne auth_client : certificat pour l'authenticateur, pr\u00e9sent\u00e9 au serveur web interne","title":"selfkeys"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/selfkeys.html#selfkeys","text":"Cette image permet uniquement de g\u00e9n\u00e9rer une hi\u00e9rarchie de certificats SSL pour faire un CA autosign\u00e9 et des certificats qui vont utiliser ce CA comme racine. La cr\u00e9ation de l'image Docker ne va pas cr\u00e9er les fichiers de clefs : le script keys.sh doit \u00eatre lanc\u00e9 pour g\u00e9n\u00e9rer les fichiers. Ceci est fait expr\u00e8s, pour pouvoir rebuilder une image avec les m\u00eames clefs. En effet, l'image a en plus le (bon) go\u00fbt de ne pas embarquer la clef priv\u00e9e CA : du coup, il n'est pas possible de g\u00e9n\u00e9rer d'autres certitificats avec le CA comme racine. A noter que les certificats pr\u00e9vus pour les serveurs sont d\u00f4t\u00e9s d'un subjectAltName, comme cela semble \u00eatre requis pour Chromium. FROM ubuntu LABEL uepal.name = \"keys\" uepal.version = \"0.0.1\" RUN mkdir /KEYS && mkdir /KEYS/USAGE && chmod -R 500 /KEYS && apt-get update && apt-get full-upgrade -y && apt-get remove --purge --auto-remove -y && rm -rf /var/lib/apt/lists COPY USAGE/* /KEYS/USAGE/ WORKDIR /KEYS CMD [ \"/bin/bash\" , \"-c\" , \"echo 'Hello KEYS'\" ]","title":"Selfkeys"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/selfkeys.html#certificats-generes","text":"Les certificats g\u00e9n\u00e9r\u00e9s sont les suivants : ca : certificat d'authorit\u00e9 intern.civicrm.test: certificat pour le serveur web interne (httpd) civicrm.test : certificat pour le reverse-proxy, pr\u00e9sent\u00e9 \u00e0 l'ext\u00e9rieur proxy_client : certificat pour le reverse-proxy, pr\u00e9sent\u00e9 au serveur web interne auth_client : certificat pour l'authenticateur, pr\u00e9sent\u00e9 au serveur web interne","title":"Certificats g\u00e9n\u00e9r\u00e9s"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/tools.html","text":"Tools : image des outils L'image des outils est une sorte d'image g\u00e9n\u00e9rale, \u00e0 tout faire, non sp\u00e9cialis\u00e9e, qui sert de support pour les op\u00e9rations sp\u00e9cifiques (initialisation d'une instance, mise \u00e0 jour d'une instance (RAF), ex\u00e9cution de cron). FROM uepal_test/composer_base LABEL uepal.name = \"tools\" uepal.version = \"0.0.1\" ARG MYSQLVERSION = 8 .0.28-0ubuntu4 ENV MYSQLVERSIONENV = ${ MYSQLVERSION } RUN echo \"MySQLVERSION : \" ${ MYSQLVERSION } RUN mkdir /tools && mkdir /exec && touch /usr/share/man/man5/maildir.maildrop.5.gz && touch /usr/share/man/man7/maildirquota.maildrop.7.gz && touch /usr/share/man/man1/makedat.1.gz && apt-get update && apt-get full-upgrade -y && export DEBIAN_FRONTEND = noninteractive && apt-get install -y gnupg mysql-client nano openssh-client mc mysql-server mysql-server-8.0 = ${ MYSQLVERSION } mysql-server-core-8.0 = ${ MYSQLVERSION } mysql-client mysql-client-core-8.0 = ${ MYSQLVERSION } maildrop rsync lftp openssh-client dnsutils && apt-get remove --purge --auto-remove -y && rm -rf /var/lib/apt/lists COPY composer.* /tools/ COPY exec.sh /exec/exec.sh WORKDIR /tools RUN /composer/vendor/bin/composer install && ln -s /tools/vendor/drush/drush/drush /usr/local/bin/drush && ln -s /tools/vendor/bin/drupal /usr/local/bin/drupal && wget https://download.civicrm.org/cv/cv.phar -O /usr/local/bin/cv && chmod 755 /usr/local/bin/cv && chmod 755 /exec/exec.sh && maildirmake /maildir && install -d /var/run/secrets COPY --from = uepal_test/composer_files /app /app/ WORKDIR /app VOLUME /var/lib/mysql /app/web/sites /maildir /app/private CMD [ \"/exec/exec.sh\" ] Cette image n'est pas pr\u00e9vue pour \u00eatre \"en contact direct\" avec des connexions entrantes, ni une utilisation comme serveur. Elle n'est en aucun cas \"durcie\". Les outils sont install\u00e9s de plusieurs mani\u00e8res : * packages Ubuntu (mysql, maildrop, rsync, lftp, gnupg, nano...) * packages Composer (dont drupal-console et drush) * t\u00e9l\u00e9chargement direct (cv) Installation d'une version sp\u00e9cifique de MySQL L'installation d'une version sp\u00e9cifique de MySQL n'est pas un pr\u00e9requis. En revanche, le but de cette installation sp\u00e9cifique vient du fait que l'image ubuntu/mysql n'est pas forc\u00e9ment mise \u00e0 jour au m\u00eame rythme qu'une image ubuntu , ce qui peut conduire \u00e0 des diff\u00e9rences de versions. Ces diff\u00e9rences ont d'ailleurs d\u00e9j\u00e0 fait que des fichiers de BD MySQL cr\u00e9es avec une version sup\u00e9rieure (8.0.29) n'ont pas voulu fonctionner avec une version inf\u00e9rieure (8.0.28) : d'o\u00f9 la mise en place de l'argument pour la version mysql, avec une version par d\u00e9faut, qui est r\u00e9percut\u00e9e sur l'installation de packages Ubuntu.","title":"tools"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/tools.html#tools-image-des-outils","text":"L'image des outils est une sorte d'image g\u00e9n\u00e9rale, \u00e0 tout faire, non sp\u00e9cialis\u00e9e, qui sert de support pour les op\u00e9rations sp\u00e9cifiques (initialisation d'une instance, mise \u00e0 jour d'une instance (RAF), ex\u00e9cution de cron). FROM uepal_test/composer_base LABEL uepal.name = \"tools\" uepal.version = \"0.0.1\" ARG MYSQLVERSION = 8 .0.28-0ubuntu4 ENV MYSQLVERSIONENV = ${ MYSQLVERSION } RUN echo \"MySQLVERSION : \" ${ MYSQLVERSION } RUN mkdir /tools && mkdir /exec && touch /usr/share/man/man5/maildir.maildrop.5.gz && touch /usr/share/man/man7/maildirquota.maildrop.7.gz && touch /usr/share/man/man1/makedat.1.gz && apt-get update && apt-get full-upgrade -y && export DEBIAN_FRONTEND = noninteractive && apt-get install -y gnupg mysql-client nano openssh-client mc mysql-server mysql-server-8.0 = ${ MYSQLVERSION } mysql-server-core-8.0 = ${ MYSQLVERSION } mysql-client mysql-client-core-8.0 = ${ MYSQLVERSION } maildrop rsync lftp openssh-client dnsutils && apt-get remove --purge --auto-remove -y && rm -rf /var/lib/apt/lists COPY composer.* /tools/ COPY exec.sh /exec/exec.sh WORKDIR /tools RUN /composer/vendor/bin/composer install && ln -s /tools/vendor/drush/drush/drush /usr/local/bin/drush && ln -s /tools/vendor/bin/drupal /usr/local/bin/drupal && wget https://download.civicrm.org/cv/cv.phar -O /usr/local/bin/cv && chmod 755 /usr/local/bin/cv && chmod 755 /exec/exec.sh && maildirmake /maildir && install -d /var/run/secrets COPY --from = uepal_test/composer_files /app /app/ WORKDIR /app VOLUME /var/lib/mysql /app/web/sites /maildir /app/private CMD [ \"/exec/exec.sh\" ] Cette image n'est pas pr\u00e9vue pour \u00eatre \"en contact direct\" avec des connexions entrantes, ni une utilisation comme serveur. Elle n'est en aucun cas \"durcie\". Les outils sont install\u00e9s de plusieurs mani\u00e8res : * packages Ubuntu (mysql, maildrop, rsync, lftp, gnupg, nano...) * packages Composer (dont drupal-console et drush) * t\u00e9l\u00e9chargement direct (cv)","title":"Tools : image des outils"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/tools.html#installation-dune-version-specifique-de-mysql","text":"L'installation d'une version sp\u00e9cifique de MySQL n'est pas un pr\u00e9requis. En revanche, le but de cette installation sp\u00e9cifique vient du fait que l'image ubuntu/mysql n'est pas forc\u00e9ment mise \u00e0 jour au m\u00eame rythme qu'une image ubuntu , ce qui peut conduire \u00e0 des diff\u00e9rences de versions. Ces diff\u00e9rences ont d'ailleurs d\u00e9j\u00e0 fait que des fichiers de BD MySQL cr\u00e9es avec une version sup\u00e9rieure (8.0.29) n'ont pas voulu fonctionner avec une version inf\u00e9rieure (8.0.28) : d'o\u00f9 la mise en place de l'argument pour la version mysql, avec une version par d\u00e9faut, qui est r\u00e9percut\u00e9e sur l'installation de packages Ubuntu.","title":"Installation d'une version sp\u00e9cifique de MySQL"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/update.html","text":"Image update Description Cette image est pr\u00e9vue pour finaliser une mise \u00e0 jour d'une instance. La mise \u00e0 jour des fichiers de code et des fichiers de traduction se fait certes via composer, mais il y a lieu ensuite d'effectuer les mises \u00e0 jour en particulier pour le niveau BD (et \u00e9ventuellement effectuer des manipulations au niveau des fichiers dans les volumes de l'installation, s'il y a lieu). Cette image descend des tools, et elle est pr\u00e9vue pour monter la base de donn\u00e9es. Toutefois, une modification de l'owner des fichiers a \u00e9t\u00e9 n\u00e9cessaire, car une modification analogue est effectu\u00e9e dans l'image ubuntu/mysql, afin que l'owner des fichiers soit bien l'utilisateur mysql, mais avec l'UID de l'utilisateur mysql de l'image. Cette modification est \"d\u00e9faite\" par l'initilisation du container ubuntu/mysql. L'image effectue plusieurs rafra\u00eechissements de cache, afin de chercher \u00e0 tenir compte des modifications qui auraient pu avoir lieu \u00e0 l'\u00e9tape juste avant du script. Il est \u00e0 noter que pour les traductions, il faut, au niveau de Drupal, importer le fichier de traduction, tandis que le fichier n\u00e9cessiterait simplement d'\u00eatre remplac\u00e9 au niveau de CiviCRM, selon le fonctionnement de l'extension de mise \u00e0 jour existante https://github.com/cividesk/com.cividesk.l10n.update/ . Le code de cette image recopie une partie du code de l'init. Il faudra donc faire \u00e9voluer les deux images de concert. Variables d'environnement Variable Signification Default Docker DBHOST Serveur DB civicrmdb SERVERNAME Nom externe du serveur civicrm.test","title":"update"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/update.html#image-update","text":"","title":"Image update"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/update.html#description","text":"Cette image est pr\u00e9vue pour finaliser une mise \u00e0 jour d'une instance. La mise \u00e0 jour des fichiers de code et des fichiers de traduction se fait certes via composer, mais il y a lieu ensuite d'effectuer les mises \u00e0 jour en particulier pour le niveau BD (et \u00e9ventuellement effectuer des manipulations au niveau des fichiers dans les volumes de l'installation, s'il y a lieu). Cette image descend des tools, et elle est pr\u00e9vue pour monter la base de donn\u00e9es. Toutefois, une modification de l'owner des fichiers a \u00e9t\u00e9 n\u00e9cessaire, car une modification analogue est effectu\u00e9e dans l'image ubuntu/mysql, afin que l'owner des fichiers soit bien l'utilisateur mysql, mais avec l'UID de l'utilisateur mysql de l'image. Cette modification est \"d\u00e9faite\" par l'initilisation du container ubuntu/mysql. L'image effectue plusieurs rafra\u00eechissements de cache, afin de chercher \u00e0 tenir compte des modifications qui auraient pu avoir lieu \u00e0 l'\u00e9tape juste avant du script. Il est \u00e0 noter que pour les traductions, il faut, au niveau de Drupal, importer le fichier de traduction, tandis que le fichier n\u00e9cessiterait simplement d'\u00eatre remplac\u00e9 au niveau de CiviCRM, selon le fonctionnement de l'extension de mise \u00e0 jour existante https://github.com/cividesk/com.cividesk.l10n.update/ . Le code de cette image recopie une partie du code de l'init. Il faudra donc faire \u00e9voluer les deux images de concert.","title":"Description"},{"location":"TECHNIQUE/INTEGRATION/DOCKER/update.html#variables-denvironnement","text":"Variable Signification Default Docker DBHOST Serveur DB civicrmdb SERVERNAME Nom externe du serveur civicrm.test","title":"Variables d'environnement"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/maquettage.html","text":"Kubernetes : maquettage Kubernetes est l'environnement cible pour les environnements Civiparoisse. En effet, Kubernetes permet de g\u00e9rer un cluster de machines pour pouvoir ex\u00e9cuter des conteneurs sur le cluster. Il va y avoir en fait deux clusters : un cluster que l'on pourrait assimiler \u00e0 un cluster de calcul, qui va disposer des ressources mat\u00e9rielles pour ex\u00e9cuter les charge un cluster de stockage Les deux clusters doivent \u00eatre interconnect\u00e9s avec des ressources r\u00e9seau ad\u00e9quates. Le travail principal avec Kubernetes consiste \u00e0 d\u00e9finir de mani\u00e8re d\u00e9clarative, via des fichiers appel\u00e9s manifestes, \u00e9crits en JSON ou YAML, des ressources qui vont servir \u00e0 configurer des charges de travail \u00e0 ex\u00e9cuter. Minikube En pratique, l'environnement utilis\u00e9 pour le d\u00e9veloppement est Minikube, qui est un environnement Kubernetes packag\u00e9, pr\u00e9vu pour apprendre. Avec Minikube, on est limit\u00e9 \u00e0 un cluster Kubernetes \u00e0 un seul noeud, mais on dispose d'une \u00e9mulation simple d'un syst\u00e8me de stockage persistant qui va stocker les donn\u00e9es sur le disque dur du syst\u00e8me (default-storageclass et storage-provisionner). Remarque sur le storage-provisionner : ce provisionneur est un provisionneur tr\u00e8s simple, qui va utiliser l'espace dans /var/hostpath-provisionner du container Docker de Minikube. Cet espace est g\u00e9r\u00e9 \u00e0 l'aide du namespace et du nom de claim. Lorsque le PersistentVolumeClaim est supprim\u00e9, les donn\u00e9es ne seront pas forc\u00e9ment (et plut\u00f4t probablement pas) supprim\u00e9es. De ce fait, il convient de les effacer manuellement pour ne pas polluer une \u00e9ventuelle r\u00e9installation ult\u00e9rieure. Minikube dispose de plusieurs modes de fonctionnement, dont le mode usuel, \u00e0 savoir Docker in Docker, ce qui veut dire qu'il faut rendre les images disponibles au Docker de Minikube pour pouvoir les utiliser - c'est relativement simple puisque Minikube a pr\u00e9vu la commande n\u00e9cessaire pour attaquer le Docker de minikube gr\u00e2ce \u00e0 la configuration de l'environnement : eval $(minikube -p minikube docker-env) . L'environnement de Minikube propose enfin aussi un dashboard dans un environnement web, ce qui est utile pour d\u00e9buter, pour les d\u00e9monstrations, et le d\u00e9buggage. N\u00e9anmoins, il convient de se familiariser \u00e9galement avec kubectl, kubectl \u00e9tant une outil qui sera utilis\u00e9 dans la plupart des environnements. L'environnement de production ne sera \u00e9videmment pas Minikube, mais sera soit un environnement de cloud public, soit un environnement de cloud h\u00e9berg\u00e9 ; dans tous les cas, il devra \u00eatre manag\u00e9 par des ressources tierces. Quelques commandes utiles : minikube start : d\u00e9marre le cluster par d\u00e9faut minikube stop : arr\u00eate le cluster par d\u00e9faut minikube ip : indique l'IP de cluster de minikube : utile pour faire la r\u00e9solution de nom dans /etc/hosts pour faire pointer les noms vers le cluster minikube depuis l'h\u00f4te minikube ssh : acc\u00e8s SSH au container de minikube eval $(minikube docker-env) : configuration du terminal courant pour se connecter au daemon docker de minikube (pour builder et puller les images par exemple) Attention : pour le moment, il est n\u00e9cessaire de builder les images dans le docker de minikube pour les rendre disponibles pour Minikube. De m\u00eame, il est n\u00e9cessaire de faire attention \u00e0 la pull policy, et id\u00e9alement de puller soi-m\u00eame les images dans le docker de minikube, afin de les rendre utilisables par Minikube Principe de fonctionnement d'acheminement des communications Les connexions entrantes sont dirig\u00e9es vers un point d'entr\u00e9e du cluster (ex : via les enregistrements DNS). On d\u00e9termine ensuite la bonne ressource (reverse proxy) destinataire, et on ex\u00e9cute la requ\u00eate dessus. On a un environnement \"mod\u00e8le\" qui va \u00eatre utilis\u00e9 pour d\u00e9ployer chaque environnement de paroisse, et qui va tirer parti des images g\u00e9n\u00e9r\u00e9es au niveau de Docker. Cet environnement mod\u00e8le est packag\u00e9 gr\u00e2ce \u00e0 Helm ( https://helm.sh/ ). Reverse-Proxy frontal TCP : nginx ingress controller On parle ici non pas du controller ingress nginx livr\u00e9 par Kubernetes, mais de celui livr\u00e9 par Nginx (F5) lui-m\u00eame : https://docs.nginx.com/nginx-ingress-controller/ et https://hub.docker.com/r/nginx/nginx-ingress/ . Son installation est assez simple, car il suffit de suivre les inscructions de https://docs.nginx.com/nginx-ingress-controller/installation/installation-with-manifests/ pour installer le n\u00e9cessaire, en ligne de commande. Quelques remarques sont toutefois n\u00e9cessaires : pour l'ingress controller (deployments/daemon-set/nginx-ingress.yaml), il est n\u00e9cessaire d'ajouter sur la ligne de commmande les param\u00e8tres : - -enable-custom-resources - -enable-tls-passthrough il est n\u00e9cessaire d'utiliser le daemonSet et non pas le deployment pour que notamment le port 443 soit accessible depuis l'ip du cluster minikube La configuration de chaque object TransportServer, qui va permettre de configurer le tunneling, est inclus dans le package de livrable Helm. R\u00e9cup\u00e9ration des identifiants Drupal apr\u00e8s installation Il est n\u00e9cessaire d'aller r\u00e9cup\u00e9rer les valeurs dans les secrets : kubectl get secrets secret -n helmtls -o json Les valeurs qui sont indiqu\u00e9es sont encod\u00e9es en base64. Il convient donc de les d\u00e9coder avec des commandes telles que : echo \"valeur\" | openssl base64 -a -d -in - -out - ; echo \"\" (Le deuxi\u00e8me echo est pr\u00e9sent pour ajouter une ligne vide et faciliter les copier-coller de la sortie).","title":"Maquettage"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/maquettage.html#kubernetes-maquettage","text":"Kubernetes est l'environnement cible pour les environnements Civiparoisse. En effet, Kubernetes permet de g\u00e9rer un cluster de machines pour pouvoir ex\u00e9cuter des conteneurs sur le cluster. Il va y avoir en fait deux clusters : un cluster que l'on pourrait assimiler \u00e0 un cluster de calcul, qui va disposer des ressources mat\u00e9rielles pour ex\u00e9cuter les charge un cluster de stockage Les deux clusters doivent \u00eatre interconnect\u00e9s avec des ressources r\u00e9seau ad\u00e9quates. Le travail principal avec Kubernetes consiste \u00e0 d\u00e9finir de mani\u00e8re d\u00e9clarative, via des fichiers appel\u00e9s manifestes, \u00e9crits en JSON ou YAML, des ressources qui vont servir \u00e0 configurer des charges de travail \u00e0 ex\u00e9cuter.","title":"Kubernetes : maquettage"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/maquettage.html#minikube","text":"En pratique, l'environnement utilis\u00e9 pour le d\u00e9veloppement est Minikube, qui est un environnement Kubernetes packag\u00e9, pr\u00e9vu pour apprendre. Avec Minikube, on est limit\u00e9 \u00e0 un cluster Kubernetes \u00e0 un seul noeud, mais on dispose d'une \u00e9mulation simple d'un syst\u00e8me de stockage persistant qui va stocker les donn\u00e9es sur le disque dur du syst\u00e8me (default-storageclass et storage-provisionner). Remarque sur le storage-provisionner : ce provisionneur est un provisionneur tr\u00e8s simple, qui va utiliser l'espace dans /var/hostpath-provisionner du container Docker de Minikube. Cet espace est g\u00e9r\u00e9 \u00e0 l'aide du namespace et du nom de claim. Lorsque le PersistentVolumeClaim est supprim\u00e9, les donn\u00e9es ne seront pas forc\u00e9ment (et plut\u00f4t probablement pas) supprim\u00e9es. De ce fait, il convient de les effacer manuellement pour ne pas polluer une \u00e9ventuelle r\u00e9installation ult\u00e9rieure. Minikube dispose de plusieurs modes de fonctionnement, dont le mode usuel, \u00e0 savoir Docker in Docker, ce qui veut dire qu'il faut rendre les images disponibles au Docker de Minikube pour pouvoir les utiliser - c'est relativement simple puisque Minikube a pr\u00e9vu la commande n\u00e9cessaire pour attaquer le Docker de minikube gr\u00e2ce \u00e0 la configuration de l'environnement : eval $(minikube -p minikube docker-env) . L'environnement de Minikube propose enfin aussi un dashboard dans un environnement web, ce qui est utile pour d\u00e9buter, pour les d\u00e9monstrations, et le d\u00e9buggage. N\u00e9anmoins, il convient de se familiariser \u00e9galement avec kubectl, kubectl \u00e9tant une outil qui sera utilis\u00e9 dans la plupart des environnements. L'environnement de production ne sera \u00e9videmment pas Minikube, mais sera soit un environnement de cloud public, soit un environnement de cloud h\u00e9berg\u00e9 ; dans tous les cas, il devra \u00eatre manag\u00e9 par des ressources tierces. Quelques commandes utiles : minikube start : d\u00e9marre le cluster par d\u00e9faut minikube stop : arr\u00eate le cluster par d\u00e9faut minikube ip : indique l'IP de cluster de minikube : utile pour faire la r\u00e9solution de nom dans /etc/hosts pour faire pointer les noms vers le cluster minikube depuis l'h\u00f4te minikube ssh : acc\u00e8s SSH au container de minikube eval $(minikube docker-env) : configuration du terminal courant pour se connecter au daemon docker de minikube (pour builder et puller les images par exemple) Attention : pour le moment, il est n\u00e9cessaire de builder les images dans le docker de minikube pour les rendre disponibles pour Minikube. De m\u00eame, il est n\u00e9cessaire de faire attention \u00e0 la pull policy, et id\u00e9alement de puller soi-m\u00eame les images dans le docker de minikube, afin de les rendre utilisables par Minikube","title":"Minikube"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/maquettage.html#principe-de-fonctionnement-dacheminement-des-communications","text":"Les connexions entrantes sont dirig\u00e9es vers un point d'entr\u00e9e du cluster (ex : via les enregistrements DNS). On d\u00e9termine ensuite la bonne ressource (reverse proxy) destinataire, et on ex\u00e9cute la requ\u00eate dessus. On a un environnement \"mod\u00e8le\" qui va \u00eatre utilis\u00e9 pour d\u00e9ployer chaque environnement de paroisse, et qui va tirer parti des images g\u00e9n\u00e9r\u00e9es au niveau de Docker. Cet environnement mod\u00e8le est packag\u00e9 gr\u00e2ce \u00e0 Helm ( https://helm.sh/ ).","title":"Principe de fonctionnement d'acheminement des communications"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/maquettage.html#reverse-proxy-frontal-tcp-nginx-ingress-controller","text":"On parle ici non pas du controller ingress nginx livr\u00e9 par Kubernetes, mais de celui livr\u00e9 par Nginx (F5) lui-m\u00eame : https://docs.nginx.com/nginx-ingress-controller/ et https://hub.docker.com/r/nginx/nginx-ingress/ . Son installation est assez simple, car il suffit de suivre les inscructions de https://docs.nginx.com/nginx-ingress-controller/installation/installation-with-manifests/ pour installer le n\u00e9cessaire, en ligne de commande. Quelques remarques sont toutefois n\u00e9cessaires : pour l'ingress controller (deployments/daemon-set/nginx-ingress.yaml), il est n\u00e9cessaire d'ajouter sur la ligne de commmande les param\u00e8tres : - -enable-custom-resources - -enable-tls-passthrough il est n\u00e9cessaire d'utiliser le daemonSet et non pas le deployment pour que notamment le port 443 soit accessible depuis l'ip du cluster minikube La configuration de chaque object TransportServer, qui va permettre de configurer le tunneling, est inclus dans le package de livrable Helm.","title":"Reverse-Proxy frontal TCP : nginx ingress controller"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/maquettage.html#recuperation-des-identifiants-drupal-apres-installation","text":"Il est n\u00e9cessaire d'aller r\u00e9cup\u00e9rer les valeurs dans les secrets : kubectl get secrets secret -n helmtls -o json Les valeurs qui sont indiqu\u00e9es sont encod\u00e9es en base64. Il convient donc de les d\u00e9coder avec des commandes telles que : echo \"valeur\" | openssl base64 -a -d -in - -out - ; echo \"\" (Le deuxi\u00e8me echo est pr\u00e9sent pour ajouter une ligne vide et faciliter les copier-coller de la sortie).","title":"R\u00e9cup\u00e9ration des identifiants Drupal apr\u00e8s installation"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/ressources.html","text":"Ressources utiles Petite liste avec quelques ressources utiles : Concepts Kubernetes : https://kubernetes.io/docs/concepts/ : documentation des concepts tr\u00e8s int\u00e9ressante et n\u00e9cessaire pour \u00e9crire les manifestes Design Patterns (OpenShift): https://www.redhat.com/en/resources/oreilly-kubernetes-patterns-cloud-native-apps : \u00e9crit par un employ\u00e9 de redhat, livre Oreilly tr\u00e8s int\u00e9ressant avec des explications d\u00e9taill\u00e9es sur les fondamentaux et les concepts plus \u00e9volu\u00e9s des architectures K8S. Un livre \u00e0 garder sous la main. Design Patterns (Azure) : https://docs.microsoft.com/en-us/azure/architecture/patterns/ Azure : ebook kubernetes (dont un O'Reilly) : https://azure.microsoft.com/en-us/resources/kubernetes-ebook-collection/ K8S Operators : https://www.redhat.com/en/resources/oreilly-kubernetes-operators-automation-ebook K8S Storage for dummies : https://www.redhat.com/en/resources/storage-patterns-kubernetes-dummies-ebook Documentation installation nginx-ingress de F5 : https://docs.nginx.com/nginx-ingress-controller/installation/installation-with-manifests/ Ebooks chez Vmware Tanzu : https://tanzu.vmware.com/content/ebooks : dont des livres O'Reilly","title":"Ressources utiles"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/ressources.html#ressources-utiles","text":"Petite liste avec quelques ressources utiles : Concepts Kubernetes : https://kubernetes.io/docs/concepts/ : documentation des concepts tr\u00e8s int\u00e9ressante et n\u00e9cessaire pour \u00e9crire les manifestes Design Patterns (OpenShift): https://www.redhat.com/en/resources/oreilly-kubernetes-patterns-cloud-native-apps : \u00e9crit par un employ\u00e9 de redhat, livre Oreilly tr\u00e8s int\u00e9ressant avec des explications d\u00e9taill\u00e9es sur les fondamentaux et les concepts plus \u00e9volu\u00e9s des architectures K8S. Un livre \u00e0 garder sous la main. Design Patterns (Azure) : https://docs.microsoft.com/en-us/azure/architecture/patterns/ Azure : ebook kubernetes (dont un O'Reilly) : https://azure.microsoft.com/en-us/resources/kubernetes-ebook-collection/ K8S Operators : https://www.redhat.com/en/resources/oreilly-kubernetes-operators-automation-ebook K8S Storage for dummies : https://www.redhat.com/en/resources/storage-patterns-kubernetes-dummies-ebook Documentation installation nginx-ingress de F5 : https://docs.nginx.com/nginx-ingress-controller/installation/installation-with-manifests/ Ebooks chez Vmware Tanzu : https://tanzu.vmware.com/content/ebooks : dont des livres O'Reilly","title":"Ressources utiles"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/cron.html","text":"Cron L'impl\u00e9mentation de l'appel \u00e0 cron utilise le cronjob. Le cron est synchronis\u00e9 via le container d'initialisation sur la disponibilit\u00e9 du proxy DB. On se rappelera que le proxy DB n'est activ\u00e9 que du moment o\u00f9 la BD elle-m\u00eame et les fichiers sont initialis\u00e9s via le container d'init de stateful_set_db . De plus, le container cron int\u00e8gre au d\u00e9but de son code d'ex\u00e9cution une routine d'attente pour \u00eatre certain que la BD est disponible (via mysqladmin ping ) La particularit\u00e9 du pod de cron est que pour que le pod se termine correctement, les deux containers doivent non seulement sortir, mais \u00e9galement sortir sans erreur (code de retour 0). Ceci implique qu'il faut arr\u00eater le container de proxy db (sidecar d'acc\u00e8s \u00e0 la BD), et pour ce faire, il faut pouvoir le tuer via les signaux, d'o\u00f9 le shareProcessNamespace: true . Pour le moment, le cronjob est d\u00e9clar\u00e9, mais est suspendu ( suspend: true ). Il faudra penser \u00e0 modifier ce point avant passage en production.","title":"Cron"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/cron.html#cron","text":"L'impl\u00e9mentation de l'appel \u00e0 cron utilise le cronjob. Le cron est synchronis\u00e9 via le container d'initialisation sur la disponibilit\u00e9 du proxy DB. On se rappelera que le proxy DB n'est activ\u00e9 que du moment o\u00f9 la BD elle-m\u00eame et les fichiers sont initialis\u00e9s via le container d'init de stateful_set_db . De plus, le container cron int\u00e8gre au d\u00e9but de son code d'ex\u00e9cution une routine d'attente pour \u00eatre certain que la BD est disponible (via mysqladmin ping ) La particularit\u00e9 du pod de cron est que pour que le pod se termine correctement, les deux containers doivent non seulement sortir, mais \u00e9galement sortir sans erreur (code de retour 0). Ceci implique qu'il faut arr\u00eater le container de proxy db (sidecar d'acc\u00e8s \u00e0 la BD), et pour ce faire, il faut pouvoir le tuer via les signaux, d'o\u00f9 le shareProcessNamespace: true . Pour le moment, le cronjob est d\u00e9clar\u00e9, mais est suspendu ( suspend: true ). Il faudra penser \u00e0 modifier ce point avant passage en production.","title":"Cron"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/db_dbproxy.html","text":"DB et DB proxy La BD est h\u00e9berg\u00e9e dans un stateful set. La BD est pr\u00e9vue pour \u00eatre acc\u00e9d\u00e9e par une socket Unix directement, ou par un tunnel SSL : d'o\u00f9 les deux services distincts, m\u00eame s'il est vrai qu'il est moins pertinent d'avoir un service DB puisque ce service n'est pas pr\u00e9vu pour \u00eatre acc\u00e9d\u00e9 par le r\u00e9seau. Une cons\u00e9quence de cette architecture est qu'en PHP, si on configure correctement le chemin par d\u00e9faut des sockets, on peut utiliser le nom sp\u00e9cial localhost pour passer par la socket Unix et acc\u00e9der, directement ou indirectement \u00e0 la BD Initialisation Un container d'initialisation est charg\u00e9 d'initialiser l'ensemble des ressources (fichiers et base de donn\u00e9es). Il pourra \u00eatre envisag\u00e9 que ce container puisse \u00e9galement proc\u00e9der aux mises \u00e0 jours des donn\u00e9es (c'est \u00e0 dire, effectuer les modifications qui impactent la BD et les fichiers propres \u00e0 chaque paroisse - les images \u00e9tant mises \u00e0 jour en les reconstruisant). Il est \u00e0 noter que ce stateful set doit \u00eatre op\u00e9rationnel pour que les autres \u00e9l\u00e9ments puissent s'activer (synchronisation via containers d'initialisation). Configuration BD Selon la documentation de MySQL https://dev.mysql.com/doc/refman/8.0/en/memory-use.html , MySQL est pr\u00e9vu pour tenir dans environ 512M de RAM. Ceci est confirm\u00e9 en pratique par l'utilisation du performance_schema : ``` mysql > SELECT SUBSTRING_INDEX ( event_name , '/' , 2 ) AS -> code_area , FORMAT_BYTES ( SUM ( current_alloc )) -> AS current_alloc -> FROM sys . x$memory_global_by_current_bytes -> GROUP BY SUBSTRING_INDEX ( event_name , '/' , 2 ) -> ORDER BY SUM ( current_alloc ) DESC ; + ---------------------------+---------------+ | code_area | current_alloc | + ---------------------------+---------------+ | memory / performance_schema | 214 . 94 MiB | | memory / innodb | 196 . 09 MiB | | memory / sql | 9 . 39 MiB | | memory / mysys | 8 . 58 MiB | | memory / temptable | 1 . 00 MiB | | memory / mysqld_openssl | 808 . 83 KiB | | memory / mysqlx | 3 . 38 KiB | | memory / vio | 1 . 16 KiB | | memory / myisam | 728 bytes | | memory / csv | 120 bytes | | memory / blackhole | 120 bytes | + ---------------------------+---------------+ 11 rows in set ( 0 . 02 sec ) mysql > select * from sys . memory_global_total ; + -----------------+ | total_allocated | + -----------------+ | 448 . 20 MiB | + -----------------+ 1 row in set ( 0 . 01 sec ) root@b64de810e1b6:/# ps -ua USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0 .0 0 .0 4140 3368 pts/0 Ss 13 :45 0 :00 bash mysql 12 1 .1 10 .0 2228664 389164 pts/0 Sl+ 13 :45 0 :02 mysqld root 155 0 .0 0 .0 4136 3392 pts/1 Ss 13 :46 0 :00 bash root 226 0 .0 0 .0 6420 1600 pts/1 R+ 13 :49 0 :00 ps -ua On constate en particulier l'utilisation de 215MB de ram pour performance_schema, alors que cette partie de la BD ne va pas r\u00e9ellement \u00eatre utilis\u00e9e. Du coup, il est envisageable de d\u00e9sactiver performance_schema. Apr\u00e8s d\u00e9sactivation, on ne peut plus utiliser la requ\u00eate SQL, mais on peut continuer \u00e0 utiliser ps -ua : mysql > SELECT SUBSTRING_INDEX ( event_name , '/' , 2 ) AS -> code_area , FORMAT_BYTES ( SUM ( current_alloc )) -> AS current_alloc -> FROM sys . x$memory_global_by_current_bytes -> GROUP BY SUBSTRING_INDEX ( event_name , '/' , 2 ) -> ORDER BY SUM ( current_alloc ) DESC ; Empty set ( 0 . 01 sec ) mysql > select * from sys . memory_global_total ; + -----------------+ | total_allocated | + -----------------+ | NULL | + -----------------+ 1 row in set ( 0 . 02 sec ) root@b64de810e1b6:/etc/mysql/conf.d# ps -ua USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.0 4140 3368 pts/0 Ss 13:45 0:00 bash root 155 0.0 0.0 4136 3400 pts/1 Ss 13:46 0:00 bash mysql 461 2.5 4.0 1940420 156368 pts/0 Sl+ 13:52 0:01 mysqld root 545 0.0 0.0 6420 1640 pts/1 R+ 13:52 0:00 ps -ua Comme j'ai fait les op\u00e9rations dans un m\u00eame container, on peut voir que plus de la moiti\u00e9 de la RAM n'est plus utilis\u00e9e apr\u00e8s avoir mis performance_schema = 0 . L'autre modification effectu\u00e9e est de positionner skip_networking = 1 de sorte que le port r\u00e9seau ne soit plus \u00e9cout\u00e9, \u00e9tant qu'un acc\u00e8s direct est \u00e0 proscrire sans support chiffr\u00e9 configur\u00e9. Proxy Le proxy est en fait une utilisation d'un tunnel socat vers la socket de mysql. On prend en fait soin de positionner le r\u00e9pertoire de la socket dans un emptyDir stock\u00e9 en m\u00e9moire et d\u00e9clar\u00e9 dans les specs, et on partage ce volume entre le container de db et la terminaison serveur du proxy : c'est une application du design pattern sidecar.","title":"DB et DB proxy"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/db_dbproxy.html#db-et-db-proxy","text":"La BD est h\u00e9berg\u00e9e dans un stateful set. La BD est pr\u00e9vue pour \u00eatre acc\u00e9d\u00e9e par une socket Unix directement, ou par un tunnel SSL : d'o\u00f9 les deux services distincts, m\u00eame s'il est vrai qu'il est moins pertinent d'avoir un service DB puisque ce service n'est pas pr\u00e9vu pour \u00eatre acc\u00e9d\u00e9 par le r\u00e9seau. Une cons\u00e9quence de cette architecture est qu'en PHP, si on configure correctement le chemin par d\u00e9faut des sockets, on peut utiliser le nom sp\u00e9cial localhost pour passer par la socket Unix et acc\u00e9der, directement ou indirectement \u00e0 la BD","title":"DB et DB proxy"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/db_dbproxy.html#initialisation","text":"Un container d'initialisation est charg\u00e9 d'initialiser l'ensemble des ressources (fichiers et base de donn\u00e9es). Il pourra \u00eatre envisag\u00e9 que ce container puisse \u00e9galement proc\u00e9der aux mises \u00e0 jours des donn\u00e9es (c'est \u00e0 dire, effectuer les modifications qui impactent la BD et les fichiers propres \u00e0 chaque paroisse - les images \u00e9tant mises \u00e0 jour en les reconstruisant). Il est \u00e0 noter que ce stateful set doit \u00eatre op\u00e9rationnel pour que les autres \u00e9l\u00e9ments puissent s'activer (synchronisation via containers d'initialisation).","title":"Initialisation"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/db_dbproxy.html#configuration-bd","text":"Selon la documentation de MySQL https://dev.mysql.com/doc/refman/8.0/en/memory-use.html , MySQL est pr\u00e9vu pour tenir dans environ 512M de RAM. Ceci est confirm\u00e9 en pratique par l'utilisation du performance_schema : ``` mysql > SELECT SUBSTRING_INDEX ( event_name , '/' , 2 ) AS -> code_area , FORMAT_BYTES ( SUM ( current_alloc )) -> AS current_alloc -> FROM sys . x$memory_global_by_current_bytes -> GROUP BY SUBSTRING_INDEX ( event_name , '/' , 2 ) -> ORDER BY SUM ( current_alloc ) DESC ; + ---------------------------+---------------+ | code_area | current_alloc | + ---------------------------+---------------+ | memory / performance_schema | 214 . 94 MiB | | memory / innodb | 196 . 09 MiB | | memory / sql | 9 . 39 MiB | | memory / mysys | 8 . 58 MiB | | memory / temptable | 1 . 00 MiB | | memory / mysqld_openssl | 808 . 83 KiB | | memory / mysqlx | 3 . 38 KiB | | memory / vio | 1 . 16 KiB | | memory / myisam | 728 bytes | | memory / csv | 120 bytes | | memory / blackhole | 120 bytes | + ---------------------------+---------------+ 11 rows in set ( 0 . 02 sec ) mysql > select * from sys . memory_global_total ; + -----------------+ | total_allocated | + -----------------+ | 448 . 20 MiB | + -----------------+ 1 row in set ( 0 . 01 sec ) root@b64de810e1b6:/# ps -ua USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0 .0 0 .0 4140 3368 pts/0 Ss 13 :45 0 :00 bash mysql 12 1 .1 10 .0 2228664 389164 pts/0 Sl+ 13 :45 0 :02 mysqld root 155 0 .0 0 .0 4136 3392 pts/1 Ss 13 :46 0 :00 bash root 226 0 .0 0 .0 6420 1600 pts/1 R+ 13 :49 0 :00 ps -ua On constate en particulier l'utilisation de 215MB de ram pour performance_schema, alors que cette partie de la BD ne va pas r\u00e9ellement \u00eatre utilis\u00e9e. Du coup, il est envisageable de d\u00e9sactiver performance_schema. Apr\u00e8s d\u00e9sactivation, on ne peut plus utiliser la requ\u00eate SQL, mais on peut continuer \u00e0 utiliser ps -ua : mysql > SELECT SUBSTRING_INDEX ( event_name , '/' , 2 ) AS -> code_area , FORMAT_BYTES ( SUM ( current_alloc )) -> AS current_alloc -> FROM sys . x$memory_global_by_current_bytes -> GROUP BY SUBSTRING_INDEX ( event_name , '/' , 2 ) -> ORDER BY SUM ( current_alloc ) DESC ; Empty set ( 0 . 01 sec ) mysql > select * from sys . memory_global_total ; + -----------------+ | total_allocated | + -----------------+ | NULL | + -----------------+ 1 row in set ( 0 . 02 sec ) root@b64de810e1b6:/etc/mysql/conf.d# ps -ua USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.0 4140 3368 pts/0 Ss 13:45 0:00 bash root 155 0.0 0.0 4136 3400 pts/1 Ss 13:46 0:00 bash mysql 461 2.5 4.0 1940420 156368 pts/0 Sl+ 13:52 0:01 mysqld root 545 0.0 0.0 6420 1640 pts/1 R+ 13:52 0:00 ps -ua Comme j'ai fait les op\u00e9rations dans un m\u00eame container, on peut voir que plus de la moiti\u00e9 de la RAM n'est plus utilis\u00e9e apr\u00e8s avoir mis performance_schema = 0 . L'autre modification effectu\u00e9e est de positionner skip_networking = 1 de sorte que le port r\u00e9seau ne soit plus \u00e9cout\u00e9, \u00e9tant qu'un acc\u00e8s direct est \u00e0 proscrire sans support chiffr\u00e9 configur\u00e9.","title":"Configuration BD"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/db_dbproxy.html#proxy","text":"Le proxy est en fait une utilisation d'un tunnel socat vers la socket de mysql. On prend en fait soin de positionner le r\u00e9pertoire de la socket dans un emptyDir stock\u00e9 en m\u00e9moire et d\u00e9clar\u00e9 dans les specs, et on partage ce volume entre le container de db et la terminaison serveur du proxy : c'est une application du design pattern sidecar.","title":"Proxy"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/description_generale.html","text":"Chart Helm: description g\u00e9n\u00e9rale Helm Helm est un syst\u00e8me de packaging pour Kubernetes. L'int\u00e9r\u00eat de Helm est qu'il permet de pr\u00e9parer des mod\u00e8les de d\u00e9ploiement d'application, dans un package appel\u00e9 \"chart\". En pratique, il permet notamment d'avoir des mod\u00e8les (templates) pour d\u00e9ployer des ressources Kubernetes, et permet d'injecter des valeurs dans ces ressources. Ces valeurs peuvent \u00eatre par exemple pr\u00e9cises dans des fichiers de valeurs, ou \u00eatre calcul\u00e9es depuis des commandes indiqu\u00e9es dans les fichiers, ou m\u00eame \u00eatre r\u00e9cup\u00e9r\u00e9es depuis un cluster Kubernetes (par exemple des clefs de chiffrement). Helm constitue donc un outil essentiel pour packager un environnement de paroisse. L'installation de Helm se fait assez simplement en r\u00e9cup\u00e9rant l'archive Helm depuis https://github.com/helm/helm/releases , en v\u00e9rifiant la somme de contr\u00f4le, en d\u00e9compressant l'archive, et en mettant Helm a un endroit accessible depuis le path (avec les droits d'ex\u00e9cution). Quelques commandes utiles : helm install --create-namespace -n helmtls helmciviparoisse . : depuis le package Helm de civiparoisse (le . ), installer une release (ici nomm\u00e9e helmciviparoisse ) dans un namespace cr\u00e9e pour l'occasion (ici helmtls ), en utilisant les valeurs par d\u00e9faut helm uninstall -n helmtls helmciviparoisse : d\u00e9sinstaller les ressources de la release helmciviparoisse dans le namespace helmtls helm list -n helmtls : r\u00e9cup\u00e9rer les noms de releases d'un namespace (ici helmtls ) Attention : pour le moment, il faut builder les images uepal_test dans l'environnement docker de Minikube. De plus, il faut puller manuellement les images ubuntu, ubuntu/apache, ubuntu/mysql, \u00e0 cause des interactions avec le tag latest et la pull Policy mise \u00e0 none dans le package helm Description des types d'objets utilis\u00e9s dans le chart Helm Il s'agit ici de d\u00e9finir une liste des types d'objets avec une br\u00e8ve description ; on se r\u00e9f\u00e8rera bien entendu \u00e0 la documentation Kubernetes ( https://kubernetes.io/fr/docs/concepts/ ) et Nginx ( https://docs.nginx.com/nginx-ingress-controller/configuration/transportserver-resource/ ) pour des explications compl\u00e8tes. On va trouver des objets de bas niveau, qui sont des objets de base, qui vont \u00eatre employ\u00e9s et g\u00e9r\u00e9s implicitement par les objets de plus haut niveau, dont notamment : Pod : le pod est un environnement d'ex\u00e9cution qui peut \u00eatre partag\u00e9 par un ou plusieurs containers. Les containers du pod auront tous acc\u00e8s au r\u00e9seau entre eux via le loopback (127.0.0.1), et ont un espace m\u00e9moire partag\u00e9. Outre les containers qui constituent la charge de travail pricipale du pod, on peut trouver des containers d'initialisation, qui sont lanc\u00e9s les uns apr\u00e8s les autres pour initialiser l'environnement du pod. ReplicaSet : un replicaSet se charge de maintenir actif un certain nombre de ressources de Pod bas\u00e9s sur un m\u00eame mod\u00e8le. Dans le cas de Civiparoisse, le passage par le ReplicaSet est plut\u00f4t anecdotique, dans la mesure o\u00f9 l'on ne maintiendra qu'un seul pod pour chaque t\u00e2che. Toutefois, le replicaSet est utilis\u00e9 indirectement par les d\u00e9ploiements. Namespace : le namespace est l'espace de nom, qui va permettre de regrouper les objets sp\u00e9cifiques \u00e0 une m\u00eame application (ici, un environnement Civiparoisse). Le namespace sera cr\u00e9e lors du d\u00e9ploiement du package Helm, via une option de la ligne de commande. De ce fait, on ne trouvera pas explicitement de d\u00e9finition du namespace. En ce qui concerne les types d'objets explicitement d\u00e9clar\u00e9s, on retrouve : PersistentVolumeClaim : cette ressource permet de d\u00e9finir un volume de stockage que l'on veut obtenir aupr\u00e8s d'un fournisseur (classe de stockage), avec des propri\u00e9t\u00e9s particuli\u00e8res (nom, taille du stockage, type d'acc\u00e8s...) ConfigMap : cette ressource permet de d\u00e9finir des couples clef-valeur qui vont ensuite \u00eatre rendus disponibles sous forme de variables d'environnement ou de montage de fichiers dans le conteneur. Ces objets ne sont pas pr\u00e9vus pour contenir des informations sensibles (mot de passes ou clefs par exemple) Secret : cette ressource permet le stockage d'informations sensibles dans le cluster Elle n'est normalement pas stock\u00e9 dans un conteneur, mais est mont\u00e9e comme fichier. CronJob : permet l'ex\u00e9cution p\u00e9riodique d'un type de pod Service : le service permet de publier au niveau du cluster la pr\u00e9sence d'un service qui est retrouv\u00e9 \u00e0 l'aide de s\u00e9lecteurs ; la publication se fait au niveau du DNS et dans les variables d'environnement. Deployment : objet d'ex\u00e9cution de charge pour les t\u00e2ches ne n\u00e9cessitant pas de gestion d'\u00e9tat ; ex : authenticateur StatefulSet : objet d'ex\u00e9cution de charge pour les t\u00e2ches n\u00e9cessitant une gestion d'\u00e9tat, et un nommage fixe ; ex : bd TransportServer : permet de configurer le TLS passthrough pour acc\u00e9der au pod reverse proxy d'une paroisse Description grosses mailles du chart Helm Le fichier principal du chart Helm est Chart.yaml. Ce fichier contient le versionning du package, mais surtout les annotations, qui peuvent \u00eatre utilis\u00e9es comme des constantes dans les templates. Dans ces annotations, on a en particulier les indications des images et des tags associ\u00e9s (pour le moment, tag latest, mais que sera \u00e0 changer pour le versionning r\u00e9el pour la production). Le principe de fonctionnement est d\u00e9crit dans la section d\u00e9di\u00e9e plus haut. Le fichier values.yaml contient des d\u00e9finitions de variables qui peuvent \u00eatre ensuite remplac\u00e9es lors de l'installation du chart. Ce sont les r\u00e9glages des valeurs de ce fichier qui va \u00eatre propre \u00e0 chaque paroisse (en plus des volumes de stockage). Le namespace sera d\u00e9fini \u00e0 l'installation du chart. Les constantes et les variables vont permettre de setter notamment les variables d'environnement ; les variables d'environnement sont expliqu\u00e9es au niveau des images Docker du projet. Le r\u00e9pertoire charts est pr\u00e9vu pour contenir des sous-charts. Ce r\u00e9pertoire est pour le moment vide. Le r\u00e9pertoire des templates contient les d\u00e9finitions des diff\u00e9rents composants pr\u00e9sent\u00e9s. Il n'y a que peu de choses \u00e0 dire, si ce n'est sur les secrets : les secrets peuvent \u00eatre r\u00e9cup\u00e9r\u00e9s depuis Kubernertes, de sorte \u00e0 ce qu'ils ne soient pas remplac\u00e9s par de nouvelles valeurs : c'est important pour les mot de passes. Ce m\u00e9canisme est \u00e9galement mis en oeuvre au niveau des clefs, car il est arriv\u00e9 que certains containers n'ont pas \u00e9t\u00e9 red\u00e9marr\u00e9s lors d'un upgrade et utilisaient les anciennes clefs, ce qui a d\u00e9clench\u00e9 un probl\u00e8me de communication entre les containers. Les containers d'initialisation ont plusieurs utilit\u00e9s : ils permettent d'initialiser des volumes avec des donn\u00e9es initiales, si les volumes sont vides ils permettent d'effectuer une synchronisation entre containers, en attendant qu'un service soit disponible par exemple, dans le container d'init. En ce qui concerne la synchronisation, l'ordre de d\u00e9marrage est fix\u00e9 dans une certaine mesure : le stateful set de base de donn\u00e9es d\u00e9marre en premier, en initilisant si n\u00e9cessaire la BD et les volumes persistants le serveur web interne d\u00e9marre ensuite le serveur proxy d\u00e9marre enfin le cron peut d\u00e9marrer du moment que la BD est initialis\u00e9e, c'est \u00e0 dire que le stateful set de BD est pr\u00eat. Le design pattern sidecar (et ses variantes) est utilis\u00e9 \u00e0 plusieurs reprises dans ce chart : au niveau de la BD, les connexions sont chiffr\u00e9es / chiffrables via des connexions SSL dont les terminaisons sont dans des sidecars au niveau du proxy, l'authentificateur est \u00e9galement un sidecar En termes de synchronisation / attentes : mysqladmin ping permet de v\u00e9rifier si une BD est disponible nslookup permet de v\u00e9rifier si un nom est r\u00e9solu ; ce test n'est toutefois pas trop int\u00e9ressant, car un service peut avoir une IP assign\u00e9e m\u00eame s'il n'y a pas de points de terminaisons associ\u00e9s au service nc -z permet de v\u00e9rifier si un port est ouvert","title":"Description g\u00e9n\u00e9rale"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/description_generale.html#chart-helm-description-generale","text":"","title":"Chart Helm: description g\u00e9n\u00e9rale"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/description_generale.html#helm","text":"Helm est un syst\u00e8me de packaging pour Kubernetes. L'int\u00e9r\u00eat de Helm est qu'il permet de pr\u00e9parer des mod\u00e8les de d\u00e9ploiement d'application, dans un package appel\u00e9 \"chart\". En pratique, il permet notamment d'avoir des mod\u00e8les (templates) pour d\u00e9ployer des ressources Kubernetes, et permet d'injecter des valeurs dans ces ressources. Ces valeurs peuvent \u00eatre par exemple pr\u00e9cises dans des fichiers de valeurs, ou \u00eatre calcul\u00e9es depuis des commandes indiqu\u00e9es dans les fichiers, ou m\u00eame \u00eatre r\u00e9cup\u00e9r\u00e9es depuis un cluster Kubernetes (par exemple des clefs de chiffrement). Helm constitue donc un outil essentiel pour packager un environnement de paroisse. L'installation de Helm se fait assez simplement en r\u00e9cup\u00e9rant l'archive Helm depuis https://github.com/helm/helm/releases , en v\u00e9rifiant la somme de contr\u00f4le, en d\u00e9compressant l'archive, et en mettant Helm a un endroit accessible depuis le path (avec les droits d'ex\u00e9cution). Quelques commandes utiles : helm install --create-namespace -n helmtls helmciviparoisse . : depuis le package Helm de civiparoisse (le . ), installer une release (ici nomm\u00e9e helmciviparoisse ) dans un namespace cr\u00e9e pour l'occasion (ici helmtls ), en utilisant les valeurs par d\u00e9faut helm uninstall -n helmtls helmciviparoisse : d\u00e9sinstaller les ressources de la release helmciviparoisse dans le namespace helmtls helm list -n helmtls : r\u00e9cup\u00e9rer les noms de releases d'un namespace (ici helmtls ) Attention : pour le moment, il faut builder les images uepal_test dans l'environnement docker de Minikube. De plus, il faut puller manuellement les images ubuntu, ubuntu/apache, ubuntu/mysql, \u00e0 cause des interactions avec le tag latest et la pull Policy mise \u00e0 none dans le package helm","title":"Helm"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/description_generale.html#description-des-types-dobjets-utilises-dans-le-chart-helm","text":"Il s'agit ici de d\u00e9finir une liste des types d'objets avec une br\u00e8ve description ; on se r\u00e9f\u00e8rera bien entendu \u00e0 la documentation Kubernetes ( https://kubernetes.io/fr/docs/concepts/ ) et Nginx ( https://docs.nginx.com/nginx-ingress-controller/configuration/transportserver-resource/ ) pour des explications compl\u00e8tes. On va trouver des objets de bas niveau, qui sont des objets de base, qui vont \u00eatre employ\u00e9s et g\u00e9r\u00e9s implicitement par les objets de plus haut niveau, dont notamment : Pod : le pod est un environnement d'ex\u00e9cution qui peut \u00eatre partag\u00e9 par un ou plusieurs containers. Les containers du pod auront tous acc\u00e8s au r\u00e9seau entre eux via le loopback (127.0.0.1), et ont un espace m\u00e9moire partag\u00e9. Outre les containers qui constituent la charge de travail pricipale du pod, on peut trouver des containers d'initialisation, qui sont lanc\u00e9s les uns apr\u00e8s les autres pour initialiser l'environnement du pod. ReplicaSet : un replicaSet se charge de maintenir actif un certain nombre de ressources de Pod bas\u00e9s sur un m\u00eame mod\u00e8le. Dans le cas de Civiparoisse, le passage par le ReplicaSet est plut\u00f4t anecdotique, dans la mesure o\u00f9 l'on ne maintiendra qu'un seul pod pour chaque t\u00e2che. Toutefois, le replicaSet est utilis\u00e9 indirectement par les d\u00e9ploiements. Namespace : le namespace est l'espace de nom, qui va permettre de regrouper les objets sp\u00e9cifiques \u00e0 une m\u00eame application (ici, un environnement Civiparoisse). Le namespace sera cr\u00e9e lors du d\u00e9ploiement du package Helm, via une option de la ligne de commande. De ce fait, on ne trouvera pas explicitement de d\u00e9finition du namespace. En ce qui concerne les types d'objets explicitement d\u00e9clar\u00e9s, on retrouve : PersistentVolumeClaim : cette ressource permet de d\u00e9finir un volume de stockage que l'on veut obtenir aupr\u00e8s d'un fournisseur (classe de stockage), avec des propri\u00e9t\u00e9s particuli\u00e8res (nom, taille du stockage, type d'acc\u00e8s...) ConfigMap : cette ressource permet de d\u00e9finir des couples clef-valeur qui vont ensuite \u00eatre rendus disponibles sous forme de variables d'environnement ou de montage de fichiers dans le conteneur. Ces objets ne sont pas pr\u00e9vus pour contenir des informations sensibles (mot de passes ou clefs par exemple) Secret : cette ressource permet le stockage d'informations sensibles dans le cluster Elle n'est normalement pas stock\u00e9 dans un conteneur, mais est mont\u00e9e comme fichier. CronJob : permet l'ex\u00e9cution p\u00e9riodique d'un type de pod Service : le service permet de publier au niveau du cluster la pr\u00e9sence d'un service qui est retrouv\u00e9 \u00e0 l'aide de s\u00e9lecteurs ; la publication se fait au niveau du DNS et dans les variables d'environnement. Deployment : objet d'ex\u00e9cution de charge pour les t\u00e2ches ne n\u00e9cessitant pas de gestion d'\u00e9tat ; ex : authenticateur StatefulSet : objet d'ex\u00e9cution de charge pour les t\u00e2ches n\u00e9cessitant une gestion d'\u00e9tat, et un nommage fixe ; ex : bd TransportServer : permet de configurer le TLS passthrough pour acc\u00e9der au pod reverse proxy d'une paroisse","title":"Description des types d'objets utilis\u00e9s dans le chart Helm"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/description_generale.html#description-grosses-mailles-du-chart-helm","text":"Le fichier principal du chart Helm est Chart.yaml. Ce fichier contient le versionning du package, mais surtout les annotations, qui peuvent \u00eatre utilis\u00e9es comme des constantes dans les templates. Dans ces annotations, on a en particulier les indications des images et des tags associ\u00e9s (pour le moment, tag latest, mais que sera \u00e0 changer pour le versionning r\u00e9el pour la production). Le principe de fonctionnement est d\u00e9crit dans la section d\u00e9di\u00e9e plus haut. Le fichier values.yaml contient des d\u00e9finitions de variables qui peuvent \u00eatre ensuite remplac\u00e9es lors de l'installation du chart. Ce sont les r\u00e9glages des valeurs de ce fichier qui va \u00eatre propre \u00e0 chaque paroisse (en plus des volumes de stockage). Le namespace sera d\u00e9fini \u00e0 l'installation du chart. Les constantes et les variables vont permettre de setter notamment les variables d'environnement ; les variables d'environnement sont expliqu\u00e9es au niveau des images Docker du projet. Le r\u00e9pertoire charts est pr\u00e9vu pour contenir des sous-charts. Ce r\u00e9pertoire est pour le moment vide. Le r\u00e9pertoire des templates contient les d\u00e9finitions des diff\u00e9rents composants pr\u00e9sent\u00e9s. Il n'y a que peu de choses \u00e0 dire, si ce n'est sur les secrets : les secrets peuvent \u00eatre r\u00e9cup\u00e9r\u00e9s depuis Kubernertes, de sorte \u00e0 ce qu'ils ne soient pas remplac\u00e9s par de nouvelles valeurs : c'est important pour les mot de passes. Ce m\u00e9canisme est \u00e9galement mis en oeuvre au niveau des clefs, car il est arriv\u00e9 que certains containers n'ont pas \u00e9t\u00e9 red\u00e9marr\u00e9s lors d'un upgrade et utilisaient les anciennes clefs, ce qui a d\u00e9clench\u00e9 un probl\u00e8me de communication entre les containers. Les containers d'initialisation ont plusieurs utilit\u00e9s : ils permettent d'initialiser des volumes avec des donn\u00e9es initiales, si les volumes sont vides ils permettent d'effectuer une synchronisation entre containers, en attendant qu'un service soit disponible par exemple, dans le container d'init. En ce qui concerne la synchronisation, l'ordre de d\u00e9marrage est fix\u00e9 dans une certaine mesure : le stateful set de base de donn\u00e9es d\u00e9marre en premier, en initilisant si n\u00e9cessaire la BD et les volumes persistants le serveur web interne d\u00e9marre ensuite le serveur proxy d\u00e9marre enfin le cron peut d\u00e9marrer du moment que la BD est initialis\u00e9e, c'est \u00e0 dire que le stateful set de BD est pr\u00eat. Le design pattern sidecar (et ses variantes) est utilis\u00e9 \u00e0 plusieurs reprises dans ce chart : au niveau de la BD, les connexions sont chiffr\u00e9es / chiffrables via des connexions SSL dont les terminaisons sont dans des sidecars au niveau du proxy, l'authentificateur est \u00e9galement un sidecar En termes de synchronisation / attentes : mysqladmin ping permet de v\u00e9rifier si une BD est disponible nslookup permet de v\u00e9rifier si un nom est r\u00e9solu ; ce test n'est toutefois pas trop int\u00e9ressant, car un service peut avoir une IP assign\u00e9e m\u00eame s'il n'y a pas de points de terminaisons associ\u00e9s au service nc -z permet de v\u00e9rifier si un port est ouvert","title":"Description grosses mailles du chart Helm"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/httpd.html","text":"Serveur web interne Il n'y a pas grand chose \u00e0 dire \u00e0 ce niveau, si ce n'est qu'on attend sur la disponibilit\u00e9 du proxy DB dans un container d'initialisation, puis qu'on utilise un sidecar pour se connecter \u00e0 la BD. La plupart des param\u00e8tres de configuration sont pass\u00e9s dans l'environnement via une configMap, tandis que les fichiers des clefs sont mont\u00e9s via des secrets.","title":"Serveur web interne"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/httpd.html#serveur-web-interne","text":"Il n'y a pas grand chose \u00e0 dire \u00e0 ce niveau, si ce n'est qu'on attend sur la disponibilit\u00e9 du proxy DB dans un container d'initialisation, puis qu'on utilise un sidecar pour se connecter \u00e0 la BD. La plupart des param\u00e8tres de configuration sont pass\u00e9s dans l'environnement via une configMap, tandis que les fichiers des clefs sont mont\u00e9s via des secrets.","title":"Serveur web interne"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/proxy_auth.html","text":"Proxy web et authenticateur Le proxy web est d\u00e9clar\u00e9 dans un d\u00e9ploiement, car il n'a pas de r\u00e9el \u00e9tat. Il dispose \u00e9ventuellement d'un cache d'authentification, mais les entr\u00e9es de ce cache n'ont pas vocation \u00e0 rester valide longtemps, et il peut \u00eatre reconstruit au fur et \u00e0 mesure de l'utilisation de civiparoisse. Le proxy web est synchronis\u00e9 sur le serveur web interne via un container d'initialisation qui attend l'ouverture du port (v\u00e9rification p\u00e9riodique avec nc -z ). Le mod\u00e8le MPM du proxy a \u00e9t\u00e9 pass\u00e9 en prefork pour n'utiliser qu'une seule technologie dans le projet (simplification des comp\u00e9tences requises). Le proxy a un sidecar : le container d'authentification ; les deux discutent via une socket mont\u00e9e dans un emptyDir en m\u00e9moire. La plupart de la configuration est stock\u00e9e dans des config maps inject\u00e9es dans l'environnement, ainsi que dans des secrets.","title":"Proxy et authenticateur"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/proxy_auth.html#proxy-web-et-authenticateur","text":"Le proxy web est d\u00e9clar\u00e9 dans un d\u00e9ploiement, car il n'a pas de r\u00e9el \u00e9tat. Il dispose \u00e9ventuellement d'un cache d'authentification, mais les entr\u00e9es de ce cache n'ont pas vocation \u00e0 rester valide longtemps, et il peut \u00eatre reconstruit au fur et \u00e0 mesure de l'utilisation de civiparoisse. Le proxy web est synchronis\u00e9 sur le serveur web interne via un container d'initialisation qui attend l'ouverture du port (v\u00e9rification p\u00e9riodique avec nc -z ). Le mod\u00e8le MPM du proxy a \u00e9t\u00e9 pass\u00e9 en prefork pour n'utiliser qu'une seule technologie dans le projet (simplification des comp\u00e9tences requises). Le proxy a un sidecar : le container d'authentification ; les deux discutent via une socket mont\u00e9e dans un emptyDir en m\u00e9moire. La plupart de la configuration est stock\u00e9e dans des config maps inject\u00e9es dans l'environnement, ainsi que dans des secrets.","title":"Proxy web et authenticateur"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/reservations.html","text":"R\u00e9servations de ressources Consid\u00e9rations G\u00e9n\u00e9rales La r\u00e9servation des ressources est un domaine important dans Kubernetes, car les r\u00e9servations permettent de mieux planifier l'ex\u00e9cution des pods. Les ressources attribu\u00e9es seraient garanties quand la demande et la limite sont \u00e9quivalentes. D'o\u00f9 la mise en oeuvre de limitations et de requ\u00eates de m\u00eames valeurs, et ce au niveau CPU et m\u00e9moire. Le profilage des ressources consomm\u00e9es joue sur plusieurs \u00e9l\u00e9ments : la RAM et l'espace disque sont des ressources critiques : en particulier, si l'on n'a plus de RAM, le container peut crasher ; en revanche, au niveau CPU, on jouera plut\u00f4t sur les performances (\u00e0 moins d'avoir des prol\u00e9matiques de temporisation) la BD est pr\u00e9vue initialement pour tenir dans 512Mo ; en d\u00e9sactivant performance_schema, on devrait pouvoir tenir dans 350Mo on peut limiter au niveau d'Apache le nombre de requ\u00eates servies simultan\u00e9ment ; ces requ\u00eates, lorsqu'elles arrivent sur du code PHP, font entrer en jeu la limite m\u00e9moire de PHP. On arrive alors \u00e0 borner la plus grosse d\u00e9pense m\u00e9moire le cron travaille avec un seul environnement PHP \u00e0 la fois : il devrait donc \u00eatre possible de borner sa consommation de RAM il y a le probl\u00e8me de l'authentification de toutes les requ\u00eates : si on passe \u00e0 la double authentification, on peut envisager d'utiliser le cache d'authentification malgr\u00e9 sa structure qui n'est plus satisfaisante, ce qui permettrait une meilleure utilisation des ressources on ne peut pas encore d\u00e9terminer avec pr\u00e9cision les espaces disques qui seront \u00e0 allouer, que ce soit pour les volumes persistants ou pour les volumes \u00e9ph\u00e9m\u00e8res (dont logs) il a \u00e9t\u00e9 pr\u00e9vu de pouvoir changer les valeurs des ressources dans chaque d\u00e9ploiement de release : en effet, la charge d\u00e9pend aussi de l'utilisation (intensive ou non) qui sera faite de l'outil. Il peut \u00eatre compr\u00e9hensible de chercher \u00e0 contenter les plus gros consommateurs tant que ce n'est pas au d\u00e9triment des autres consommateurs il ne faut pas oublier que le nombre cible de d\u00e9ploiements est tr\u00e8s cons\u00e9quent : de ce fait, des petites \u00e9conomies de ressources peuvent avoir toutefois un effet notable on ne peut pas additionner aveugl\u00e9ment les ressources de tous les containers : il faut \u00e9galement consid\u00e9rer l'ordre de d\u00e9marrage des pods, et le fait que les containers d'init d'un pod n'existent pas en m\u00eame temps que les containers qui constituent la v\u00e9ritable charge de travail il ne faut pas oublier que toutes les ressources du cloud ont un co\u00fbt associ\u00e9, d'o\u00f9 l'apparition d'une nouvelle d\u00e9marche : le FinOps, qui cherche \u00e0 optimiser l'utilisation des ressources et le co\u00fbt. Estimations des ressources d'une instance Hypoth\u00e8ses de travail Il est n\u00e9cessaire de poser un certain nombre d'hypoth\u00e8ses de travail : on va supposer que l'on va utiliser le cache d'authentification ; en effet, le co\u00fbt d'une authentification multifacteur via du SSL est un co\u00fbt quasiment consid\u00e9rable comme fixe (prix des clefs de s\u00e9curit\u00e9, et \u00e9ventuellement, prix des certificats (annuels ou multiannuels)s'ils ne sont pas autog\u00e9n\u00e9r\u00e9s), alors que la puissance consomm\u00e9e d\u00e9pend du nombre de requ\u00eates, et influe donc sur le co\u00fbt de revient mensuel de l'instance : on va limiter le nombre de requ\u00eates traitables simultan\u00e9ment. on va se baser sur des ressources garanties (request=limit sur les r\u00e9servations), pour ne pas avoir en th\u00e9orie de probl\u00e8mes d'\u00e9viction il faudra rajouter le co\u00fbt d'un probable firewall qui viendra en coupure des flux on va passer sur un mod\u00e8le de threading Apache en mpm_prefork, qui est de toute fa\u00e7on utilis\u00e9 pour le PHP si on n'utilise pas php-fpm, et on va utiliser par simplicit\u00e9 ce mod\u00e8le de threading \u00e0 la fois sur le serveur web interne et le reverse proxy le minimum de m\u00e9moire (memory_limit requis par Drupal est 64M); toutefois selon https://docs.civicrm.org/installation/en/latest/general/requirements/ il faudrait passer au moins \u00e0 256M les logs passeront par un DaemonSet EFK ou \u00e9quivalent : du coup, le conteneur de gestion des logs n'est pas comptabilis\u00e9 dans l'infrastructure d'une instance on suppose qu'on n'int\u00e8gre pas de serveur de m\u00e9dias, qu'on n'int\u00e8gre pas le traitement des mails entrants (donc traitement manuel), et qu'on sp\u00e9cialise le traitement des mails sortants configuration mpm_prefork : MAX_CONNECTIONS_PER_CHILD=1 MAX_REQUEST_WORKERS=4 SERVER_LIMIT=4 START_SERVERS=4 MIN_SPARE_SERVERS=0 MAX_SPARE_SERVERS=4 Du coup, on sert 4 connexions simultan\u00e9es, ce qui pourrait \u00eatre suffisant pour un seul utilisateur. Conteneur Description Limite m\u00e9moire Limite CPU proxy reverse proxy d'authentification 256Mi 250m proxy_init init du reverse proxy 50Mi 100m auth (proxy_authenticator) authentificateur 256Mi 250m cron ex\u00e9cution cron 384Mi 250m cron_dbproxy acc\u00e8s tunnel BD SSL pour cron 50Mi 100m cron_init initialisation du pod cron 50Mi 100m httpd serveur web interne 1536Mi 1000m httpd_dbproxy acc\u00e8s tunnel BD SSL pour serveur web 100Mi 100m httpd_init initialisation du pod server web interne 50Mi 100m db conteneur BD 512Mi 250m db_init initialisation environnement BD 1024Mi 1000m dbproxy acc\u00e8s tunnel BD SSL pour le serveur BD 100Mi 100m Ordre de d\u00e9marrage (sans sp\u00e9cialisation du mail sortant): Les containeurs d'initialisation impl\u00e9mentent les contraintes suivantes : db_init permet de lancer db et dbproxy httpd_init d\u00e9pend de dbproxy pour lancer httpd_dbproxy et httpd cron_init d\u00e9pend de dbproxy pour lancer cron et cron_dbproxy proxy_init d\u00e9pend du lancement de httpd pour lancer proxy et auth On en obtient un \u00e9quivalent de graphe de d\u00e9pendances : db_init db dbproxy httpd_init httpd_dbproxy httpd proxy_init proxy auth cron_init cron cron_dbproxy On peut d\u00e9duire deux phases de lancement d'une instance : installation initiale : seul db_init est lanc\u00e9 : 1024Mi, 1000m ensuite, le pire cas est quand tous les services tournent, car httpd_init , proxy_init et cron_init consomment moins que les services proprement dits. Toutefois, l'unit\u00e9 \u00e9tant le pod d'ex\u00e9cution (\u00e0 cause du scheduling sur les noeuds), il faut faire des sommes s\u00e9par\u00e9es pour chaque pod : pod db : 1124Mi et 1100m pod cron : 434Mi et 350m pod httpd : 1636Mi et 1100m pod proxy : 512Mi et 500m Ce \u00e0 quoi on ajoute la sp\u00e9cialisation du mail sortant : Client d'acc\u00e8s \u00e0 50Mi et 100m pour le pod httpd et le pod proxy Pod sp\u00e9cifique d'envoi des mails : 256Mi et 200m On en arrive donc, avec la sp\u00e9cialisation du mail sortant : pod db : 1124Mi et 1100m pod cron : 484Mi et 450m pod httpd : 1686Mi et 1200m pod proxy : 512Mi et 500m pod mail_sortant : 256Mi et 200m Donc une consommation totale max de : 4062Mi et 3450m","title":"R\u00e9servations"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/reservations.html#reservations-de-ressources","text":"","title":"R\u00e9servations de ressources"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/reservations.html#considerations-generales","text":"La r\u00e9servation des ressources est un domaine important dans Kubernetes, car les r\u00e9servations permettent de mieux planifier l'ex\u00e9cution des pods. Les ressources attribu\u00e9es seraient garanties quand la demande et la limite sont \u00e9quivalentes. D'o\u00f9 la mise en oeuvre de limitations et de requ\u00eates de m\u00eames valeurs, et ce au niveau CPU et m\u00e9moire. Le profilage des ressources consomm\u00e9es joue sur plusieurs \u00e9l\u00e9ments : la RAM et l'espace disque sont des ressources critiques : en particulier, si l'on n'a plus de RAM, le container peut crasher ; en revanche, au niveau CPU, on jouera plut\u00f4t sur les performances (\u00e0 moins d'avoir des prol\u00e9matiques de temporisation) la BD est pr\u00e9vue initialement pour tenir dans 512Mo ; en d\u00e9sactivant performance_schema, on devrait pouvoir tenir dans 350Mo on peut limiter au niveau d'Apache le nombre de requ\u00eates servies simultan\u00e9ment ; ces requ\u00eates, lorsqu'elles arrivent sur du code PHP, font entrer en jeu la limite m\u00e9moire de PHP. On arrive alors \u00e0 borner la plus grosse d\u00e9pense m\u00e9moire le cron travaille avec un seul environnement PHP \u00e0 la fois : il devrait donc \u00eatre possible de borner sa consommation de RAM il y a le probl\u00e8me de l'authentification de toutes les requ\u00eates : si on passe \u00e0 la double authentification, on peut envisager d'utiliser le cache d'authentification malgr\u00e9 sa structure qui n'est plus satisfaisante, ce qui permettrait une meilleure utilisation des ressources on ne peut pas encore d\u00e9terminer avec pr\u00e9cision les espaces disques qui seront \u00e0 allouer, que ce soit pour les volumes persistants ou pour les volumes \u00e9ph\u00e9m\u00e8res (dont logs) il a \u00e9t\u00e9 pr\u00e9vu de pouvoir changer les valeurs des ressources dans chaque d\u00e9ploiement de release : en effet, la charge d\u00e9pend aussi de l'utilisation (intensive ou non) qui sera faite de l'outil. Il peut \u00eatre compr\u00e9hensible de chercher \u00e0 contenter les plus gros consommateurs tant que ce n'est pas au d\u00e9triment des autres consommateurs il ne faut pas oublier que le nombre cible de d\u00e9ploiements est tr\u00e8s cons\u00e9quent : de ce fait, des petites \u00e9conomies de ressources peuvent avoir toutefois un effet notable on ne peut pas additionner aveugl\u00e9ment les ressources de tous les containers : il faut \u00e9galement consid\u00e9rer l'ordre de d\u00e9marrage des pods, et le fait que les containers d'init d'un pod n'existent pas en m\u00eame temps que les containers qui constituent la v\u00e9ritable charge de travail il ne faut pas oublier que toutes les ressources du cloud ont un co\u00fbt associ\u00e9, d'o\u00f9 l'apparition d'une nouvelle d\u00e9marche : le FinOps, qui cherche \u00e0 optimiser l'utilisation des ressources et le co\u00fbt.","title":"Consid\u00e9rations G\u00e9n\u00e9rales"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/reservations.html#estimations-des-ressources-dune-instance","text":"","title":"Estimations des ressources d'une instance"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/reservations.html#hypotheses-de-travail","text":"Il est n\u00e9cessaire de poser un certain nombre d'hypoth\u00e8ses de travail : on va supposer que l'on va utiliser le cache d'authentification ; en effet, le co\u00fbt d'une authentification multifacteur via du SSL est un co\u00fbt quasiment consid\u00e9rable comme fixe (prix des clefs de s\u00e9curit\u00e9, et \u00e9ventuellement, prix des certificats (annuels ou multiannuels)s'ils ne sont pas autog\u00e9n\u00e9r\u00e9s), alors que la puissance consomm\u00e9e d\u00e9pend du nombre de requ\u00eates, et influe donc sur le co\u00fbt de revient mensuel de l'instance : on va limiter le nombre de requ\u00eates traitables simultan\u00e9ment. on va se baser sur des ressources garanties (request=limit sur les r\u00e9servations), pour ne pas avoir en th\u00e9orie de probl\u00e8mes d'\u00e9viction il faudra rajouter le co\u00fbt d'un probable firewall qui viendra en coupure des flux on va passer sur un mod\u00e8le de threading Apache en mpm_prefork, qui est de toute fa\u00e7on utilis\u00e9 pour le PHP si on n'utilise pas php-fpm, et on va utiliser par simplicit\u00e9 ce mod\u00e8le de threading \u00e0 la fois sur le serveur web interne et le reverse proxy le minimum de m\u00e9moire (memory_limit requis par Drupal est 64M); toutefois selon https://docs.civicrm.org/installation/en/latest/general/requirements/ il faudrait passer au moins \u00e0 256M les logs passeront par un DaemonSet EFK ou \u00e9quivalent : du coup, le conteneur de gestion des logs n'est pas comptabilis\u00e9 dans l'infrastructure d'une instance on suppose qu'on n'int\u00e8gre pas de serveur de m\u00e9dias, qu'on n'int\u00e8gre pas le traitement des mails entrants (donc traitement manuel), et qu'on sp\u00e9cialise le traitement des mails sortants configuration mpm_prefork : MAX_CONNECTIONS_PER_CHILD=1 MAX_REQUEST_WORKERS=4 SERVER_LIMIT=4 START_SERVERS=4 MIN_SPARE_SERVERS=0 MAX_SPARE_SERVERS=4 Du coup, on sert 4 connexions simultan\u00e9es, ce qui pourrait \u00eatre suffisant pour un seul utilisateur. Conteneur Description Limite m\u00e9moire Limite CPU proxy reverse proxy d'authentification 256Mi 250m proxy_init init du reverse proxy 50Mi 100m auth (proxy_authenticator) authentificateur 256Mi 250m cron ex\u00e9cution cron 384Mi 250m cron_dbproxy acc\u00e8s tunnel BD SSL pour cron 50Mi 100m cron_init initialisation du pod cron 50Mi 100m httpd serveur web interne 1536Mi 1000m httpd_dbproxy acc\u00e8s tunnel BD SSL pour serveur web 100Mi 100m httpd_init initialisation du pod server web interne 50Mi 100m db conteneur BD 512Mi 250m db_init initialisation environnement BD 1024Mi 1000m dbproxy acc\u00e8s tunnel BD SSL pour le serveur BD 100Mi 100m Ordre de d\u00e9marrage (sans sp\u00e9cialisation du mail sortant): Les containeurs d'initialisation impl\u00e9mentent les contraintes suivantes : db_init permet de lancer db et dbproxy httpd_init d\u00e9pend de dbproxy pour lancer httpd_dbproxy et httpd cron_init d\u00e9pend de dbproxy pour lancer cron et cron_dbproxy proxy_init d\u00e9pend du lancement de httpd pour lancer proxy et auth On en obtient un \u00e9quivalent de graphe de d\u00e9pendances : db_init db dbproxy httpd_init httpd_dbproxy httpd proxy_init proxy auth cron_init cron cron_dbproxy On peut d\u00e9duire deux phases de lancement d'une instance : installation initiale : seul db_init est lanc\u00e9 : 1024Mi, 1000m ensuite, le pire cas est quand tous les services tournent, car httpd_init , proxy_init et cron_init consomment moins que les services proprement dits. Toutefois, l'unit\u00e9 \u00e9tant le pod d'ex\u00e9cution (\u00e0 cause du scheduling sur les noeuds), il faut faire des sommes s\u00e9par\u00e9es pour chaque pod : pod db : 1124Mi et 1100m pod cron : 434Mi et 350m pod httpd : 1636Mi et 1100m pod proxy : 512Mi et 500m Ce \u00e0 quoi on ajoute la sp\u00e9cialisation du mail sortant : Client d'acc\u00e8s \u00e0 50Mi et 100m pour le pod httpd et le pod proxy Pod sp\u00e9cifique d'envoi des mails : 256Mi et 200m On en arrive donc, avec la sp\u00e9cialisation du mail sortant : pod db : 1124Mi et 1100m pod cron : 484Mi et 450m pod httpd : 1686Mi et 1200m pod proxy : 512Mi et 500m pod mail_sortant : 256Mi et 200m Donc une consommation totale max de : 4062Mi et 3450m","title":"Hypoth\u00e8ses de travail"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/secrets.html","text":"Secrets Les secrets sont de deux types : le stockage des donn\u00e9es sensibles de type \"mot de passe\" : mot de passe DB, utilisateur/mot de passe admin Drupal : ces donn\u00e9es sont g\u00e9n\u00e9r\u00e9es par d\u00e9faut (en particulier avec la fonction randAlpha de Helm), et r\u00e9utilis\u00e9es si elles existent les infrastructures de clef : trois CA sont utilis\u00e9s : le CA pour le certificat pr\u00e9sent\u00e9 aux utilisateurs, au travers du proxy/auth le CA utilis\u00e9 pour les tunnels SSL pour la communication avec la BD : certificat pour le serveur db, pour le proxy db pour le serveur web interne, pour le proxy db pour cron le CA utilis\u00e9 pour les communications avec le serveur web interne : serveur web interne, partie client interne du proxy, authenticateur On utilise \u00e9galement la fonction lookup de Helm pour conserver les clefs existantes et avoir ainsi une stabilit\u00e9 des clefs.","title":"Secrets"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/secrets.html#secrets","text":"Les secrets sont de deux types : le stockage des donn\u00e9es sensibles de type \"mot de passe\" : mot de passe DB, utilisateur/mot de passe admin Drupal : ces donn\u00e9es sont g\u00e9n\u00e9r\u00e9es par d\u00e9faut (en particulier avec la fonction randAlpha de Helm), et r\u00e9utilis\u00e9es si elles existent les infrastructures de clef : trois CA sont utilis\u00e9s : le CA pour le certificat pr\u00e9sent\u00e9 aux utilisateurs, au travers du proxy/auth le CA utilis\u00e9 pour les tunnels SSL pour la communication avec la BD : certificat pour le serveur db, pour le proxy db pour le serveur web interne, pour le proxy db pour cron le CA utilis\u00e9 pour les communications avec le serveur web interne : serveur web interne, partie client interne du proxy, authenticateur On utilise \u00e9galement la fonction lookup de Helm pour conserver les clefs existantes et avoir ainsi une stabilit\u00e9 des clefs.","title":"Secrets"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/volumes.html","text":"Volumes (persistants) Les volumes dont il est question ici sont les volumes persistants. Les volumes temporaires sont la plupart du temps utilis\u00e9 dans le contexte d'une mise \u00e0 disposition d'une socket Unix via un emptyDir. Les volumes sont g\u00e9r\u00e9s au travers de PersistentFolumeClaim sur une classe de stockage, avec un mode ReadwriteMany. Les tailles pr\u00e9sentes dans le chart seront \u00e0 adapter \u00e0 l'usage. On retrouve trois volumes persistants : dbvolclaim : le stockage des fichiers de la BD filevolclaim : le stockage des fichiers du site civicrm privatevolclaim: le stockage des fichiers priv\u00e9s du site civicrm D'autres volumes pourront faire leur apparition, notamment pour la sauvegarde, les logs, les mails.","title":"Volumes (persistants)"},{"location":"TECHNIQUE/INTEGRATION/KUBERNETES/HELM/volumes.html#volumes-persistants","text":"Les volumes dont il est question ici sont les volumes persistants. Les volumes temporaires sont la plupart du temps utilis\u00e9 dans le contexte d'une mise \u00e0 disposition d'une socket Unix via un emptyDir. Les volumes sont g\u00e9r\u00e9s au travers de PersistentFolumeClaim sur une classe de stockage, avec un mode ReadwriteMany. Les tailles pr\u00e9sentes dans le chart seront \u00e0 adapter \u00e0 l'usage. On retrouve trois volumes persistants : dbvolclaim : le stockage des fichiers de la BD filevolclaim : le stockage des fichiers du site civicrm privatevolclaim: le stockage des fichiers priv\u00e9s du site civicrm D'autres volumes pourront faire leur apparition, notamment pour la sauvegarde, les logs, les mails.","title":"Volumes (persistants)"},{"location":"TECHNIQUE/LOGICIEL/index.html","text":"Aspects logiciels D\u00e9veloppements sp\u00e9cifiques Les besoins fonctionnels seront trait\u00e9s via des d\u00e9veloppements sp\u00e9cifiques s\u2019appuyant sur CiviCRM, qui est un CRM \u00e9crit en PHP n\u00e9cessitant un CMS et une stack LAMP. Le CMS Drupal a \u00e9t\u00e9 choisi \u00e0 cet effet. Les d\u00e9veloppements sp\u00e9cifiques sont r\u00e9partis \u00e0 ce jour en trois modules : un module drupal : ce module n\u2019est qu\u2019un module qui remplit un besoin technique (permettre l\u2019utilisation de l\u2019authentification de type basic) un module civicrm : ce module int\u00e8gre les adaptations de CiviCRM n\u00e9cessaires pour les fonctions \u00ab coeur de m\u00e9tier \u00bb un module plugin d'installation pour civicrm : ce module int\u00e8gre certains aspects d'installation initiale de CiviCRM qui ne sont pas ou difficilement pr\u00e9vus pour la ligne de commande. Chaque module est versionn\u00e9 dans git, et constitue un package composer. Le choix d\u2019utiliser composer n\u2019est pas anodin : il est utilis\u00e9 \u00e0 la fois par CiviCRM et Drupal, ce qui uniformise dans une certaine mesure la gestion des fichiers source du projet. Il a \u00e9t\u00e9 d\u00e9cid\u00e9 de suivre la gestion git \u00ab gitflow \u00bb ( https://www.atlassian.com/fr/git/tutorials/comparing-workflows/gitflow-workflow ). Le suivi des d\u00e9veloppements se fait via les outils mis \u00e0 disposition sur Github (dont notamment les issues). Qualit\u00e9 du code Le code sp\u00e9cifique est pour l\u2019heure encore non stabilis\u00e9. N\u00e9anmoins, il devra \u00eatre envisag\u00e9 de mettre en place des tests automatis\u00e9s pour fiabiliser les d\u00e9veloppements, voire m\u00eame de faire de l\u2019int\u00e9gration continue. Distribution du code sp\u00e9cifique Le code a pour vocation d\u2019\u00eatre sous licence \u00ab logiciel libre \u00bb (licence exacte \u00e0 d\u00e9finir). De ce fait, il conviendra de publier le code source dans un d\u00e9p\u00f4t git \u00ab public \u00bb. Toutefois, mettre \u00e0 disposition le code n\u2019implique pas de mettre \u00e0 disposition le d\u00e9tail des interactions des intervenants (ni leur identit\u00e9). De ce fait, il est pr\u00e9vu que la publication sur le d\u00e9p\u00f4t git public se fasse \u00e0 travers un fetch remote de profondeur 1 et un checkout en orphan release de FETCH_HEAD, de sorte \u00e0 conserver uniquement le code, et pas l\u2019historique. Cette mani\u00e8re de proc\u00e9der permettra toutefois les comparaisons d\u2019une version \u00e0 l\u2019autre, ainsi que la mise en place des tags qui sont n\u00e9cessaires pour identifier les versions. Utilisation de modules tiers D\u2019autres modules / extensions peuvent \u00e9galement \u00eatre n\u00e9cessaires au projet : il s\u2019agira de les int\u00e9grer, dans la mesure du possible, comme des packages composer. Au pire des cas, on pourra utiliser un repository de type \u00ab package \u00bb dans composer (cf https://getcomposer.org/doc/05-repositories.md#package-2 ). Documents Cette section r\u00e9pertoire les documentations relatives au d\u00e9veloppement logiciel de Civiparoisse. Distribution du code Environnement de dev Importation des donn\u00e9es","title":"Index"},{"location":"TECHNIQUE/LOGICIEL/index.html#aspects-logiciels","text":"","title":"Aspects logiciels"},{"location":"TECHNIQUE/LOGICIEL/index.html#developpements-specifiques","text":"Les besoins fonctionnels seront trait\u00e9s via des d\u00e9veloppements sp\u00e9cifiques s\u2019appuyant sur CiviCRM, qui est un CRM \u00e9crit en PHP n\u00e9cessitant un CMS et une stack LAMP. Le CMS Drupal a \u00e9t\u00e9 choisi \u00e0 cet effet. Les d\u00e9veloppements sp\u00e9cifiques sont r\u00e9partis \u00e0 ce jour en trois modules : un module drupal : ce module n\u2019est qu\u2019un module qui remplit un besoin technique (permettre l\u2019utilisation de l\u2019authentification de type basic) un module civicrm : ce module int\u00e8gre les adaptations de CiviCRM n\u00e9cessaires pour les fonctions \u00ab coeur de m\u00e9tier \u00bb un module plugin d'installation pour civicrm : ce module int\u00e8gre certains aspects d'installation initiale de CiviCRM qui ne sont pas ou difficilement pr\u00e9vus pour la ligne de commande. Chaque module est versionn\u00e9 dans git, et constitue un package composer. Le choix d\u2019utiliser composer n\u2019est pas anodin : il est utilis\u00e9 \u00e0 la fois par CiviCRM et Drupal, ce qui uniformise dans une certaine mesure la gestion des fichiers source du projet. Il a \u00e9t\u00e9 d\u00e9cid\u00e9 de suivre la gestion git \u00ab gitflow \u00bb ( https://www.atlassian.com/fr/git/tutorials/comparing-workflows/gitflow-workflow ). Le suivi des d\u00e9veloppements se fait via les outils mis \u00e0 disposition sur Github (dont notamment les issues).","title":"D\u00e9veloppements sp\u00e9cifiques"},{"location":"TECHNIQUE/LOGICIEL/index.html#qualite-du-code","text":"Le code sp\u00e9cifique est pour l\u2019heure encore non stabilis\u00e9. N\u00e9anmoins, il devra \u00eatre envisag\u00e9 de mettre en place des tests automatis\u00e9s pour fiabiliser les d\u00e9veloppements, voire m\u00eame de faire de l\u2019int\u00e9gration continue.","title":"Qualit\u00e9 du code"},{"location":"TECHNIQUE/LOGICIEL/index.html#distribution-du-code-specifique","text":"Le code a pour vocation d\u2019\u00eatre sous licence \u00ab logiciel libre \u00bb (licence exacte \u00e0 d\u00e9finir). De ce fait, il conviendra de publier le code source dans un d\u00e9p\u00f4t git \u00ab public \u00bb. Toutefois, mettre \u00e0 disposition le code n\u2019implique pas de mettre \u00e0 disposition le d\u00e9tail des interactions des intervenants (ni leur identit\u00e9). De ce fait, il est pr\u00e9vu que la publication sur le d\u00e9p\u00f4t git public se fasse \u00e0 travers un fetch remote de profondeur 1 et un checkout en orphan release de FETCH_HEAD, de sorte \u00e0 conserver uniquement le code, et pas l\u2019historique. Cette mani\u00e8re de proc\u00e9der permettra toutefois les comparaisons d\u2019une version \u00e0 l\u2019autre, ainsi que la mise en place des tags qui sont n\u00e9cessaires pour identifier les versions.","title":"Distribution du code sp\u00e9cifique"},{"location":"TECHNIQUE/LOGICIEL/index.html#utilisation-de-modules-tiers","text":"D\u2019autres modules / extensions peuvent \u00e9galement \u00eatre n\u00e9cessaires au projet : il s\u2019agira de les int\u00e9grer, dans la mesure du possible, comme des packages composer. Au pire des cas, on pourra utiliser un repository de type \u00ab package \u00bb dans composer (cf https://getcomposer.org/doc/05-repositories.md#package-2 ).","title":"Utilisation de modules tiers"},{"location":"TECHNIQUE/LOGICIEL/index.html#documents","text":"Cette section r\u00e9pertoire les documentations relatives au d\u00e9veloppement logiciel de Civiparoisse. Distribution du code Environnement de dev Importation des donn\u00e9es","title":"Documents"},{"location":"TECHNIQUE/LOGICIEL/distribution_code_composer.html","text":"Distribution du code de Civiparoisse La distribution du code de Civiparoisse est un point crucial de l\u2019industrialisation de l\u2019installation des instances CiviCRM. On a d\u00e9j\u00e0 vu que Composer procurait une facilit\u00e9 d\u2019installation et de mise \u00e0 jour des instances de Drupal et du coeur de CiviCRM. Il est donc int\u00e9ressant de capitaliser sur Composer. Pour ce faire, il \u00e9tait tout d\u2019abord n\u00e9cessaire d\u2019unifier les modules civiparoisse existants en un seul, de le pr\u00e9parer pour devenir un package, puis g\u00e9n\u00e9rer les packages, et enfin les utiliser. Unification des extensions Civiparoisse L\u2019unification des extensions Civiparoisse s\u2019est impos\u00e9e pour plusieurs raisons : les diff\u00e9rentes extensions avaient fonctionnellement le m\u00eame but : fournir la gestion op\u00e9rationnelle des paroisses, et d\u00e9pendaient les unes des autres pour fournir la fonctionnalit\u00e9 globale : ces \u00e9ventuelles interd\u00e9pendances auraient pu devenir probl\u00e9matique pour la maintenance des extensions, d\u2019aunt plus que certains \u00e9l\u00e9ments n\u00e9cessitent des \u00ab racines \u00bb (par exemple : cr\u00e9ation d\u2019un menu \u00ab racine \u00bb Uepal) diff\u00e9rentes extensions peuvent conduire \u00e0 de la duplication de code : en effet, certains m\u00e9canismes comme la gestion des menus, les settings, auraient pu \u00eatre requis dans le temps par plusieurs modules la gestion de versions est facilit\u00e9e : une seule version \u00e9tait d\u00e9j\u00e0 pr\u00e9vue pour tout le code via les tags git : on pourra donc aligner la version de info.xml et les tags les s\u00e9parations qui semblaient n\u00e9cessaires restent pr\u00e9sentes, mais sont int\u00e9gr\u00e9es dans des niveaux plus profonds : on retrouve diff\u00e9rents \u00ab namespaces \u00bb, comme CRM_Civiparoisse_Parametres,CRM_Civiparoisse_Pages\u2026 Il en est de m\u00eame pour les templates associ\u00e9s Composer peut utiliser un d\u00e9p\u00f4t git comme un repository qui contient un package versionn\u00e9 avec les tags ; si on ne souhaite pas utiliser directement le d\u00e9p\u00f4t git, il est \u00e9galement possible de g\u00e9n\u00e9rer un site web \u00ab statique \u00bb avec Satis ( https://github.com/composer/satis ) qui contient les packages g\u00e9n\u00e9r\u00e9s, et utiliser ce site web comme repository Composer. La fusion des diff\u00e9rentes extensions a eu lieu dans l\u2019issue 39. Pr\u00e9paration \u00e0 l\u2019utilisation du d\u00e9p\u00f4t Git comme repository Composer Le code, une fois unifi\u00e9, peut \u00eatre utilis\u00e9 assez simplement comme un package composer : il suffit d\u2019un fichier composer.json qui indique le vendor et le nom du package, mis \u00e0 la racine du code, comme par exemple : { \"name\" : \"uepal/fr.uepalparoisse.civiparoisse\" } Ensuite, les versions du code sont g\u00e9r\u00e9es avec des tags git qui prennent la forme du pr\u00e9fixe \u00ab v \u00bb auquel on accole le num\u00e9ro de version (on obtient par exemple v0.0.1, v0.0.2,\u2026). (Voir https://getcomposer.org/doc/articles/versions.md , https://getcomposer.org/doc/02-libraries.md et https://getcomposer.org/doc/05-repositories.md#vcs ). CiviCRM facilite la maintenance des extensions qui sont des packages Composer : en effet, CiviCRM inclut dans les lieux o\u00f9 il cherche les extensions le lieu \u00ab CMS_ROOT/vendor \u00bb, qui n\u2019est autre que le lieu o\u00f9 Composer met par d\u00e9faut les fichiers issus d\u2019un composer update. Il est \u00e0 noter que le plugin d\u2019installeur n\u2019a pas fonctionn\u00e9 avec la proc\u00e9dure d\u2019installation, car un r\u00e9pertoire ext situ\u00e9 \u00e0 la racine du projet n\u2019est pas scann\u00e9 par d\u00e9faut pour les extensions. Mise \u00e0 disposition du package On arrive ensuite \u00e0 la distribution du package, qui peut \u00eatre r\u00e9alis\u00e9e par deux approches compl\u00e9mentaires : distribuer le package via un d\u00e9p\u00f4t git, et \u00e9ventuellement distribuer le package via un site web. Mise \u00e0 disposition via d\u00e9p\u00f4t Git La mise \u00e0 disposition via d\u00e9p\u00f4t Git est plus ou moins obligatoire, dans la mesure o\u00f9 les g\u00e9n\u00e9rateurs de site web utiliseront le d\u00e9p\u00f4t Git comme source. Il convient de ne pas utiliser directement comme source le d\u00e9p\u00f4t de d\u00e9veloppement, car celui-ci contient l\u2019historique du travail, dont les messages de commit, ainsi que les emails des d\u00e9veloppeurs : ces \u00e9l\u00e9ments n\u2019ont pas besoin d\u2019\u00eatre vus par tous. On utilisera de ce fait un autre d\u00e9p\u00f4t Git (sur Github) que l\u2019on va utiliser uniquement pour publier les releases. La proc\u00e9dure de mise \u00e0 disposition va faire intervenir trois d\u00e9p\u00f4ts au total : le d\u00e9p\u00f4t de publication le d\u00e9p\u00f4t des sources un d\u00e9p\u00f4t local de travail La proc\u00e9dure est au bout du compte assez simple, on va travailler uniquement depuis le d\u00e9p\u00f4t local de travail: on cr\u00e9e le d\u00e9p\u00f4t de travail en clonant le d\u00e9p\u00f4t de publication (git clone) on ajoute une r\u00e9f\u00e9rence au d\u00e9p\u00f4t source au d\u00e9p\u00f4t de travail : depuis le d\u00e9p\u00f4t de travail : git remote add source <url ou chemin du d\u00e9p\u00f4t d\u2019origine> * depuis le d\u00e9p\u00f4t de travail, on r\u00e9cup\u00e8re le commit correspondant au tag, et qui sera mis dans FETCH_HEAD selon ce qu\u2019on voit dans la sortie de la commande : git fetch --depth 1 source tags/v2.0 on cr\u00e9e une branche en orphan (sans historique et sans commit) depuis FETCH_HEAD : git checkout --orphan release_v2 FETCH_HEAD on commite : attention \u00e0 l\u2019identit\u00e9 configur\u00e9e (nom et mail d\u2019utilisateur), et au message de commit : ces infos seront publi\u00e9es ensuite. git commit -m \"Release v2.0\" on taggue : git tag v2.0 release_v2 on pousse le tag vers le d\u00e9p\u00f4t de release (qui est origin depuis le clone) : git push origin tags/v2.0 On peut tester ensuite le fonctionnement : on cr\u00e9e un composer.json du genre : { \"repositories\" :[ { \"type\" : \"vcs\" , \"url\" : \"file:///home/ubuntu/DRUPAL_TEST/test3/release\" }], \"require\" :{ \"uepal/fr.uepalparoisse.civiparoisse\" : \"2.0\" } } Et ensuite, on peut utiliser composer pour lister les packages : ubuntu@wpcore:~/DRUPAL_TEST/test3/usage$ ./composer.phar show -a uepal/fr.uepalparoisse.civiparoisse Xdebug: [Step Debug] Could not connect to debugging client. Tried: 127.0.0.1:9003 (through xdebug.client_host/xdebug.client_port) :-( Warning from https://repo.packagist.org: Support for Composer 1 is deprecated and some packages will not be available. You should upgrade to Composer 2. See https://blog.packagist.com/deprecating-composer-1-support/ name : uepal/fr.uepalparoisse.civiparoisse descrip. : keywords : versions : v2.0 type : library homepage : source : [git] /home/ubuntu/DRUPAL_TEST/test3/release a85389ed3454e345d2bc67d4b0873f5d06e5dab8 dist : [] names : uepal/fr.uepalparoisse.civiparoisse On peut \u00e9galement installer le package pour tester. Si l\u2019on veut mettre le code \u00e0 la disposition de tous, on peut tr\u00e8s bien faire du d\u00e9p\u00f4t de release un d\u00e9p\u00f4t \u00ab public \u00bb. Mise \u00e0 disposition via site web La g\u00e9n\u00e9ration des packages \u00e0 mettre sur un site web pr\u00e9suppose de l\u2019utilisation d\u2019un syst\u00e8me de versionning (en l\u2019occurence, un d\u00e9p\u00f4t git) qui va \u00eatre interrog\u00e9 pour g\u00e9n\u00e9rer les packages de code qui vont \u00eatre mis \u00e0 disposition. Le plus propre est de connecter l\u2019outil sur le d\u00e9p\u00f4t de release g\u00e9n\u00e9r\u00e9 dans le point au-dessus, car il appara\u00eet que les sources sont r\u00e9f\u00e9renc\u00e9es dans les fichiers json g\u00e9n\u00e9r\u00e9s. Si les sources sont publiques, et donc mises \u00e0 la disposition de tous, alors on peut \u00e9ventuellement penser \u00e0 publier directement chez packagist.org, qui va s\u2019occuper lui-m\u00eame de parcourir p\u00e9riodiquement le d\u00e9p\u00f4t git de release et g\u00e9n\u00e9rer les packages (voir : https://packagist.org/about ). En revanche, il faut \u00e9ventuellement mettre en place une configuration de hook sur le d\u00e9p\u00f4t git pourque github avertisse packagist quand une modification est effectu\u00e9e, de sorte \u00e0 ne pas avoir besoin d\u2019attendre le d\u00e9lai de la semaine. Si on veut utiliser un d\u00e9p\u00f4t priv\u00e9, il faudra alors plut\u00f4t se tourner vers packagist.com ( https://packagist.com/ ), mais il y aura alors des co\u00fbts associ\u00e9s. Un autre type de solution est la g\u00e9n\u00e9ration du site web via Satis ( https://github.com/composer/satis ). Satis est configur\u00e9 via un ficher de configuration, qui est par d\u00e9faut satis.json . Un exemple de configuration est le suivant : { \"name\" : \"uepal/satis\" , \"homepage\" : \"http://satis.test\" , \"repositories\" :[ { \"type\" : \"vcs\" , \"url\" : \"/home/ubuntu/DRUPAL_TEST/test3/release\" } ], \"require-all\" : true , \"archive\" :{ \"directory\" : \"dist\" , \"format\" : \"tar\" , \"checksum\" : true , \"skip-dev\" : true }, \"output-dir\" : \"TEST_RELEASE\" , \"output-html\" : true , \"providers\" : true , \"pretty-print\" : true } Les param\u00e8tres variants sont la homepage, qui sera l\u2019URL de publication finale du contenu, les repositories qui seront analys\u00e9s pour g\u00e9n\u00e9rer les packages, et l\u2019output-dir, qui est le r\u00e9pertoire de destination. Un simple appel de satis avec le param\u00e8tre build permettra ensuite de g\u00e9n\u00e9rer le site. La documentation de satis est assez compl\u00e8te (dont https://github.com/composer/satis/blob/main/docs/using.md et https://github.com/composer/satis/blob/main/docs/config.md ), et compl\u00e8te \u00e9galement celle de Composer pour les d\u00e9p\u00f4ts priv\u00e9s ( https://getcomposer.org/doc/articles/handling-private-packages.md ). Comme il s\u2019agira d\u2019un site web \u00ab ind\u00e9pendant \u00bb dans une certaine mesure, on pourra mettre en \u0153uvre des \u00e9l\u00e9ments comme l\u2019authentification des clients. La g\u00e9n\u00e9ration peut par exemple donner des fichiers comme : ubuntu@wpcore:~/DRUPAL_COMPOSER2/TOOLS/satis/TEST$ ls -lR .: total 156 drwxrwxr-x 3 ubuntu ubuntu 4096 nov. 13 16 :14 dist -rw-rw-r-- 1 ubuntu ubuntu 140235 nov. 13 16 :14 index.html drwxrwxr-x 3 ubuntu ubuntu 4096 nov. 13 16 :14 p drwxrwxr-x 3 ubuntu ubuntu 4096 nov. 13 16 :14 p2 -rw-rw-r-- 1 ubuntu ubuntu 369 nov. 13 16 :14 packages.json ./dist: total 4 drwxrwxr-x 3 ubuntu ubuntu 4096 nov.13 16 :14 uepal ./dist/uepal: total 4 drwxrwxr-x 2 ubuntu ubuntu 4096 nov.13 16 :14 fr-uepalparoisse-civiparoisse./dist/uepal/fr-uepalparoisse-civiparoisse: total 1128 -rw-rw-r-- 1 ubuntu ubuntu 382464 nov. 13 16 :14 uepal-fr-uepalparoisse-civiparoisse-v0.0.1-66a904.tar -rw-rw-r-- 1 ubuntu ubuntu 382464 nov. 13 16 :14 uepal-fr-uepalparoisse-civiparoisse-v0.0.2-ff0663.tar -rw-rw-r-- 1 ubuntu ubuntu 382464 nov. 13 16 :14 uepal-fr-uepalparoisse-civiparoisse-v0.0.3-283727.tar ./p: total 4 drwxrwxr-x 2 ubuntu ubuntu 4096 nov.13 16 :14 uepal ./p/uepal: total 4 -rw-rw-r-- 1 ubuntu ubuntu 3889 nov. 13 16 :14 'fr.uepalparoisse.civiparoisse$1060f03e1bdec900db4bd55eb8eb8bb1ad05795428765663e44247de1f6d7ecd.json' ./p2: total 4 drwxrwxr-x 2 ubuntu ubuntu 4096 nov. 13 16 :14 uepal ./p2/uepal: total 8 -rw-rw-r-- 1 ubuntu ubuntu 744 nov. 13 16 :14 fr.uepalparoisse.civiparoisse~dev.json -rw-rw-r-- 1 ubuntu ubuntu 3167 nov. 13 16 :14 fr.uepalparoisse.civiparoisse.json La consommation du package se fait ensuite en sp\u00e9cifiant dans le composer.json du projet d\u2019installation \u00e0 la fois le d\u00e9p\u00f4t priv\u00e9 et le package requis, comme par exemple pour l\u2019exp\u00e9rimentation : { \"repositories\" :[{ \"type\" : \"composer\" , \"url\" : \"http://satis.test\" }], \"extra\" :{ \"enable-patching\" : true , \"compile-whitelist\" : [ \"civicrm/civicrm-core\" , \"civicrm/composer-compile-lib\" ] }, \"require\" :{ \"drupal/recommended-project\" : \">=9.2\" , \"drush/drush\" : \">=10\" , \"drupal/console\" : \">=1\" , \"civicrm/civicrm-core\" : \">=5.38\" , \"civicrm/civicrm-packages\" : \">=5.38\" , \"civicrm/civicrm-drupal-8\" : \">=5.38\" , \"civicrm/civicrm-asset-plugin\" : \">=1.1\" , \"civicrm/composer-downloads-plugin\" : \">=3\" , \"uepal/fr.uepalparoisse.civiparoisse\" : \"0.0.3\" }, \"minimum-stability\" : \"dev\" , \"prefer-stable\" : true , \"config\" :{ \"secure-http\" : false } } Le secure-http \u00e0 FALSE a \u00e9t\u00e9 utilis\u00e9 pour ne pas avoir besoin de faire une configuration fastidieuse du SSL dans l\u2019exp\u00e9rimentation, \u00e9tant donn\u00e9 que dans le cadre d\u2019une mise en production on utiliserait probablement des certificats reconnus sans avoir besoin de r\u00e9glages sp\u00e9cifiques. Apr\u00e8s utilisation du composer update, on retrouve ensuite dans le r\u00e9pertoire vendor/uepal/fr.uepalparoisse.civiparoisse l\u2019ensemble de l\u2019extension. On comprend donc que chaque m\u00e9thode a des avantages et des inconv\u00e9nients, mais on peut globalement supposer que l\u2019utilisation du d\u00e9p\u00f4t git uniquement convient pour un petit nombre d\u2019instances, tandis que l\u2019utilisation d\u2019un site web fournira des facilit\u00e9s d\u2019installation pour des instances plus nombreuses, dans la mesure o\u00f9 le site web pourra disposer de fonctionnalit\u00e9s suppl\u00e9mentaires (par exemple un proxy cache qui pourra \u00eatre utile pour \u00e9conomiser du trafic r\u00e9seau pour la r\u00e9cup\u00e9ration des packages Composer, sans compter une s\u00e9paration plus nette entre les outils de d\u00e9veloppements et les outils de production).","title":"Distribution de code"},{"location":"TECHNIQUE/LOGICIEL/distribution_code_composer.html#distribution-du-code-de-civiparoisse","text":"La distribution du code de Civiparoisse est un point crucial de l\u2019industrialisation de l\u2019installation des instances CiviCRM. On a d\u00e9j\u00e0 vu que Composer procurait une facilit\u00e9 d\u2019installation et de mise \u00e0 jour des instances de Drupal et du coeur de CiviCRM. Il est donc int\u00e9ressant de capitaliser sur Composer. Pour ce faire, il \u00e9tait tout d\u2019abord n\u00e9cessaire d\u2019unifier les modules civiparoisse existants en un seul, de le pr\u00e9parer pour devenir un package, puis g\u00e9n\u00e9rer les packages, et enfin les utiliser.","title":"Distribution du code de Civiparoisse"},{"location":"TECHNIQUE/LOGICIEL/distribution_code_composer.html#unification-des-extensions-civiparoisse","text":"L\u2019unification des extensions Civiparoisse s\u2019est impos\u00e9e pour plusieurs raisons : les diff\u00e9rentes extensions avaient fonctionnellement le m\u00eame but : fournir la gestion op\u00e9rationnelle des paroisses, et d\u00e9pendaient les unes des autres pour fournir la fonctionnalit\u00e9 globale : ces \u00e9ventuelles interd\u00e9pendances auraient pu devenir probl\u00e9matique pour la maintenance des extensions, d\u2019aunt plus que certains \u00e9l\u00e9ments n\u00e9cessitent des \u00ab racines \u00bb (par exemple : cr\u00e9ation d\u2019un menu \u00ab racine \u00bb Uepal) diff\u00e9rentes extensions peuvent conduire \u00e0 de la duplication de code : en effet, certains m\u00e9canismes comme la gestion des menus, les settings, auraient pu \u00eatre requis dans le temps par plusieurs modules la gestion de versions est facilit\u00e9e : une seule version \u00e9tait d\u00e9j\u00e0 pr\u00e9vue pour tout le code via les tags git : on pourra donc aligner la version de info.xml et les tags les s\u00e9parations qui semblaient n\u00e9cessaires restent pr\u00e9sentes, mais sont int\u00e9gr\u00e9es dans des niveaux plus profonds : on retrouve diff\u00e9rents \u00ab namespaces \u00bb, comme CRM_Civiparoisse_Parametres,CRM_Civiparoisse_Pages\u2026 Il en est de m\u00eame pour les templates associ\u00e9s Composer peut utiliser un d\u00e9p\u00f4t git comme un repository qui contient un package versionn\u00e9 avec les tags ; si on ne souhaite pas utiliser directement le d\u00e9p\u00f4t git, il est \u00e9galement possible de g\u00e9n\u00e9rer un site web \u00ab statique \u00bb avec Satis ( https://github.com/composer/satis ) qui contient les packages g\u00e9n\u00e9r\u00e9s, et utiliser ce site web comme repository Composer. La fusion des diff\u00e9rentes extensions a eu lieu dans l\u2019issue 39.","title":"Unification des extensions Civiparoisse"},{"location":"TECHNIQUE/LOGICIEL/distribution_code_composer.html#preparation-a-lutilisation-du-depot-git-comme-repository-composer","text":"Le code, une fois unifi\u00e9, peut \u00eatre utilis\u00e9 assez simplement comme un package composer : il suffit d\u2019un fichier composer.json qui indique le vendor et le nom du package, mis \u00e0 la racine du code, comme par exemple : { \"name\" : \"uepal/fr.uepalparoisse.civiparoisse\" } Ensuite, les versions du code sont g\u00e9r\u00e9es avec des tags git qui prennent la forme du pr\u00e9fixe \u00ab v \u00bb auquel on accole le num\u00e9ro de version (on obtient par exemple v0.0.1, v0.0.2,\u2026). (Voir https://getcomposer.org/doc/articles/versions.md , https://getcomposer.org/doc/02-libraries.md et https://getcomposer.org/doc/05-repositories.md#vcs ). CiviCRM facilite la maintenance des extensions qui sont des packages Composer : en effet, CiviCRM inclut dans les lieux o\u00f9 il cherche les extensions le lieu \u00ab CMS_ROOT/vendor \u00bb, qui n\u2019est autre que le lieu o\u00f9 Composer met par d\u00e9faut les fichiers issus d\u2019un composer update. Il est \u00e0 noter que le plugin d\u2019installeur n\u2019a pas fonctionn\u00e9 avec la proc\u00e9dure d\u2019installation, car un r\u00e9pertoire ext situ\u00e9 \u00e0 la racine du projet n\u2019est pas scann\u00e9 par d\u00e9faut pour les extensions.","title":"Pr\u00e9paration \u00e0 l\u2019utilisation du d\u00e9p\u00f4t Git comme repository Composer"},{"location":"TECHNIQUE/LOGICIEL/distribution_code_composer.html#mise-a-disposition-du-package","text":"On arrive ensuite \u00e0 la distribution du package, qui peut \u00eatre r\u00e9alis\u00e9e par deux approches compl\u00e9mentaires : distribuer le package via un d\u00e9p\u00f4t git, et \u00e9ventuellement distribuer le package via un site web.","title":"Mise \u00e0 disposition du package"},{"location":"TECHNIQUE/LOGICIEL/distribution_code_composer.html#mise-a-disposition-via-depot-git","text":"La mise \u00e0 disposition via d\u00e9p\u00f4t Git est plus ou moins obligatoire, dans la mesure o\u00f9 les g\u00e9n\u00e9rateurs de site web utiliseront le d\u00e9p\u00f4t Git comme source. Il convient de ne pas utiliser directement comme source le d\u00e9p\u00f4t de d\u00e9veloppement, car celui-ci contient l\u2019historique du travail, dont les messages de commit, ainsi que les emails des d\u00e9veloppeurs : ces \u00e9l\u00e9ments n\u2019ont pas besoin d\u2019\u00eatre vus par tous. On utilisera de ce fait un autre d\u00e9p\u00f4t Git (sur Github) que l\u2019on va utiliser uniquement pour publier les releases. La proc\u00e9dure de mise \u00e0 disposition va faire intervenir trois d\u00e9p\u00f4ts au total : le d\u00e9p\u00f4t de publication le d\u00e9p\u00f4t des sources un d\u00e9p\u00f4t local de travail La proc\u00e9dure est au bout du compte assez simple, on va travailler uniquement depuis le d\u00e9p\u00f4t local de travail: on cr\u00e9e le d\u00e9p\u00f4t de travail en clonant le d\u00e9p\u00f4t de publication (git clone) on ajoute une r\u00e9f\u00e9rence au d\u00e9p\u00f4t source au d\u00e9p\u00f4t de travail : depuis le d\u00e9p\u00f4t de travail : git remote add source <url ou chemin du d\u00e9p\u00f4t d\u2019origine> * depuis le d\u00e9p\u00f4t de travail, on r\u00e9cup\u00e8re le commit correspondant au tag, et qui sera mis dans FETCH_HEAD selon ce qu\u2019on voit dans la sortie de la commande : git fetch --depth 1 source tags/v2.0 on cr\u00e9e une branche en orphan (sans historique et sans commit) depuis FETCH_HEAD : git checkout --orphan release_v2 FETCH_HEAD on commite : attention \u00e0 l\u2019identit\u00e9 configur\u00e9e (nom et mail d\u2019utilisateur), et au message de commit : ces infos seront publi\u00e9es ensuite. git commit -m \"Release v2.0\" on taggue : git tag v2.0 release_v2 on pousse le tag vers le d\u00e9p\u00f4t de release (qui est origin depuis le clone) : git push origin tags/v2.0 On peut tester ensuite le fonctionnement : on cr\u00e9e un composer.json du genre : { \"repositories\" :[ { \"type\" : \"vcs\" , \"url\" : \"file:///home/ubuntu/DRUPAL_TEST/test3/release\" }], \"require\" :{ \"uepal/fr.uepalparoisse.civiparoisse\" : \"2.0\" } } Et ensuite, on peut utiliser composer pour lister les packages : ubuntu@wpcore:~/DRUPAL_TEST/test3/usage$ ./composer.phar show -a uepal/fr.uepalparoisse.civiparoisse Xdebug: [Step Debug] Could not connect to debugging client. Tried: 127.0.0.1:9003 (through xdebug.client_host/xdebug.client_port) :-( Warning from https://repo.packagist.org: Support for Composer 1 is deprecated and some packages will not be available. You should upgrade to Composer 2. See https://blog.packagist.com/deprecating-composer-1-support/ name : uepal/fr.uepalparoisse.civiparoisse descrip. : keywords : versions : v2.0 type : library homepage : source : [git] /home/ubuntu/DRUPAL_TEST/test3/release a85389ed3454e345d2bc67d4b0873f5d06e5dab8 dist : [] names : uepal/fr.uepalparoisse.civiparoisse On peut \u00e9galement installer le package pour tester. Si l\u2019on veut mettre le code \u00e0 la disposition de tous, on peut tr\u00e8s bien faire du d\u00e9p\u00f4t de release un d\u00e9p\u00f4t \u00ab public \u00bb.","title":"Mise \u00e0 disposition via d\u00e9p\u00f4t Git"},{"location":"TECHNIQUE/LOGICIEL/distribution_code_composer.html#mise-a-disposition-via-site-web","text":"La g\u00e9n\u00e9ration des packages \u00e0 mettre sur un site web pr\u00e9suppose de l\u2019utilisation d\u2019un syst\u00e8me de versionning (en l\u2019occurence, un d\u00e9p\u00f4t git) qui va \u00eatre interrog\u00e9 pour g\u00e9n\u00e9rer les packages de code qui vont \u00eatre mis \u00e0 disposition. Le plus propre est de connecter l\u2019outil sur le d\u00e9p\u00f4t de release g\u00e9n\u00e9r\u00e9 dans le point au-dessus, car il appara\u00eet que les sources sont r\u00e9f\u00e9renc\u00e9es dans les fichiers json g\u00e9n\u00e9r\u00e9s. Si les sources sont publiques, et donc mises \u00e0 la disposition de tous, alors on peut \u00e9ventuellement penser \u00e0 publier directement chez packagist.org, qui va s\u2019occuper lui-m\u00eame de parcourir p\u00e9riodiquement le d\u00e9p\u00f4t git de release et g\u00e9n\u00e9rer les packages (voir : https://packagist.org/about ). En revanche, il faut \u00e9ventuellement mettre en place une configuration de hook sur le d\u00e9p\u00f4t git pourque github avertisse packagist quand une modification est effectu\u00e9e, de sorte \u00e0 ne pas avoir besoin d\u2019attendre le d\u00e9lai de la semaine. Si on veut utiliser un d\u00e9p\u00f4t priv\u00e9, il faudra alors plut\u00f4t se tourner vers packagist.com ( https://packagist.com/ ), mais il y aura alors des co\u00fbts associ\u00e9s. Un autre type de solution est la g\u00e9n\u00e9ration du site web via Satis ( https://github.com/composer/satis ). Satis est configur\u00e9 via un ficher de configuration, qui est par d\u00e9faut satis.json . Un exemple de configuration est le suivant : { \"name\" : \"uepal/satis\" , \"homepage\" : \"http://satis.test\" , \"repositories\" :[ { \"type\" : \"vcs\" , \"url\" : \"/home/ubuntu/DRUPAL_TEST/test3/release\" } ], \"require-all\" : true , \"archive\" :{ \"directory\" : \"dist\" , \"format\" : \"tar\" , \"checksum\" : true , \"skip-dev\" : true }, \"output-dir\" : \"TEST_RELEASE\" , \"output-html\" : true , \"providers\" : true , \"pretty-print\" : true } Les param\u00e8tres variants sont la homepage, qui sera l\u2019URL de publication finale du contenu, les repositories qui seront analys\u00e9s pour g\u00e9n\u00e9rer les packages, et l\u2019output-dir, qui est le r\u00e9pertoire de destination. Un simple appel de satis avec le param\u00e8tre build permettra ensuite de g\u00e9n\u00e9rer le site. La documentation de satis est assez compl\u00e8te (dont https://github.com/composer/satis/blob/main/docs/using.md et https://github.com/composer/satis/blob/main/docs/config.md ), et compl\u00e8te \u00e9galement celle de Composer pour les d\u00e9p\u00f4ts priv\u00e9s ( https://getcomposer.org/doc/articles/handling-private-packages.md ). Comme il s\u2019agira d\u2019un site web \u00ab ind\u00e9pendant \u00bb dans une certaine mesure, on pourra mettre en \u0153uvre des \u00e9l\u00e9ments comme l\u2019authentification des clients. La g\u00e9n\u00e9ration peut par exemple donner des fichiers comme : ubuntu@wpcore:~/DRUPAL_COMPOSER2/TOOLS/satis/TEST$ ls -lR .: total 156 drwxrwxr-x 3 ubuntu ubuntu 4096 nov. 13 16 :14 dist -rw-rw-r-- 1 ubuntu ubuntu 140235 nov. 13 16 :14 index.html drwxrwxr-x 3 ubuntu ubuntu 4096 nov. 13 16 :14 p drwxrwxr-x 3 ubuntu ubuntu 4096 nov. 13 16 :14 p2 -rw-rw-r-- 1 ubuntu ubuntu 369 nov. 13 16 :14 packages.json ./dist: total 4 drwxrwxr-x 3 ubuntu ubuntu 4096 nov.13 16 :14 uepal ./dist/uepal: total 4 drwxrwxr-x 2 ubuntu ubuntu 4096 nov.13 16 :14 fr-uepalparoisse-civiparoisse./dist/uepal/fr-uepalparoisse-civiparoisse: total 1128 -rw-rw-r-- 1 ubuntu ubuntu 382464 nov. 13 16 :14 uepal-fr-uepalparoisse-civiparoisse-v0.0.1-66a904.tar -rw-rw-r-- 1 ubuntu ubuntu 382464 nov. 13 16 :14 uepal-fr-uepalparoisse-civiparoisse-v0.0.2-ff0663.tar -rw-rw-r-- 1 ubuntu ubuntu 382464 nov. 13 16 :14 uepal-fr-uepalparoisse-civiparoisse-v0.0.3-283727.tar ./p: total 4 drwxrwxr-x 2 ubuntu ubuntu 4096 nov.13 16 :14 uepal ./p/uepal: total 4 -rw-rw-r-- 1 ubuntu ubuntu 3889 nov. 13 16 :14 'fr.uepalparoisse.civiparoisse$1060f03e1bdec900db4bd55eb8eb8bb1ad05795428765663e44247de1f6d7ecd.json' ./p2: total 4 drwxrwxr-x 2 ubuntu ubuntu 4096 nov. 13 16 :14 uepal ./p2/uepal: total 8 -rw-rw-r-- 1 ubuntu ubuntu 744 nov. 13 16 :14 fr.uepalparoisse.civiparoisse~dev.json -rw-rw-r-- 1 ubuntu ubuntu 3167 nov. 13 16 :14 fr.uepalparoisse.civiparoisse.json La consommation du package se fait ensuite en sp\u00e9cifiant dans le composer.json du projet d\u2019installation \u00e0 la fois le d\u00e9p\u00f4t priv\u00e9 et le package requis, comme par exemple pour l\u2019exp\u00e9rimentation : { \"repositories\" :[{ \"type\" : \"composer\" , \"url\" : \"http://satis.test\" }], \"extra\" :{ \"enable-patching\" : true , \"compile-whitelist\" : [ \"civicrm/civicrm-core\" , \"civicrm/composer-compile-lib\" ] }, \"require\" :{ \"drupal/recommended-project\" : \">=9.2\" , \"drush/drush\" : \">=10\" , \"drupal/console\" : \">=1\" , \"civicrm/civicrm-core\" : \">=5.38\" , \"civicrm/civicrm-packages\" : \">=5.38\" , \"civicrm/civicrm-drupal-8\" : \">=5.38\" , \"civicrm/civicrm-asset-plugin\" : \">=1.1\" , \"civicrm/composer-downloads-plugin\" : \">=3\" , \"uepal/fr.uepalparoisse.civiparoisse\" : \"0.0.3\" }, \"minimum-stability\" : \"dev\" , \"prefer-stable\" : true , \"config\" :{ \"secure-http\" : false } } Le secure-http \u00e0 FALSE a \u00e9t\u00e9 utilis\u00e9 pour ne pas avoir besoin de faire une configuration fastidieuse du SSL dans l\u2019exp\u00e9rimentation, \u00e9tant donn\u00e9 que dans le cadre d\u2019une mise en production on utiliserait probablement des certificats reconnus sans avoir besoin de r\u00e9glages sp\u00e9cifiques. Apr\u00e8s utilisation du composer update, on retrouve ensuite dans le r\u00e9pertoire vendor/uepal/fr.uepalparoisse.civiparoisse l\u2019ensemble de l\u2019extension. On comprend donc que chaque m\u00e9thode a des avantages et des inconv\u00e9nients, mais on peut globalement supposer que l\u2019utilisation du d\u00e9p\u00f4t git uniquement convient pour un petit nombre d\u2019instances, tandis que l\u2019utilisation d\u2019un site web fournira des facilit\u00e9s d\u2019installation pour des instances plus nombreuses, dans la mesure o\u00f9 le site web pourra disposer de fonctionnalit\u00e9s suppl\u00e9mentaires (par exemple un proxy cache qui pourra \u00eatre utile pour \u00e9conomiser du trafic r\u00e9seau pour la r\u00e9cup\u00e9ration des packages Composer, sans compter une s\u00e9paration plus nette entre les outils de d\u00e9veloppements et les outils de production).","title":"Mise \u00e0 disposition via site web"},{"location":"TECHNIQUE/LOGICIEL/environnement_dev.html","text":"Environnement de d\u00e9veloppement Principe de fonctionnement L'id\u00e9e de l'environnement de d\u00e9veloppement est de fournir des outils rapides et efficaces pour faire les travaux de d\u00e9veloppement, sans s'encombrer d'une infrastructure compl\u00e8te. Cette structure est pr\u00e9vue pour des travaux sur des fonctionnalit\u00e9s internes \u00e0 Civiparoisse, mais n'est pas suffisante s'il y a besoin de tester des \u00e9l\u00e9ments plus importants qui mettent en jeu l'infrastructure (ex : envoi / r\u00e9ception de mail). Dans le d\u00e9pot des Dockerfiles, il y a non seulement le n\u00e9cessaire pour constituer les images, mais \u00e9galement trois docker-compose : docker-init.yml : contient un container d'initialisation docker-compose.yml : contient une stack minimale, avec la DB, l'authenticateur, et le proxy et le serveur web docker-compose-bind.yml : contient la m\u00eame stack, mais avec une variable d'environnement pour faire un montage en bind du r\u00e9pertoire /app L'id\u00e9e est la suivante : initialiser un environnement pour avoir une installation propre r\u00e9cup\u00e9rer en local l'ensemble des fichiers de l'environnement remplacer les emplacements qui contiennent le code sp\u00e9cifique de civiparoisse par des clones git utiliser la copie pour la faire tourner dans Docker R\u00e9solution de noms Le nom utilis\u00e9 dans les images est civicrm.test . Il y a lieu d'\u00e9crire une entr\u00e9e dans /etc/hosts pour r\u00e9soudre ce nom vers 127.0.0.1 . Initialisation du r\u00e9pertoire de destination #!/bin/bash echo \"export CIVIPAROISSEDEV=~/devciviparoisse\" >>~/.bashrc source ~/.bashrc mkdir -p ${ CIVIPAROISSEDEV } On d\u00e9finit la variable CIVIPAROISSEDEV dans le bashrc de sorte que la variable soit disponible, et charg\u00e9e via le shell (bash). R\u00e9cup\u00e9ration des Dockerfiles Les dockerfiles se trouvent dans un d\u00e9p\u00f4t sp\u00e9cifique : git@github.com:UEPAL-CiviParoisse/Dockerfiles.git Il faut compiler les images du Dockerfile (pour l'instant, branche ENV_DEV ), via le build.sh pr\u00e9sent dans le d\u00e9p\u00f4t. La compilation des images prend un certain temps (et un temps certain). Initialisation d'une installation docker-compose -f docker-init.yml up docker-compose -f docker-init.yml down --remove-orphans Ceci initialise surtout les volumes dont on aura besoin R\u00e9cup\u00e9ration des donn\u00e9es en local On lance l'environnement : docker-compose -f docker-compose.yml up -d Le but est d'avoir le conteneur du serveur web lanc\u00e9. On utilise docker container ls pour voir la liste des conteneurs lanc\u00e9s. Le nom du conteneur d\u00e9pendra du r\u00e9pertoire contenant le clone du d\u00e9p\u00f4t des dockerfiles. docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7d607761b474 uepal_test/proxy \"apache2-foreground\" About a minute ago Up About a minute 80 /tcp, 127 .0.0.1:443->443/tcp git_dockerfiles_civiproxy_1 00d5bf0ad884 uepal_test/authenticator \"/exec/exec.sh\" About a minute ago Up About a minute git_dockerfiles_civiauthenticator_1 d960762f63b0 uepal_test/httpd \"apache2-foreground\" About a minute ago Up About a minute 80 /tcp, 444 /tcp git_dockerfiles_civihttpd_1 898dca63e562 ubuntu/mysql \"docker-entrypoint.s\u2026\" About a minute ago Up About a minute 3306 /tcp, 33060 /tcp git_dockerfiles_cividb_1 22b88b8c9cde uepal_test/mkdocs-material \"mkdocs serve --dev-\u2026\" 2 hours ago Up 2 hours 127 .0.0.1:8000->8000/tcp mkdocs_material Ici, le nom du conteneur est : git_dockerfiles_civihttpd_1 . On va r\u00e9cup\u00e9rer l'ensemble du r\u00e9pertoire /app en local, et on va utiliser des r\u00e8gles ACL pour positionner des droits pour l'utilisateur courant (et ainsi, on aura moins besoin de jongler entre les droits dans le conteneur et l'environnement de travail). La copie cr\u00e9ant de nouveaux fichiers, et comme on va binder les volumes, il faut \u00e9galement positionner les droits sur les fichiers du bind. Dans le conteneur courant, www-data est un utilisateur dont l'UID est 33 (pour le moment, mais \u00e7a peut changer en fonction de la vie des images); d'o\u00f9 la mise en place des droits pour l'utilisateur 33. sudo docker cp git_dockerfiles_civihttpd_1:/app/ ${ CIVIPAROISSEDEV } sudo setfacl -R -m u: $( whoami ) :rwx ${ CIVIPAROISSEDEV } sudo setfacl -R -m u:33:rxw ${ CIVIPAROISSEDEV } On arr\u00eate les conteneurs : docker-compose -f docker-compose.yml down Branchement des d\u00e9p\u00f4ts gits Les d\u00e9p\u00f4ts gits viendront remplacer les fichiers de l'image, via de l'effacement puis des clones. D\u00e9p\u00f4t Description Chemin git@github.com:UEPAL-CiviParoisse/Extensions_CiviCRM.git Fichiers extension civiparoisse ${CIVIPAROISSEDEV}/app/vendor/uepal/fr.uepalparoisse.civiparoisse git@github.com:UEPAL-CiviParoisse/CIVIP_INSTALL.git Setup civicrm-civiparoisse ${CIVIPAROISSEDEV}/app/vendor/uepal/civisetup git@github.com:UEPAL-CiviParoisse/Modules_Drupal.git Module drupal civiparoisse ${CIVIPAROISSEDEV}/app/web/modules/contrib/fr.uepalparoisse.druparoisse Lorsqu'on branche les d\u00e9p\u00f4ts gits, on va certainement faire : un mv ou rm des fichiers pr\u00e9sents en local dans les r\u00e9pertoires cibles, des git clone pour remplacer les fichiers des git checkout pour se positionner dans les bonnes branches des setfacl pour positionner les droits pour le serveur web Lorsqu'on change les branches, il faudra penser \u00e0 vider les caches (par exemple via les interfaces d'administration). Lancement de l'environnement pour dev L'environnement pour le d\u00e9veloppement est un peu particulier, dans la mesure o\u00f9 l'on va utiliser un conteneur httpd modifi\u00e9 pour inclure Xdebug, ainsi qu'un montage bind des fichiers locaux. De m\u00eame, le r\u00e9seau utilis\u00e9 est un seul r\u00e9seau (en raison de probl\u00e8mes de mise au point sur les scopes). Pour le lancer : docker-compose -f docker-compose-bind.yml up -d Pour arr\u00eater : docker-compose -f docker-compose-bind.yml down Mots de passe par d\u00e9faut Les mots de passe sont pr\u00e9sents dans les secrets li\u00e9s \u00e0 l'image init . Configuration xdebug pour vscode : launch.json On ouvre le dossier ${CIVIPAROISSEDEV}/app dans vscode. Vscode propose une extension pour xdebug : identificateur : xdebug.php-debug . Cette extension utilise un fichier launch.json pour configurer une instance de xdebug. Il convient de faire attention d'\u00e9couter sur toutes les IP et sur le bon port (9003), ainsi que de configurer le pathMapping, pour la correspondance des fichiers sources. { // Utilisez IntelliSense pour en savoir plus sur les attributs possibles. // Pointez pour afficher la description des attributs existants. // Pour plus d'informations, visitez : https://go.microsoft.com/fwlink/?linkid=830387 \"version\" : \"0.2.0\" , \"configurations\" : [ { \"name\" : \"Listen for Xdebug\" , \"type\" : \"php\" , \"request\" : \"launch\" , \"port\" : 9003 , \"hostname\" : \"::\" , \"pathMappings\" : { \"/app\" : \"${workspaceFolder}\" } } ] } Une fois que cela est fait, il suffit donc de positionner les points d'arr\u00eats et de lancer le d\u00e9bugger. A noter que xdebug, tel que configur\u00e9, est pr\u00e9vu pour envoyer des requ\u00eates dans tous les cas \u00e0 l'IDE.","title":"Environnement de dev"},{"location":"TECHNIQUE/LOGICIEL/environnement_dev.html#environnement-de-developpement","text":"","title":"Environnement de d\u00e9veloppement"},{"location":"TECHNIQUE/LOGICIEL/environnement_dev.html#principe-de-fonctionnement","text":"L'id\u00e9e de l'environnement de d\u00e9veloppement est de fournir des outils rapides et efficaces pour faire les travaux de d\u00e9veloppement, sans s'encombrer d'une infrastructure compl\u00e8te. Cette structure est pr\u00e9vue pour des travaux sur des fonctionnalit\u00e9s internes \u00e0 Civiparoisse, mais n'est pas suffisante s'il y a besoin de tester des \u00e9l\u00e9ments plus importants qui mettent en jeu l'infrastructure (ex : envoi / r\u00e9ception de mail). Dans le d\u00e9pot des Dockerfiles, il y a non seulement le n\u00e9cessaire pour constituer les images, mais \u00e9galement trois docker-compose : docker-init.yml : contient un container d'initialisation docker-compose.yml : contient une stack minimale, avec la DB, l'authenticateur, et le proxy et le serveur web docker-compose-bind.yml : contient la m\u00eame stack, mais avec une variable d'environnement pour faire un montage en bind du r\u00e9pertoire /app L'id\u00e9e est la suivante : initialiser un environnement pour avoir une installation propre r\u00e9cup\u00e9rer en local l'ensemble des fichiers de l'environnement remplacer les emplacements qui contiennent le code sp\u00e9cifique de civiparoisse par des clones git utiliser la copie pour la faire tourner dans Docker","title":"Principe de fonctionnement"},{"location":"TECHNIQUE/LOGICIEL/environnement_dev.html#resolution-de-noms","text":"Le nom utilis\u00e9 dans les images est civicrm.test . Il y a lieu d'\u00e9crire une entr\u00e9e dans /etc/hosts pour r\u00e9soudre ce nom vers 127.0.0.1 .","title":"R\u00e9solution de noms"},{"location":"TECHNIQUE/LOGICIEL/environnement_dev.html#initialisation-du-repertoire-de-destination","text":"#!/bin/bash echo \"export CIVIPAROISSEDEV=~/devciviparoisse\" >>~/.bashrc source ~/.bashrc mkdir -p ${ CIVIPAROISSEDEV } On d\u00e9finit la variable CIVIPAROISSEDEV dans le bashrc de sorte que la variable soit disponible, et charg\u00e9e via le shell (bash).","title":"Initialisation du r\u00e9pertoire de destination"},{"location":"TECHNIQUE/LOGICIEL/environnement_dev.html#recuperation-des-dockerfiles","text":"Les dockerfiles se trouvent dans un d\u00e9p\u00f4t sp\u00e9cifique : git@github.com:UEPAL-CiviParoisse/Dockerfiles.git Il faut compiler les images du Dockerfile (pour l'instant, branche ENV_DEV ), via le build.sh pr\u00e9sent dans le d\u00e9p\u00f4t. La compilation des images prend un certain temps (et un temps certain).","title":"R\u00e9cup\u00e9ration des Dockerfiles"},{"location":"TECHNIQUE/LOGICIEL/environnement_dev.html#initialisation-dune-installation","text":"docker-compose -f docker-init.yml up docker-compose -f docker-init.yml down --remove-orphans Ceci initialise surtout les volumes dont on aura besoin","title":"Initialisation d'une installation"},{"location":"TECHNIQUE/LOGICIEL/environnement_dev.html#recuperation-des-donnees-en-local","text":"On lance l'environnement : docker-compose -f docker-compose.yml up -d Le but est d'avoir le conteneur du serveur web lanc\u00e9. On utilise docker container ls pour voir la liste des conteneurs lanc\u00e9s. Le nom du conteneur d\u00e9pendra du r\u00e9pertoire contenant le clone du d\u00e9p\u00f4t des dockerfiles. docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7d607761b474 uepal_test/proxy \"apache2-foreground\" About a minute ago Up About a minute 80 /tcp, 127 .0.0.1:443->443/tcp git_dockerfiles_civiproxy_1 00d5bf0ad884 uepal_test/authenticator \"/exec/exec.sh\" About a minute ago Up About a minute git_dockerfiles_civiauthenticator_1 d960762f63b0 uepal_test/httpd \"apache2-foreground\" About a minute ago Up About a minute 80 /tcp, 444 /tcp git_dockerfiles_civihttpd_1 898dca63e562 ubuntu/mysql \"docker-entrypoint.s\u2026\" About a minute ago Up About a minute 3306 /tcp, 33060 /tcp git_dockerfiles_cividb_1 22b88b8c9cde uepal_test/mkdocs-material \"mkdocs serve --dev-\u2026\" 2 hours ago Up 2 hours 127 .0.0.1:8000->8000/tcp mkdocs_material Ici, le nom du conteneur est : git_dockerfiles_civihttpd_1 . On va r\u00e9cup\u00e9rer l'ensemble du r\u00e9pertoire /app en local, et on va utiliser des r\u00e8gles ACL pour positionner des droits pour l'utilisateur courant (et ainsi, on aura moins besoin de jongler entre les droits dans le conteneur et l'environnement de travail). La copie cr\u00e9ant de nouveaux fichiers, et comme on va binder les volumes, il faut \u00e9galement positionner les droits sur les fichiers du bind. Dans le conteneur courant, www-data est un utilisateur dont l'UID est 33 (pour le moment, mais \u00e7a peut changer en fonction de la vie des images); d'o\u00f9 la mise en place des droits pour l'utilisateur 33. sudo docker cp git_dockerfiles_civihttpd_1:/app/ ${ CIVIPAROISSEDEV } sudo setfacl -R -m u: $( whoami ) :rwx ${ CIVIPAROISSEDEV } sudo setfacl -R -m u:33:rxw ${ CIVIPAROISSEDEV } On arr\u00eate les conteneurs : docker-compose -f docker-compose.yml down","title":"R\u00e9cup\u00e9ration des donn\u00e9es en local"},{"location":"TECHNIQUE/LOGICIEL/environnement_dev.html#branchement-des-depots-gits","text":"Les d\u00e9p\u00f4ts gits viendront remplacer les fichiers de l'image, via de l'effacement puis des clones. D\u00e9p\u00f4t Description Chemin git@github.com:UEPAL-CiviParoisse/Extensions_CiviCRM.git Fichiers extension civiparoisse ${CIVIPAROISSEDEV}/app/vendor/uepal/fr.uepalparoisse.civiparoisse git@github.com:UEPAL-CiviParoisse/CIVIP_INSTALL.git Setup civicrm-civiparoisse ${CIVIPAROISSEDEV}/app/vendor/uepal/civisetup git@github.com:UEPAL-CiviParoisse/Modules_Drupal.git Module drupal civiparoisse ${CIVIPAROISSEDEV}/app/web/modules/contrib/fr.uepalparoisse.druparoisse Lorsqu'on branche les d\u00e9p\u00f4ts gits, on va certainement faire : un mv ou rm des fichiers pr\u00e9sents en local dans les r\u00e9pertoires cibles, des git clone pour remplacer les fichiers des git checkout pour se positionner dans les bonnes branches des setfacl pour positionner les droits pour le serveur web Lorsqu'on change les branches, il faudra penser \u00e0 vider les caches (par exemple via les interfaces d'administration).","title":"Branchement des d\u00e9p\u00f4ts gits"},{"location":"TECHNIQUE/LOGICIEL/environnement_dev.html#lancement-de-lenvironnement-pour-dev","text":"L'environnement pour le d\u00e9veloppement est un peu particulier, dans la mesure o\u00f9 l'on va utiliser un conteneur httpd modifi\u00e9 pour inclure Xdebug, ainsi qu'un montage bind des fichiers locaux. De m\u00eame, le r\u00e9seau utilis\u00e9 est un seul r\u00e9seau (en raison de probl\u00e8mes de mise au point sur les scopes). Pour le lancer : docker-compose -f docker-compose-bind.yml up -d Pour arr\u00eater : docker-compose -f docker-compose-bind.yml down","title":"Lancement de l'environnement pour dev"},{"location":"TECHNIQUE/LOGICIEL/environnement_dev.html#mots-de-passe-par-defaut","text":"Les mots de passe sont pr\u00e9sents dans les secrets li\u00e9s \u00e0 l'image init .","title":"Mots de passe par d\u00e9faut"},{"location":"TECHNIQUE/LOGICIEL/environnement_dev.html#configuration-xdebug-pour-vscode-launchjson","text":"On ouvre le dossier ${CIVIPAROISSEDEV}/app dans vscode. Vscode propose une extension pour xdebug : identificateur : xdebug.php-debug . Cette extension utilise un fichier launch.json pour configurer une instance de xdebug. Il convient de faire attention d'\u00e9couter sur toutes les IP et sur le bon port (9003), ainsi que de configurer le pathMapping, pour la correspondance des fichiers sources. { // Utilisez IntelliSense pour en savoir plus sur les attributs possibles. // Pointez pour afficher la description des attributs existants. // Pour plus d'informations, visitez : https://go.microsoft.com/fwlink/?linkid=830387 \"version\" : \"0.2.0\" , \"configurations\" : [ { \"name\" : \"Listen for Xdebug\" , \"type\" : \"php\" , \"request\" : \"launch\" , \"port\" : 9003 , \"hostname\" : \"::\" , \"pathMappings\" : { \"/app\" : \"${workspaceFolder}\" } } ] } Une fois que cela est fait, il suffit donc de positionner les points d'arr\u00eats et de lancer le d\u00e9bugger. A noter que xdebug, tel que configur\u00e9, est pr\u00e9vu pour envoyer des requ\u00eates dans tous les cas \u00e0 l'IDE.","title":"Configuration xdebug pour vscode : launch.json"},{"location":"TECHNIQUE/LOGICIEL/environnement_dev_env.html","text":"Personnalisation de l'environnement de d\u00e9veloppement Attention ! Les \u00e9l\u00e9ments de ce fichier n'ont pas \u00e9t\u00e9 v\u00e9rifi\u00e9s ; les lignes de commandes n'ont pas \u00e9t\u00e9 test\u00e9es. L'environnement de d\u00e9veloppement a \u00e9t\u00e9 pens\u00e9 initialement pour utiliser les images issues des Dockerfiles avec les variables d'environnement par d\u00e9faut. Toutefois, il est parfois n\u00e9cessaire de pouvoir personnaliser les valeurs, dont notamment le nom du serveur, et ceci peut avoir un impact sur les clefs TLS. Aspects th\u00e9oriques Personnalisation de l'environnement L'approche qui est pr\u00e9vue pour Helm est d'utiliser le fichier de valeurs, qui h\u00e9rite des valeurs par d\u00e9faut, pour pr\u00e9parer les \u00e9l\u00e9ments de configuration n\u00e9cessaires (ConfigMap, Secrets, entre autres) des pods. En revanche, cette approche est plus difficile \u00e0 mettre en oeuvre dans le cas de Compose. L'approche retenue est d'utiliser les fichiers d'environnement. On trouve trois type de fichiers : le fichier d'environnement sp\u00e9cifi\u00e9 au niveau de la ligne de commande ( --env-file ) : ce fichier permet d'utiliser des variables qui sont r\u00e9f\u00e9renc\u00e9es directement dans le fichier yml de docker-compose, et les valeurs peuvent \u00eatre propag\u00e9es, si elles sont au minimum mentionn\u00e9es dans le docker-compose, jusqu'au container le premier fichier d'environnement sp\u00e9cifi\u00e9 au niveau des configurations via env_file : ce fichier est pr\u00e9vu pour contenir des valeurs \"par d\u00e9faut\" qui sont normalement celles pr\u00e9sentes dans les images. Ces valeurs peuvent se retrouver par docker image inspect <nom image> . le deuxi\u00e8me fichier d'environnement sp\u00e9cifi\u00e9 via env_file (fichier avec suffixe override dans la configuration ): comme c'est le deuxi\u00e8me fichier, il sera pris en compte en priorit\u00e9 par rapport au premier fichier. Lorsque l'on souhaite modifier l'environnement, il faut donc modifier le fichier envfile principal et les fichiers d'override, en gardant la correspondance des valeurs. Attention ! Si on modifie SERVERNAME , il faut \u00e9galement penser \u00e0 inclure la modification dans le TRUSTED_HOST_PATTERNS . Clefs TLS Au niveau de Helm, le template qui g\u00e8re les clefs TLS est capable de pr\u00e9parer les hi\u00e9rarchies de certificats (avec CA autosign\u00e9s), et est pr\u00e9vu pour ne remplacer les clefs que si elles n'existent pas. Au niveau de docker-compose, ce m\u00e9canisme n'existe pas, et il a \u00e9t\u00e9 n\u00e9cessaire de pr\u00e9parer une image KEYS_INIT pour pr\u00e9parer les jeux de clefs qui vont \u00eatre stock\u00e9s dans un montage de type bind (vers le r\u00e9pertoire genkeys ). Pour utiliser cette image, il faudra passer la valeur de la variable d'environnement SERVERNAME au container. Le fichier docker-init-envkeys.yml est pr\u00e9vu pour cela, en utilisant en plus le fichier principal d'environnement ( --env-file ). Aspects pratiques En pratique, on suivra le cheminement suivant pour utiliser ces \u00e9l\u00e9ments : r\u00e9cup\u00e9ration du d\u00e9p\u00f4t des Dockerfiles, et se positionner sur la branche (peut-\u00eatre ENV_DEV_KEYS ) personnalisation des fichiers d'environnement envfile principal et les fichiers envfile_*_override , en fonction des besoins du d\u00e9veloppeur build des images, gr\u00e2ce au script build.sh g\u00e9n\u00e9ration des clefs : #!/bin/bash docker-compose -f docker-init-envkeys.yml --env-file envfile up docker-compose -f docker-init-envkeys.yml --env-file envfile down installation de l'environnement (volumes et BD) : #!/bin/bash docker-compose -f docker-init-env.yml --env-file envfile up docker-compose -f docker-init-env.yml --env-file envfile down d\u00e9marrage avec l'environnement des containers : #!/bin/bash docker-compose -f docker-compose-env.yml --env-file envfile up se logguer dans le syst\u00e8me pour v\u00e9rifier que tout s'est bien pass\u00e9 r\u00e9cup\u00e9rer le /app du container de serveur web interne comme d\u00e9crit dans l'environnement de dev (en pensant \u00e0 r\u00e9gler aussi les droits) arr\u00eater l'environnement des containers : #!/bin/bash docker-compose -f docker-compose-env.yml --env-file envfile down d\u00e9marrer l'environnement bind\u00e9 avec les r\u00e9pertoires locaux (comme d\u00e9crits dans l'environnement de d\u00e9veloppement) #!/bin/bash docker-compose -f docker-compose-bind-env.yml --env-file envfile up faire le travail d\u00e9sir\u00e9 (d\u00e9veloppement) arr\u00eater l'environnement #!/bin/bash docker-compose -f docker-compose-bind-env.yml --env-file envfile down","title":"Personnalisation environnement de dev"},{"location":"TECHNIQUE/LOGICIEL/environnement_dev_env.html#personnalisation-de-lenvironnement-de-developpement","text":"Attention ! Les \u00e9l\u00e9ments de ce fichier n'ont pas \u00e9t\u00e9 v\u00e9rifi\u00e9s ; les lignes de commandes n'ont pas \u00e9t\u00e9 test\u00e9es. L'environnement de d\u00e9veloppement a \u00e9t\u00e9 pens\u00e9 initialement pour utiliser les images issues des Dockerfiles avec les variables d'environnement par d\u00e9faut. Toutefois, il est parfois n\u00e9cessaire de pouvoir personnaliser les valeurs, dont notamment le nom du serveur, et ceci peut avoir un impact sur les clefs TLS.","title":"Personnalisation de l'environnement de d\u00e9veloppement"},{"location":"TECHNIQUE/LOGICIEL/environnement_dev_env.html#aspects-theoriques","text":"","title":"Aspects th\u00e9oriques"},{"location":"TECHNIQUE/LOGICIEL/environnement_dev_env.html#personnalisation-de-lenvironnement","text":"L'approche qui est pr\u00e9vue pour Helm est d'utiliser le fichier de valeurs, qui h\u00e9rite des valeurs par d\u00e9faut, pour pr\u00e9parer les \u00e9l\u00e9ments de configuration n\u00e9cessaires (ConfigMap, Secrets, entre autres) des pods. En revanche, cette approche est plus difficile \u00e0 mettre en oeuvre dans le cas de Compose. L'approche retenue est d'utiliser les fichiers d'environnement. On trouve trois type de fichiers : le fichier d'environnement sp\u00e9cifi\u00e9 au niveau de la ligne de commande ( --env-file ) : ce fichier permet d'utiliser des variables qui sont r\u00e9f\u00e9renc\u00e9es directement dans le fichier yml de docker-compose, et les valeurs peuvent \u00eatre propag\u00e9es, si elles sont au minimum mentionn\u00e9es dans le docker-compose, jusqu'au container le premier fichier d'environnement sp\u00e9cifi\u00e9 au niveau des configurations via env_file : ce fichier est pr\u00e9vu pour contenir des valeurs \"par d\u00e9faut\" qui sont normalement celles pr\u00e9sentes dans les images. Ces valeurs peuvent se retrouver par docker image inspect <nom image> . le deuxi\u00e8me fichier d'environnement sp\u00e9cifi\u00e9 via env_file (fichier avec suffixe override dans la configuration ): comme c'est le deuxi\u00e8me fichier, il sera pris en compte en priorit\u00e9 par rapport au premier fichier. Lorsque l'on souhaite modifier l'environnement, il faut donc modifier le fichier envfile principal et les fichiers d'override, en gardant la correspondance des valeurs. Attention ! Si on modifie SERVERNAME , il faut \u00e9galement penser \u00e0 inclure la modification dans le TRUSTED_HOST_PATTERNS .","title":"Personnalisation de l'environnement"},{"location":"TECHNIQUE/LOGICIEL/environnement_dev_env.html#clefs-tls","text":"Au niveau de Helm, le template qui g\u00e8re les clefs TLS est capable de pr\u00e9parer les hi\u00e9rarchies de certificats (avec CA autosign\u00e9s), et est pr\u00e9vu pour ne remplacer les clefs que si elles n'existent pas. Au niveau de docker-compose, ce m\u00e9canisme n'existe pas, et il a \u00e9t\u00e9 n\u00e9cessaire de pr\u00e9parer une image KEYS_INIT pour pr\u00e9parer les jeux de clefs qui vont \u00eatre stock\u00e9s dans un montage de type bind (vers le r\u00e9pertoire genkeys ). Pour utiliser cette image, il faudra passer la valeur de la variable d'environnement SERVERNAME au container. Le fichier docker-init-envkeys.yml est pr\u00e9vu pour cela, en utilisant en plus le fichier principal d'environnement ( --env-file ).","title":"Clefs TLS"},{"location":"TECHNIQUE/LOGICIEL/environnement_dev_env.html#aspects-pratiques","text":"En pratique, on suivra le cheminement suivant pour utiliser ces \u00e9l\u00e9ments : r\u00e9cup\u00e9ration du d\u00e9p\u00f4t des Dockerfiles, et se positionner sur la branche (peut-\u00eatre ENV_DEV_KEYS ) personnalisation des fichiers d'environnement envfile principal et les fichiers envfile_*_override , en fonction des besoins du d\u00e9veloppeur build des images, gr\u00e2ce au script build.sh g\u00e9n\u00e9ration des clefs : #!/bin/bash docker-compose -f docker-init-envkeys.yml --env-file envfile up docker-compose -f docker-init-envkeys.yml --env-file envfile down installation de l'environnement (volumes et BD) : #!/bin/bash docker-compose -f docker-init-env.yml --env-file envfile up docker-compose -f docker-init-env.yml --env-file envfile down d\u00e9marrage avec l'environnement des containers : #!/bin/bash docker-compose -f docker-compose-env.yml --env-file envfile up se logguer dans le syst\u00e8me pour v\u00e9rifier que tout s'est bien pass\u00e9 r\u00e9cup\u00e9rer le /app du container de serveur web interne comme d\u00e9crit dans l'environnement de dev (en pensant \u00e0 r\u00e9gler aussi les droits) arr\u00eater l'environnement des containers : #!/bin/bash docker-compose -f docker-compose-env.yml --env-file envfile down d\u00e9marrer l'environnement bind\u00e9 avec les r\u00e9pertoires locaux (comme d\u00e9crits dans l'environnement de d\u00e9veloppement) #!/bin/bash docker-compose -f docker-compose-bind-env.yml --env-file envfile up faire le travail d\u00e9sir\u00e9 (d\u00e9veloppement) arr\u00eater l'environnement #!/bin/bash docker-compose -f docker-compose-bind-env.yml --env-file envfile down","title":"Aspects pratiques"},{"location":"TECHNIQUE/LOGICIEL/importation.html","text":"Importation initiale Civiparoisse a besoin de donn\u00e9es pour pouvoir rendre service aux paroisses. Les donn\u00e9es initiales ont \u00e9t\u00e9 collect\u00e9es et stock\u00e9es dans un fichier excel ad-hoc, dont le format est d\u00e9crit dans un document tiers. Deux \u00e9tapes sont n\u00e9cessaires pour importer les donn\u00e9es : parser le fichier excel, puis exploiter les donn\u00e9es. Parsage des donn\u00e9es Le parsage du fichier excel peut \u00eatre effectu\u00e9 gr\u00e2ce \u00e0 la librairie phpoffice/phpspreadsheet, qui est une d\u00e9pendance (r\u00e9cente) de CiviCRM. Les donn\u00e9es pars\u00e9es correspondent \u00e0 une partie d'une pseudo-table globale de connaissances sur les paroissiens. Il a sembl\u00e9 judicieux de mettre le code relatif au parsage des donn\u00e9es dans une biblioth\u00e8que s\u00e9par\u00e9e, afin de pouvoir \u00e9ventuellement r\u00e9utiliser le code de parsage pour une validation du fichier Excel hors CiviCRM. Le parsage est conceptuellement simple : on cr\u00e9e des parseurs de colonnes issus d'une m\u00eame classe abstraite pour analyser les diff\u00e9rents cellules d'une ligne de donn\u00e9es, et on met les r\u00e9sultats du parsage dans une structure de donn\u00e9es. Parser une ligne consiste donc \u00e0 ex\u00e9cuter l'ensemble des parseurs disponibles. Le code pr\u00e9voit des contr\u00f4les sur les donn\u00e9es ; une donn\u00e9e jug\u00e9e invalide est ignor\u00e9e. Les contr\u00f4les similaires (par exemple sur la casse, ou sur des expressions rationnelles) sont impl\u00e9ment\u00e9es dans des classes abstraites qui d\u00e9coulent du parseur principal afin de factoriser le code. On liste en-dessous les parseurs, et les contr\u00f4les effectu\u00e9s. On arrive \u00e0 d\u00e9duire du nom du parseur le champ concern\u00e9 du fichier Excel. En plus des champs proprement dit, on r\u00e9cup\u00e8re \u00e9galemement le num\u00e9ro de ligne. Celui-ci pourra \u00e9ventuellement \u00eatre utile pour les logs de message d'erreur. Bug Remarque globale pour tous les parsers \"Oui/Non\" : v\u00e9rifier que Excel renvoie bien Oui/Non, et pas Vrai/Faux Bug Code Postal : attention on peut avoir des CP suisses en 4 chiffres, voir \u00e9ventuellement des CP d'autres pays Bug T\u00e9l\u00e9phones : on peut avoir des num\u00e9ros \u00e0 l'\u00e9tranger (Allemagne, Suisse, ...) Parseur Contr\u00f4le AdresseLigne1Parser Ne pas matcher la cha\u00eene vide (Regex : '/^[[:space:]]*$/' ) AdresseLigne2Parser Ne pas matcher la cha\u00eene vide (Regex : '/^[[:space:]]*$/' ) AdresseLigne3Parser Ne pas matcher la cha\u00eene vide (Regex : '/^[[:space:]]*$/' ) AdulteParser Doit correspondre soit \u00e0 la cha\u00eene 'Oui' soit \u00e0 la cha\u00eene 'Non' CiviliteParser Doit correspondre soit \u00e0 la cha\u00eene 'M.' soit \u00e0 la cha\u00eene 'Mme' CodePostalParser Doit matcher '/^([[:upper:]]+-)?[0-9]{5}$/' DateNaissanceParser Doit \u00eatre parsable avec le format DateTime 'd/m/Y|' DiversParser Ne pas matcher la cha\u00eene vide (Regex : '/^[[:space:]]*$/' ) ElecteurParser Doit correspondre soit \u00e0 la cha\u00eene 'Oui' soit \u00e0 la cha\u00eene 'Non' EmailAutreParser Doit passer avec filter_var avec FILTER_VALIDATE_EMAIL EmailPriveParser Doit passer avec filter_var avec FILTER_VALIDATE_EMAIL EnfantParser Doit correspondre soit \u00e0 la cha\u00eene 'Oui' soit \u00e0 la cha\u00eene 'Non' FoyerAppartenanceParser Ne pas matcher la cha\u00eene vide (Regex : '/^[[:space:]]*$/' ) LieuNaissanceParser Ne pas matcher la cha\u00eene vide (Regex : '/^[[:space:]]*$/' ) NomConjointParser Ne pas matcher la cha\u00eene vide (Regex : '/^[[:space:]]*$/' ) NomNaissanceParser Doit matcher la Regex '#^[[:upper:]]+([ \\-\\'/][[:upper:]]+)*$#' NomParentsParser Ne pas matcher la cha\u00eene vide (Regex : '/^[[:space:]]*$/' ) NomParser Doit matcher la Regex '#^[[:upper:]]+([ \\-\\'/][[:upper:]]+)*$#' PaysParser Ne pas matcher la cha\u00eene vide (Regex : '/^[[:space:]]*$/' ) PrenomParser Doit matcher la regex '/^[[:upper:]][[:lower:]\u00e9\u00e8\u00ea\u00eb\u00fc\u00f4\u00ef\u00e0\u00f9]+(-[[:upper:]][[:lower:]\u00e9\u00e8\u00ea\u00eb\u00fc\u00f4\u00ef\u00e0\u00f9]+)*$/' RowIndexParser La valeur doit \u00eatre non vide et num\u00e9rique ( is_numeric ) TelephoneAutreParser Doit matcher la Regex '#^00 33 [12345679] [0-9]{2} [0-9]{2} [0-9]{2} [0-9]{2}$#' TelephoneFixeParser Doit matcher la Regex '#^00 33 [123459] [0-9]{2} [0-9]{2} [0-9]{2} [0-9]{2}$#' TelephonePortableParser Doit matcher la Regex '#^00 33 [67] [0-9]{2} [0-9]{2} [0-9]{2} [0-9]{2}$#' VilleParser Doit matcher la Regex '#^[[:upper:]]+([ \\-\\'/][[:upper:]]+)*$#' Exploitation des donn\u00e9es Plusieurs approches semblent convenir pour exploiter cette pseudo-table : travailler directement en m\u00e9moire, en calculant et en mettant \u00e0 jour des structures de donn\u00e9es. passer par des requ\u00eates SQL que ce soit avec un moteur s\u00e9par\u00e9 (par exemple sqlite) ou en utilisant MySQL, et, par exemple, des tables temporaires (voir https://dev.mysql.com/doc/refman/8.0/en/create-temporary-table.html ) construction petit \u00e0 petit des enregistrements, avec utilisation de fonctions getOrCreate, et en mettant un peu d'intelligence dans le ParsedContact pour exploiter les donn\u00e9es Import des \u00e9l\u00e9ments li\u00e9s au Contact Le parsage cr\u00e9e des objets de type Uepal\\CiviImport\\ParsedContact. Pour importer les \u00e9l\u00e9ments, il faut d'abord commencer par identifier les entit\u00e9s cibles de CiviCRM : le contact : on aura un contact par ligne. Les attributs qui seront stock\u00e9s sont les suivants : protected function computeContactParams(): array { $cfUtils = CRM_Civiparoisse_Utils_CustomFields::getSingleton(); $parsedContact = $this->getCompositeImportData()->getParsedContact(); $candidates = [\"prefix_id:label\" => $parsedContact->getCivilite(), \"gender_id:name\" => $this->computeContactGenderName($parsedContact), \"contact_type:name\" => \"Individual\", \"last_name\" => $parsedContact->getNom(), $cfUtils->getFieldNameId(\"nom_naissance\") => $parsedContact->getNomNaissan ce(), \"first_name\" => $parsedContact->getPrenom(), \"birth_date\" => CRM_Civiparoisse_Utils_DateFormatter::formatDate($parsedCo ntact->getDateNaissance()), $cfUtils->getFieldNameId(\"lieu_naissance\") => $parsedContact->getLieuNaissance(), 'household_name' => $parsedContact->getFoyerAppartenance()]; $candidates = array_filter($candidates); return ['values' => $candidates]; } le t\u00e9l\u00e9phone mobile : protected function computeMobilePhoneParams(): array { return ['values' => ['location_type:name' => 'Accueil', 'phone_type_id:name' => 'Mobile', 'contact_id' => $this->getCompositeImportData()->getContactId(), 'phone' => $this->getCompositeImportData()->getParsedContact()->getTelephonePortable(), 'is_primary' => 1]]; } le t\u00e9l\u00e9phone professionnel appel\u00e9 auparavant \"autre\" protected function computeOtherPhoneParams(): array { return ['values' => ['location_type:name' => 'Travail', 'phone_type_id:name' => 'Phone', 'contact_id' => $this->getCompositeImportData()->getContactId(), 'phone' => $this->getCompositeImportData()->getParsedContact()->getTelephoneAutre(), 'is_primary' => 0]]; } le mail priv\u00e9 : protected function computeEmailPriveParam() : array { return ['values' => ['email' => $this->getCompositeImportData()->getParsedContact()->getEmailPrive(), 'contact_id' => $this->getCompositeImportData()->getContactId(), 'location_type:name' => 'Accueil', 'is_primary' => TRUE]]; } le mail professionnel : protected function computeEmailAutreParam() : array { return ['values' => ['email' => $this->getCompositeImportData()->getParsedContact()->getEmailAutre(), 'contact_id' => $this->getCompositeImportData()->getContactId(), 'location_type_id:name' => 'Travail', 'is_primary' => 0 ]]; } * la note compl\u00e9mentaire : protected function computeNoteDiversParam(): array { return ['values' => [ 'note' => $this->getCompositeImportData()->getParsedContact()->getDivers(), 'entity_table:name' => 'Contact', 'entity_id' => $this->getCompositeImportData()->getContactId(), 'contact_id' =>CRM_Core_Session::getLoggedInContactID(), 'subject' => 'Note import' ]]; } Import des \u00e9l\u00e9ments li\u00e9s au foyer le foyer : un foyer sera constitu\u00e9 par un nom de foyer, une adresse, et un num\u00e9ro de t\u00e9l\u00e9phone fixe. Toute alt\u00e9ration d'un des champs conduira \u00e0 un nouveau foyer ; on se souviendra que le foyer est un type de contact. Le foyer est consid\u00e9r\u00e9 comme une unit\u00e9 familiale (parents et \u00e9ventuellement enfants). protected function computeHouseholdParams(): array { return ['values' => [ 'contact_type' => 'Household', 'display_name' => $this->getCompositeImportData()->getParsedContact()->getFoyerAppartenance(), 'household_name' => $this->getCompositeImportData()->getParsedContact()->getFoyerAppartenance() ]]; } l'adresse : l'adresse sera rattach\u00e9e au foyer. Du fait de la construction du fichier, il serait difficile de faire les s\u00e9parations fines des constituants de l'adresse pour les faire rentrer exactement dans les champs de civicrm. On utilise donc les lignes d'adresse supl\u00e9mentaire pour le stockage. protected function computeAddressParams(): array { return ['values' => ['street_address' => $this->getCompositeImportData()->getParsedContact()->getAdresseLigne1(), 'supplemental_address_1' => $this->getCompositeImportData()->getParsedContact()->getAdresseLigne2(), 'supplemental_address_2' => $this->getCompositeImportData()->getParsedContact()->getAdresseLigne3(), 'postal_code' => $this->getCompositeImportData()->getParsedContact()->getCodePostal(), 'city' => $this->getCompositeImportData()->getParsedContact()->getVille(), 'country_id:label' => $this->getCompositeImportData()->getParsedContact()->getPays(), 'contact_id' => $this->getCompositeImportData()->getFoyerId(), 'is_primary' => TRUE, 'location_type_id:name' => 'Accueil']]; } Bug Pour l'adresse il faut rajouter une variable location_type 'location_type_id' => 1, // 1 = domicile, 2 = travail, 3 \u00e0 5 pas utilis\u00e9s dans notre projet le num\u00e9ro de t\u00e9l\u00e9phone fixe : chaque num\u00e9ro est une entit\u00e9 distincte. Le num\u00e9ro fixe est reli\u00e9 au foyer, tandis que le num\u00e9ro mobile et le num\u00e9ro autre est reli\u00e9 au contact. La distinction entre les num\u00e9ros de t\u00e9l\u00e9phones se fait via le champ location_type_id et phone_type_id (\u00e0 v\u00e9rifier : les valeurs de location_type que l'on souhaite utiliser): protected function computePhoneParams(): array { return ['values' => [ 'contact_id' => $this->getCompositeImportData()->getFoyerId(), 'phone' => $this->getCompositeImportData()->getParsedContact()->getTelephoneFixe(), 'location_type_id:name' => 'Accueil', 'phone_type_id:name' => 'Phone', 'is_primary' => 1 ]]; } Bug Pour les t\u00e9l\u00e9phones, il faut g\u00e9rer deux variables 'location_type_id' => 1, // 1 = domicile, 2 = travail, 3 \u00e0 5 pas utilis\u00e9s dans notre projet 'phone_type_id' => 2, // 1= fixe, 2 = portable, 3 = fax, 4 et 5 pas utilis\u00e9s dans notre projet Bug CAUTION : je ne suis pas s\u00fbr que ce soit les bonnes valeurs du location_type les emails : chaque email constitue \u00e9galement une entit\u00e9 distincte, \u00e9galement reli\u00e9e au contact, et on utilise \u00e9galement le location_type pour distinguer les emails : Bug Pour les mails, je ne suis pas s\u00fbr que les valeurs location_type ci-dessous soient les bonnes 'location_type_id' => 1, // 1 = domicile, 2 = travail, 3 \u00e0 5 pas utilis\u00e9s dans notre projet La liaison entre les contacts individuels et les adresses Il s'agit ici de cr\u00e9er des adresses pour chaque contact individuel : ces adresses vont \u00eatre rattach\u00e9es aux adresses du foyer. protected function computeContactAddrWorkload() : array { return ['values'=>[ 'contact_id'=>$this->getCompositeData()->getContactId(), 'master_id'=>$this->getCompositeData()->getFoyerAddrId() ]]; } Les relations entre les contacts, foyers, et le membership relation membre de foyer : il s'agi de mat\u00e9rialiser le fait qu'un contact fasse parti d'un foyer. protected function computeMemberOfHouseholdParams(int $ord): array { return ['values' => ['relationship_type_id:name' => 'Household Member of', 'contact_id_a' => $this->getCompositeImportData($ord)->getContactId(), 'contact_id_b' => $this->getCompositeImportData($ord)->getFoyerId()]]; } relation adulte : il s'agit en fait des \"chefs de famille\" - chefs de foyers. Le fait d'activer la case \u00e0 cocher indique qu'il faut g\u00e9n\u00e9rer une relation chef de famille vers le foyer protected function computeHeadOfHouseholdParams(int $ord): array { $compositeImportData = $this->getCompositeImportData($ord); return ['values' => ['relationship_type_id:name' => 'Head of Household for', 'contact_id_a' => $compositeImportData->getContactId(), 'contact_id_b' => $compositeImportData->getFoyerId()]]; } membre \u00e9lecteur : il s'agit d'un type de membership vers l'organisation de la paroisse ; ce membership est mis en oeuvre du moment que Electeur est activ\u00e9. protected function computeElecteurParams(int $ord): array { return ['values' => ['membership_type_id.name' => 'Electeur\u00b7trice', 'contact_id' => $this->getCompositeImportData($ord)->getContactId()]]; } relation conjoint : On effectue une liaison en v\u00e9rifiant nom et pr\u00e9nom ; on privil\u00e9giera le fait de faire parti d'un m\u00eame foyer pour la s\u00e9lection du conjoint. Le type de relation lui-m\u00eame d\u00e9pendra du nom du foyer, car le nom du foyer refl\u00e8te le mariage ou la libre union. protected function computeSpouseParams(int $ord): array { $spouseId = $this->retrieveSpouseId($ord); $contactId = $this->getCompositeImportData($ord)->getContactId(); $relationship = $this->computeSpouseRelationTypeName($ord); return ['values' => ['relationship_type_id:name' => $relationship, 'contact_id_a' => $contactId, 'contact_id_b' => $spouseId]]; } relation parent : la relation de parents indique le nom des deux parents. On distingue le fait que les parents soit mari\u00e9s ou non pour calculer le nom individuel recherch\u00e9 de chaque parent. Le parent est cherch\u00e9 en priorit\u00e9 dans le foyer, et ensuite dans l'ensemble des contacts. protected function computeParentParam(int $ord, int $parentId): array { $contactId = $this->getCompositeImportData($ord)->getContactId(); return ['values' => ['relationship_type_id:name' => 'Child of', 'contact_id_a' => $contactId, 'contact_id_b' => $parentId]]; } membre enfant inscrit: un enfant est uniquement membre du foyer, marqu\u00e9 comme enfant,non marqu\u00e9 comme \u00e9lecteur et n'\u00e9tant pas majeur. protected function computeEnfantInscritParam(int $ord): array { return ['values' => ['membership_type_id.name' => 'Inscrit\u00b7e Enfant', 'contact_id' => $this->getCompositeImportData($ord)->getContactId()]]; } relation de fratrie : la relation de fratrie est uniquement activ\u00e9 lorsque les deux parents sont les m\u00eames. protected function computeFratrieParam(int $ord,int $fratrieId) : array { $contactId = $this->getCompositeImportData($ord)->getContactId(); return ['values' => ['relationship_type_id:name' => 'Sibling of', 'contact_id_a' => $contactId, 'contact_id_b' => $fratrieId]]; } Guidelines pour l'import Le but est ici uniquement de g\u00e9rer un import initial. Toutefois, si les donn\u00e9es de diff\u00e9rents lots sont enti\u00e8rement disjointes, on peut envisager des imports successifs \u00e0 partir de plusieurs fichiers - m\u00eame s'il faut garder \u00e0 l'esprit que le d\u00e9veloppement n'a pas \u00e9t\u00e9 pr\u00e9vu pour \u00e7a. Outillage : l'image tools La proc\u00e9dure d'import est pr\u00e9vue pour \u00eatre lanc\u00e9e depuis la ligne de commande (outil cv). De ce fait, on utilisera l'image des outils pour acc\u00e9der au n\u00e9cessaire, en effectuant les montages requis (en particulier montage des fichiers, et montage du point d'acc\u00e8s \u00e0 la BD). Le fichier lui-m\u00eame pourra \u00eatre \u00e9galement mont\u00e9 dans l'image, ou copi\u00e9 dans le container lors de l'ex\u00e9cution (par exemple via docker cp ). Parsage Avant de lancer l'import proprement dit, il faut v\u00e9rifier si le parsage se fait correctement. Il est en effet arriv\u00e9 lors des tests qu'un fichier au format xlsx modifi\u00e9 par LibreOffice a pos\u00e9 probl\u00e8me lors du parsage (mauvaise consid\u00e9ration de la derni\u00e8re ligne renseign\u00e9e). Dans ce genre de cas, on privil\u00e9giera des enregistrements dans des formats natifs (ods, xlsx) du moment que les formats sont support\u00e9s par phpspreadsheet. #!/bin/bash #export PHP_IDE_CONFIG=\"serverName=civicrm.test\" export CIVIPAROISSE_IMPORT_FILEPATH = \"/app/test2.ods\" export CIVIPAROISSE_IMPORT_SHEETNAME = \"Feuil1\" cv ev 'var_dump(CRM_Civiparoisse_Import_Importer::parse(new Uepal\\CiviImport\\MiniLogger()))' Le parseur est pr\u00e9vu pour utiliser un logger sp\u00e9cifi\u00e9 en param\u00e8tre. Trois loggers sont notamment \u00e0 consid\u00e9rer : le MiniLogger : new Uepal\\CiviImport\\MiniLogger()) : ce logger est inclus dans le code du parseur, et il utilise le error_log de PHP pour logguer les messages le Logger de Civicrm ( CRM_Core_Error_Log ) : l'acc\u00e8s \u00e0 ce Logger suppose la pr\u00e9sence de CiviCRM. Un helper a \u00e9t\u00e9 pr\u00e9par\u00e9 pour acc\u00e9der \u00e0 ce logger : CRM_Civiparoisse_Utils_Logger::getLogger : /** * General Purpose CiviCRM logger (psr_log) * @return LoggerInterface */ public static function getLogger(): LoggerInterface { return (Container::singleton()->get('psr_log')); } le Logger pr\u00e9sent dans \\Psr\\Log\\NullLogger : ce logger fait parti du package Composer psr/log, et fait partie des d\u00e9pendances requises par le parseur. Son int\u00e9r\u00eat est qu'il ne fait rien, donc ne va pas effectuer des logs, et permet de garder une sortie \u00e9cran \"propre\" pour voir ce qui a \u00e9t\u00e9 pars\u00e9. A l'occasion des parsages, on fera en particulier attention si les dates correspondent, et si le nombre d'enregistrement est juste. Le parsage est fait en \"Best Effort\" : une valeur qui n'est pas valid\u00e9e par les contr\u00f4les du syst\u00e8me sera ignor\u00e9e. Importation L'importation est r\u00e9alis\u00e9e \u00e9galement en ligne de commande. #!/bin/bash #export PHP_IDE_CONFIG=\"serverName=civicrm.test\" export CIVIPAROISSE_IMPORT_FILEPATH = \"/app/test2.ods\" export CIVIPAROISSE_IMPORT_SHEETNAME = \"Feuil1\" cv ev -U drupaladmin 'CRM_Civiparoisse_Import_Importer::parseImport(CRM_Civiparoisse_Utils_Logger::getLogger())' Si on consid\u00e8re un syst\u00e8me fra\u00eechement install\u00e9, un moyen qui semble \u00eatre assez efficace pour effacer une importation est de supprimer l'ensemble des contacts dont l'ID est strictement sup\u00e9rieur \u00e0 2, en n'utilisant pas la corbeille (trash). Ceci peut \u00eatre r\u00e9alis\u00e9 depuis l'explorateur d'API v4, depuis les menus de CiviCRM. On peut v\u00e9rifier les r\u00e9sultats de l'importation de plusieurs mani\u00e8res : analyser l'ex\u00e9cution de l'import via Xdebug et un IDE analyser le contenu de la BD via MySQL analyser le contenu de la BD via des appels API analyser le contenu de la BD depuis l'interface web de civicrm","title":"Importation de donn\u00e9es"},{"location":"TECHNIQUE/LOGICIEL/importation.html#importation-initiale","text":"Civiparoisse a besoin de donn\u00e9es pour pouvoir rendre service aux paroisses. Les donn\u00e9es initiales ont \u00e9t\u00e9 collect\u00e9es et stock\u00e9es dans un fichier excel ad-hoc, dont le format est d\u00e9crit dans un document tiers. Deux \u00e9tapes sont n\u00e9cessaires pour importer les donn\u00e9es : parser le fichier excel, puis exploiter les donn\u00e9es.","title":"Importation initiale"},{"location":"TECHNIQUE/LOGICIEL/importation.html#parsage-des-donnees","text":"Le parsage du fichier excel peut \u00eatre effectu\u00e9 gr\u00e2ce \u00e0 la librairie phpoffice/phpspreadsheet, qui est une d\u00e9pendance (r\u00e9cente) de CiviCRM. Les donn\u00e9es pars\u00e9es correspondent \u00e0 une partie d'une pseudo-table globale de connaissances sur les paroissiens. Il a sembl\u00e9 judicieux de mettre le code relatif au parsage des donn\u00e9es dans une biblioth\u00e8que s\u00e9par\u00e9e, afin de pouvoir \u00e9ventuellement r\u00e9utiliser le code de parsage pour une validation du fichier Excel hors CiviCRM. Le parsage est conceptuellement simple : on cr\u00e9e des parseurs de colonnes issus d'une m\u00eame classe abstraite pour analyser les diff\u00e9rents cellules d'une ligne de donn\u00e9es, et on met les r\u00e9sultats du parsage dans une structure de donn\u00e9es. Parser une ligne consiste donc \u00e0 ex\u00e9cuter l'ensemble des parseurs disponibles. Le code pr\u00e9voit des contr\u00f4les sur les donn\u00e9es ; une donn\u00e9e jug\u00e9e invalide est ignor\u00e9e. Les contr\u00f4les similaires (par exemple sur la casse, ou sur des expressions rationnelles) sont impl\u00e9ment\u00e9es dans des classes abstraites qui d\u00e9coulent du parseur principal afin de factoriser le code. On liste en-dessous les parseurs, et les contr\u00f4les effectu\u00e9s. On arrive \u00e0 d\u00e9duire du nom du parseur le champ concern\u00e9 du fichier Excel. En plus des champs proprement dit, on r\u00e9cup\u00e8re \u00e9galemement le num\u00e9ro de ligne. Celui-ci pourra \u00e9ventuellement \u00eatre utile pour les logs de message d'erreur. Bug Remarque globale pour tous les parsers \"Oui/Non\" : v\u00e9rifier que Excel renvoie bien Oui/Non, et pas Vrai/Faux Bug Code Postal : attention on peut avoir des CP suisses en 4 chiffres, voir \u00e9ventuellement des CP d'autres pays Bug T\u00e9l\u00e9phones : on peut avoir des num\u00e9ros \u00e0 l'\u00e9tranger (Allemagne, Suisse, ...) Parseur Contr\u00f4le AdresseLigne1Parser Ne pas matcher la cha\u00eene vide (Regex : '/^[[:space:]]*$/' ) AdresseLigne2Parser Ne pas matcher la cha\u00eene vide (Regex : '/^[[:space:]]*$/' ) AdresseLigne3Parser Ne pas matcher la cha\u00eene vide (Regex : '/^[[:space:]]*$/' ) AdulteParser Doit correspondre soit \u00e0 la cha\u00eene 'Oui' soit \u00e0 la cha\u00eene 'Non' CiviliteParser Doit correspondre soit \u00e0 la cha\u00eene 'M.' soit \u00e0 la cha\u00eene 'Mme' CodePostalParser Doit matcher '/^([[:upper:]]+-)?[0-9]{5}$/' DateNaissanceParser Doit \u00eatre parsable avec le format DateTime 'd/m/Y|' DiversParser Ne pas matcher la cha\u00eene vide (Regex : '/^[[:space:]]*$/' ) ElecteurParser Doit correspondre soit \u00e0 la cha\u00eene 'Oui' soit \u00e0 la cha\u00eene 'Non' EmailAutreParser Doit passer avec filter_var avec FILTER_VALIDATE_EMAIL EmailPriveParser Doit passer avec filter_var avec FILTER_VALIDATE_EMAIL EnfantParser Doit correspondre soit \u00e0 la cha\u00eene 'Oui' soit \u00e0 la cha\u00eene 'Non' FoyerAppartenanceParser Ne pas matcher la cha\u00eene vide (Regex : '/^[[:space:]]*$/' ) LieuNaissanceParser Ne pas matcher la cha\u00eene vide (Regex : '/^[[:space:]]*$/' ) NomConjointParser Ne pas matcher la cha\u00eene vide (Regex : '/^[[:space:]]*$/' ) NomNaissanceParser Doit matcher la Regex '#^[[:upper:]]+([ \\-\\'/][[:upper:]]+)*$#' NomParentsParser Ne pas matcher la cha\u00eene vide (Regex : '/^[[:space:]]*$/' ) NomParser Doit matcher la Regex '#^[[:upper:]]+([ \\-\\'/][[:upper:]]+)*$#' PaysParser Ne pas matcher la cha\u00eene vide (Regex : '/^[[:space:]]*$/' ) PrenomParser Doit matcher la regex '/^[[:upper:]][[:lower:]\u00e9\u00e8\u00ea\u00eb\u00fc\u00f4\u00ef\u00e0\u00f9]+(-[[:upper:]][[:lower:]\u00e9\u00e8\u00ea\u00eb\u00fc\u00f4\u00ef\u00e0\u00f9]+)*$/' RowIndexParser La valeur doit \u00eatre non vide et num\u00e9rique ( is_numeric ) TelephoneAutreParser Doit matcher la Regex '#^00 33 [12345679] [0-9]{2} [0-9]{2} [0-9]{2} [0-9]{2}$#' TelephoneFixeParser Doit matcher la Regex '#^00 33 [123459] [0-9]{2} [0-9]{2} [0-9]{2} [0-9]{2}$#' TelephonePortableParser Doit matcher la Regex '#^00 33 [67] [0-9]{2} [0-9]{2} [0-9]{2} [0-9]{2}$#' VilleParser Doit matcher la Regex '#^[[:upper:]]+([ \\-\\'/][[:upper:]]+)*$#'","title":"Parsage des donn\u00e9es"},{"location":"TECHNIQUE/LOGICIEL/importation.html#exploitation-des-donnees","text":"Plusieurs approches semblent convenir pour exploiter cette pseudo-table : travailler directement en m\u00e9moire, en calculant et en mettant \u00e0 jour des structures de donn\u00e9es. passer par des requ\u00eates SQL que ce soit avec un moteur s\u00e9par\u00e9 (par exemple sqlite) ou en utilisant MySQL, et, par exemple, des tables temporaires (voir https://dev.mysql.com/doc/refman/8.0/en/create-temporary-table.html ) construction petit \u00e0 petit des enregistrements, avec utilisation de fonctions getOrCreate, et en mettant un peu d'intelligence dans le ParsedContact pour exploiter les donn\u00e9es","title":"Exploitation des donn\u00e9es"},{"location":"TECHNIQUE/LOGICIEL/importation.html#import-des-elements-lies-au-contact","text":"Le parsage cr\u00e9e des objets de type Uepal\\CiviImport\\ParsedContact. Pour importer les \u00e9l\u00e9ments, il faut d'abord commencer par identifier les entit\u00e9s cibles de CiviCRM : le contact : on aura un contact par ligne. Les attributs qui seront stock\u00e9s sont les suivants : protected function computeContactParams(): array { $cfUtils = CRM_Civiparoisse_Utils_CustomFields::getSingleton(); $parsedContact = $this->getCompositeImportData()->getParsedContact(); $candidates = [\"prefix_id:label\" => $parsedContact->getCivilite(), \"gender_id:name\" => $this->computeContactGenderName($parsedContact), \"contact_type:name\" => \"Individual\", \"last_name\" => $parsedContact->getNom(), $cfUtils->getFieldNameId(\"nom_naissance\") => $parsedContact->getNomNaissan ce(), \"first_name\" => $parsedContact->getPrenom(), \"birth_date\" => CRM_Civiparoisse_Utils_DateFormatter::formatDate($parsedCo ntact->getDateNaissance()), $cfUtils->getFieldNameId(\"lieu_naissance\") => $parsedContact->getLieuNaissance(), 'household_name' => $parsedContact->getFoyerAppartenance()]; $candidates = array_filter($candidates); return ['values' => $candidates]; } le t\u00e9l\u00e9phone mobile : protected function computeMobilePhoneParams(): array { return ['values' => ['location_type:name' => 'Accueil', 'phone_type_id:name' => 'Mobile', 'contact_id' => $this->getCompositeImportData()->getContactId(), 'phone' => $this->getCompositeImportData()->getParsedContact()->getTelephonePortable(), 'is_primary' => 1]]; } le t\u00e9l\u00e9phone professionnel appel\u00e9 auparavant \"autre\" protected function computeOtherPhoneParams(): array { return ['values' => ['location_type:name' => 'Travail', 'phone_type_id:name' => 'Phone', 'contact_id' => $this->getCompositeImportData()->getContactId(), 'phone' => $this->getCompositeImportData()->getParsedContact()->getTelephoneAutre(), 'is_primary' => 0]]; } le mail priv\u00e9 : protected function computeEmailPriveParam() : array { return ['values' => ['email' => $this->getCompositeImportData()->getParsedContact()->getEmailPrive(), 'contact_id' => $this->getCompositeImportData()->getContactId(), 'location_type:name' => 'Accueil', 'is_primary' => TRUE]]; } le mail professionnel : protected function computeEmailAutreParam() : array { return ['values' => ['email' => $this->getCompositeImportData()->getParsedContact()->getEmailAutre(), 'contact_id' => $this->getCompositeImportData()->getContactId(), 'location_type_id:name' => 'Travail', 'is_primary' => 0 ]]; } * la note compl\u00e9mentaire : protected function computeNoteDiversParam(): array { return ['values' => [ 'note' => $this->getCompositeImportData()->getParsedContact()->getDivers(), 'entity_table:name' => 'Contact', 'entity_id' => $this->getCompositeImportData()->getContactId(), 'contact_id' =>CRM_Core_Session::getLoggedInContactID(), 'subject' => 'Note import' ]]; }","title":"Import des \u00e9l\u00e9ments li\u00e9s au Contact"},{"location":"TECHNIQUE/LOGICIEL/importation.html#import-des-elements-lies-au-foyer","text":"le foyer : un foyer sera constitu\u00e9 par un nom de foyer, une adresse, et un num\u00e9ro de t\u00e9l\u00e9phone fixe. Toute alt\u00e9ration d'un des champs conduira \u00e0 un nouveau foyer ; on se souviendra que le foyer est un type de contact. Le foyer est consid\u00e9r\u00e9 comme une unit\u00e9 familiale (parents et \u00e9ventuellement enfants). protected function computeHouseholdParams(): array { return ['values' => [ 'contact_type' => 'Household', 'display_name' => $this->getCompositeImportData()->getParsedContact()->getFoyerAppartenance(), 'household_name' => $this->getCompositeImportData()->getParsedContact()->getFoyerAppartenance() ]]; } l'adresse : l'adresse sera rattach\u00e9e au foyer. Du fait de la construction du fichier, il serait difficile de faire les s\u00e9parations fines des constituants de l'adresse pour les faire rentrer exactement dans les champs de civicrm. On utilise donc les lignes d'adresse supl\u00e9mentaire pour le stockage. protected function computeAddressParams(): array { return ['values' => ['street_address' => $this->getCompositeImportData()->getParsedContact()->getAdresseLigne1(), 'supplemental_address_1' => $this->getCompositeImportData()->getParsedContact()->getAdresseLigne2(), 'supplemental_address_2' => $this->getCompositeImportData()->getParsedContact()->getAdresseLigne3(), 'postal_code' => $this->getCompositeImportData()->getParsedContact()->getCodePostal(), 'city' => $this->getCompositeImportData()->getParsedContact()->getVille(), 'country_id:label' => $this->getCompositeImportData()->getParsedContact()->getPays(), 'contact_id' => $this->getCompositeImportData()->getFoyerId(), 'is_primary' => TRUE, 'location_type_id:name' => 'Accueil']]; } Bug Pour l'adresse il faut rajouter une variable location_type 'location_type_id' => 1, // 1 = domicile, 2 = travail, 3 \u00e0 5 pas utilis\u00e9s dans notre projet le num\u00e9ro de t\u00e9l\u00e9phone fixe : chaque num\u00e9ro est une entit\u00e9 distincte. Le num\u00e9ro fixe est reli\u00e9 au foyer, tandis que le num\u00e9ro mobile et le num\u00e9ro autre est reli\u00e9 au contact. La distinction entre les num\u00e9ros de t\u00e9l\u00e9phones se fait via le champ location_type_id et phone_type_id (\u00e0 v\u00e9rifier : les valeurs de location_type que l'on souhaite utiliser): protected function computePhoneParams(): array { return ['values' => [ 'contact_id' => $this->getCompositeImportData()->getFoyerId(), 'phone' => $this->getCompositeImportData()->getParsedContact()->getTelephoneFixe(), 'location_type_id:name' => 'Accueil', 'phone_type_id:name' => 'Phone', 'is_primary' => 1 ]]; } Bug Pour les t\u00e9l\u00e9phones, il faut g\u00e9rer deux variables 'location_type_id' => 1, // 1 = domicile, 2 = travail, 3 \u00e0 5 pas utilis\u00e9s dans notre projet 'phone_type_id' => 2, // 1= fixe, 2 = portable, 3 = fax, 4 et 5 pas utilis\u00e9s dans notre projet Bug CAUTION : je ne suis pas s\u00fbr que ce soit les bonnes valeurs du location_type les emails : chaque email constitue \u00e9galement une entit\u00e9 distincte, \u00e9galement reli\u00e9e au contact, et on utilise \u00e9galement le location_type pour distinguer les emails : Bug Pour les mails, je ne suis pas s\u00fbr que les valeurs location_type ci-dessous soient les bonnes 'location_type_id' => 1, // 1 = domicile, 2 = travail, 3 \u00e0 5 pas utilis\u00e9s dans notre projet","title":"Import des \u00e9l\u00e9ments li\u00e9s au foyer"},{"location":"TECHNIQUE/LOGICIEL/importation.html#la-liaison-entre-les-contacts-individuels-et-les-adresses","text":"Il s'agit ici de cr\u00e9er des adresses pour chaque contact individuel : ces adresses vont \u00eatre rattach\u00e9es aux adresses du foyer. protected function computeContactAddrWorkload() : array { return ['values'=>[ 'contact_id'=>$this->getCompositeData()->getContactId(), 'master_id'=>$this->getCompositeData()->getFoyerAddrId() ]]; }","title":"La liaison entre les contacts individuels et les adresses"},{"location":"TECHNIQUE/LOGICIEL/importation.html#les-relations-entre-les-contacts-foyers-et-le-membership","text":"relation membre de foyer : il s'agi de mat\u00e9rialiser le fait qu'un contact fasse parti d'un foyer. protected function computeMemberOfHouseholdParams(int $ord): array { return ['values' => ['relationship_type_id:name' => 'Household Member of', 'contact_id_a' => $this->getCompositeImportData($ord)->getContactId(), 'contact_id_b' => $this->getCompositeImportData($ord)->getFoyerId()]]; } relation adulte : il s'agit en fait des \"chefs de famille\" - chefs de foyers. Le fait d'activer la case \u00e0 cocher indique qu'il faut g\u00e9n\u00e9rer une relation chef de famille vers le foyer protected function computeHeadOfHouseholdParams(int $ord): array { $compositeImportData = $this->getCompositeImportData($ord); return ['values' => ['relationship_type_id:name' => 'Head of Household for', 'contact_id_a' => $compositeImportData->getContactId(), 'contact_id_b' => $compositeImportData->getFoyerId()]]; } membre \u00e9lecteur : il s'agit d'un type de membership vers l'organisation de la paroisse ; ce membership est mis en oeuvre du moment que Electeur est activ\u00e9. protected function computeElecteurParams(int $ord): array { return ['values' => ['membership_type_id.name' => 'Electeur\u00b7trice', 'contact_id' => $this->getCompositeImportData($ord)->getContactId()]]; } relation conjoint : On effectue une liaison en v\u00e9rifiant nom et pr\u00e9nom ; on privil\u00e9giera le fait de faire parti d'un m\u00eame foyer pour la s\u00e9lection du conjoint. Le type de relation lui-m\u00eame d\u00e9pendra du nom du foyer, car le nom du foyer refl\u00e8te le mariage ou la libre union. protected function computeSpouseParams(int $ord): array { $spouseId = $this->retrieveSpouseId($ord); $contactId = $this->getCompositeImportData($ord)->getContactId(); $relationship = $this->computeSpouseRelationTypeName($ord); return ['values' => ['relationship_type_id:name' => $relationship, 'contact_id_a' => $contactId, 'contact_id_b' => $spouseId]]; } relation parent : la relation de parents indique le nom des deux parents. On distingue le fait que les parents soit mari\u00e9s ou non pour calculer le nom individuel recherch\u00e9 de chaque parent. Le parent est cherch\u00e9 en priorit\u00e9 dans le foyer, et ensuite dans l'ensemble des contacts. protected function computeParentParam(int $ord, int $parentId): array { $contactId = $this->getCompositeImportData($ord)->getContactId(); return ['values' => ['relationship_type_id:name' => 'Child of', 'contact_id_a' => $contactId, 'contact_id_b' => $parentId]]; } membre enfant inscrit: un enfant est uniquement membre du foyer, marqu\u00e9 comme enfant,non marqu\u00e9 comme \u00e9lecteur et n'\u00e9tant pas majeur. protected function computeEnfantInscritParam(int $ord): array { return ['values' => ['membership_type_id.name' => 'Inscrit\u00b7e Enfant', 'contact_id' => $this->getCompositeImportData($ord)->getContactId()]]; } relation de fratrie : la relation de fratrie est uniquement activ\u00e9 lorsque les deux parents sont les m\u00eames. protected function computeFratrieParam(int $ord,int $fratrieId) : array { $contactId = $this->getCompositeImportData($ord)->getContactId(); return ['values' => ['relationship_type_id:name' => 'Sibling of', 'contact_id_a' => $contactId, 'contact_id_b' => $fratrieId]]; }","title":"Les relations entre les contacts, foyers, et le membership"},{"location":"TECHNIQUE/LOGICIEL/importation.html#guidelines-pour-limport","text":"Le but est ici uniquement de g\u00e9rer un import initial. Toutefois, si les donn\u00e9es de diff\u00e9rents lots sont enti\u00e8rement disjointes, on peut envisager des imports successifs \u00e0 partir de plusieurs fichiers - m\u00eame s'il faut garder \u00e0 l'esprit que le d\u00e9veloppement n'a pas \u00e9t\u00e9 pr\u00e9vu pour \u00e7a.","title":"Guidelines pour l'import"},{"location":"TECHNIQUE/LOGICIEL/importation.html#outillage-limage-tools","text":"La proc\u00e9dure d'import est pr\u00e9vue pour \u00eatre lanc\u00e9e depuis la ligne de commande (outil cv). De ce fait, on utilisera l'image des outils pour acc\u00e9der au n\u00e9cessaire, en effectuant les montages requis (en particulier montage des fichiers, et montage du point d'acc\u00e8s \u00e0 la BD). Le fichier lui-m\u00eame pourra \u00eatre \u00e9galement mont\u00e9 dans l'image, ou copi\u00e9 dans le container lors de l'ex\u00e9cution (par exemple via docker cp ).","title":"Outillage : l'image tools"},{"location":"TECHNIQUE/LOGICIEL/importation.html#parsage","text":"Avant de lancer l'import proprement dit, il faut v\u00e9rifier si le parsage se fait correctement. Il est en effet arriv\u00e9 lors des tests qu'un fichier au format xlsx modifi\u00e9 par LibreOffice a pos\u00e9 probl\u00e8me lors du parsage (mauvaise consid\u00e9ration de la derni\u00e8re ligne renseign\u00e9e). Dans ce genre de cas, on privil\u00e9giera des enregistrements dans des formats natifs (ods, xlsx) du moment que les formats sont support\u00e9s par phpspreadsheet. #!/bin/bash #export PHP_IDE_CONFIG=\"serverName=civicrm.test\" export CIVIPAROISSE_IMPORT_FILEPATH = \"/app/test2.ods\" export CIVIPAROISSE_IMPORT_SHEETNAME = \"Feuil1\" cv ev 'var_dump(CRM_Civiparoisse_Import_Importer::parse(new Uepal\\CiviImport\\MiniLogger()))' Le parseur est pr\u00e9vu pour utiliser un logger sp\u00e9cifi\u00e9 en param\u00e8tre. Trois loggers sont notamment \u00e0 consid\u00e9rer : le MiniLogger : new Uepal\\CiviImport\\MiniLogger()) : ce logger est inclus dans le code du parseur, et il utilise le error_log de PHP pour logguer les messages le Logger de Civicrm ( CRM_Core_Error_Log ) : l'acc\u00e8s \u00e0 ce Logger suppose la pr\u00e9sence de CiviCRM. Un helper a \u00e9t\u00e9 pr\u00e9par\u00e9 pour acc\u00e9der \u00e0 ce logger : CRM_Civiparoisse_Utils_Logger::getLogger : /** * General Purpose CiviCRM logger (psr_log) * @return LoggerInterface */ public static function getLogger(): LoggerInterface { return (Container::singleton()->get('psr_log')); } le Logger pr\u00e9sent dans \\Psr\\Log\\NullLogger : ce logger fait parti du package Composer psr/log, et fait partie des d\u00e9pendances requises par le parseur. Son int\u00e9r\u00eat est qu'il ne fait rien, donc ne va pas effectuer des logs, et permet de garder une sortie \u00e9cran \"propre\" pour voir ce qui a \u00e9t\u00e9 pars\u00e9. A l'occasion des parsages, on fera en particulier attention si les dates correspondent, et si le nombre d'enregistrement est juste. Le parsage est fait en \"Best Effort\" : une valeur qui n'est pas valid\u00e9e par les contr\u00f4les du syst\u00e8me sera ignor\u00e9e.","title":"Parsage"},{"location":"TECHNIQUE/LOGICIEL/importation.html#importation","text":"L'importation est r\u00e9alis\u00e9e \u00e9galement en ligne de commande. #!/bin/bash #export PHP_IDE_CONFIG=\"serverName=civicrm.test\" export CIVIPAROISSE_IMPORT_FILEPATH = \"/app/test2.ods\" export CIVIPAROISSE_IMPORT_SHEETNAME = \"Feuil1\" cv ev -U drupaladmin 'CRM_Civiparoisse_Import_Importer::parseImport(CRM_Civiparoisse_Utils_Logger::getLogger())' Si on consid\u00e8re un syst\u00e8me fra\u00eechement install\u00e9, un moyen qui semble \u00eatre assez efficace pour effacer une importation est de supprimer l'ensemble des contacts dont l'ID est strictement sup\u00e9rieur \u00e0 2, en n'utilisant pas la corbeille (trash). Ceci peut \u00eatre r\u00e9alis\u00e9 depuis l'explorateur d'API v4, depuis les menus de CiviCRM. On peut v\u00e9rifier les r\u00e9sultats de l'importation de plusieurs mani\u00e8res : analyser l'ex\u00e9cution de l'import via Xdebug et un IDE analyser le contenu de la BD via MySQL analyser le contenu de la BD via des appels API analyser le contenu de la BD depuis l'interface web de civicrm","title":"Importation"},{"location":"TECHNIQUE/MAIL/ecosysteme.html","text":"Ecosyst\u00e8me des mails de masse Les mails de masse sont des outils de communication qui sont permis et support\u00e9s par un certain nombre de techniques compl\u00e9mentaires, dont une partie d\u00e9pend de l'int\u00e9gration technique de CiviCRM, et du p\u00e9rim\u00e8tre fonctionnel retenu dans le cadre du projet. Il est donc int\u00e9ressant de faire d'abord un \u00e9tat des lieux des fonctionnalit\u00e9s natives propos\u00e9es par CiviCRM, avant de voir l'usage souhait\u00e9 et les adaptations requises. Le natif existant Ciblage des destinataires : smart groups Il est important que le mail soit pertinent pour ses destinataires. De ce fait, on cherchera \u00e0 identifier ces personnes en se basant sur des crit\u00e8res se basant sur les donn\u00e9es stock\u00e9es dans CiviCRM. Pour identifier les destinataires, une possibilit\u00e9 est de cr\u00e9er des groupes, voire des groupes dynamiques (smart groups : https://docs.civicrm.org/user/fr/latest/organising-your-data/smart-groups/ ). L'int\u00e9r\u00eat des groupes dynamiques est que l'on peut recalculer les destinataires, et ainsi mettre \u00e0 jour les destinataires. Contenu textuel du mail de masse : personnalisation Le mail de masse est envoy\u00e9 \u00e0 un grand nombre de personnes, ce qui est une forme de communication diff\u00e9rente que les communications d'une personne \u00e0 une unique autre ; ce sujet peut donc n\u00e9cessiter une formation sp\u00e9cifique. M\u00eame si le mail de masse s'adresse \u00e0 un grand nombre, un certain degr\u00e9 de personnalisation du mail peut aider \u00e0 renforcer l'int\u00e9r\u00eat du destinataire pour le mail. A cet effet, CiviCRM pr\u00e9voit un m\u00e9canisme de tokens pour injecter des donn\u00e9es personnalis\u00e9es dans les mails. On retrouve par exemple des donn\u00e9es sur l'instance CiviCRM elle-m\u00eame, mais \u00e9galement des donn\u00e9es relatives au contact (par exemple, nom, pr\u00e9nom...). M\u00eame si la personnalisation cherche \u00e0 renforcer le lien avec l'utilisateur, il ne faut pas oublier que les mails circulent la plupart du temps dans un format d\u00e9chiffrable au niveau d'un noeud de transport (notamment MTA ou MDA). On peut donc supposer qu'il est pr\u00e9f\u00e9rable de ne pas inclure des donn\u00e9es sensibles dans les mails. Toutefois, il est \u00e0 remarquer que des donn\u00e9es sensibles peuvent parfois \u00eatre d\u00e9duites du fait de l'envoi d'un mail sur un sujet particulier... Mise en forme de mails de masse Les mails sont g\u00e9n\u00e9ralement transmissibles au niveau des mails de masse de CiviCRM peuvent \u00eatre sous deux formes : texte brut : dans ce mode, seul, \u00e9ventuellement, des \u00e9l\u00e9ments comme les retours \u00e0 la ligne et l'ascii-art peuvent intervenir dans la mise en forme au niveau de l'exp\u00e9diteur. Ce mode d'envoi \u00e0 l'int\u00e9r\u00eat d'\u00eatre tr\u00e8s simple, tr\u00e8s l\u00e9ger, et permet de se concentrer sur le contenu r\u00e9dactionnel, et devrait \u00eatre utilisable dans la plupart des clients mails. Toutefois, le texte brut pr\u00e9sente l'inconv\u00e9nient de ne pas v\u00e9hiculer facilement des \u00e9l\u00e9ments significatifs relatifs \u00e0 l'identit\u00e9 num\u00e9rique d'une entit\u00e9 (logo/images, charte graphique), et ne fournit pas nativement de liens vers des \u00e9l\u00e9ments ext\u00e9rieurs qui sont utilisables par exemple pour les statistiques des mails format html : gr\u00e2ce aux liens vers des \u00e9l\u00e9ments externes, on peut incorporer au mail des images, on peut v\u00e9hiculer dans une certaine mesure une charte graphique via des styles CSS, on peut tenter d'obtenir des statistiques d'ouverture des mails, voire m\u00eame de d\u00e9terminer les \u00e9l\u00e9ments qui ont d\u00e9clench\u00e9 le plus de clics utilisateurs dans le mail. Toutefois, le format html est difficile \u00e0 mettre en oeuvre, notamment en raison des diff\u00e9rences plus que notables de pr\u00e9sentation des mails en fonction des clients mails utilis\u00e9s (clients lourds, interface webmail, interface en mode texte pour ne citer qu'eux). Ces diff\u00e9rences ont conduit \u00e0 l'adoption de pratiques particuli\u00e8res pour chercher \u00e0 obtenir un rendu acceptable pour le plus grand nombre. On trouve des conseils sur des sites d'acteurs sp\u00e9cialis\u00e9s comme : https://www.caniemail.com/ : Can I email : ce site est le pendant pour les mails de https://caniuse.com/ , et pr\u00e9sente la compatibilit\u00e9 de techniques par rapport aux clients mails https://www.litmus.com/resources/ : Litmus https://www.emailonacid.com/white-papers/ : Email on Acid https://www.sarbacane.com/email-marketing/comment-faire : Sarbacane (peut proposer des prestations de formation) https://mosaico.io/ : Mosaico : logiciel d'interface utilisateur pour simplifier la mise en forme des mails, en partant de mod\u00e8les (templates) pr\u00e9con\u00e7us https://www.phplist.org/manual/books/phplist-manual/page/targeting-your-campaigns : phpList : choix des destinataires En ce qui concerne la mise en forme HTML, en plus de la litt\u00e9rature qui d\u00e9crit les pratiques employ\u00e9es par certains professionnels, on peut constater qu'il existerait des outils CSS sp\u00e9cialis\u00e9s, tels que : https://bootstrapemail.com/ https://get.foundation/emails.html : Framework foundation pour les mails Etant donn\u00e9 la difficult\u00e9 de cr\u00e9er des mails adapt\u00e9s ex nihilo, il semble judicieux de partir d'un template (soit un fourni par Mosaico, soit un qui sera cr\u00e9e \u00e0 partir d'un framework CSS pour les mails) que l'on int\u00e8grera \u00e0 Mosaico. Le passage par Mosaico permet de fournir une interface utilisateur simplifi\u00e9e qui permet \u00e0 l'utilisateur de ne pas avoir \u00e0 \u00e9crire directement du HTML si ce n'est pas ce qu'il souhaite faire. Si un utilisateur souhaite \u00e9crire du code HTML, l'interface lui en laisse toutefois la possibilit\u00e9. L'utilisation de ces outils n'est toutefois pas un gage de r\u00e9ussite, car le sujet reste malgr\u00e9 tout complexe. Il est \u00e0 noter que les templates CiviCRM et Mosaico sont diff\u00e9rents : les templates CiviCRM peuvent contenir trois sections (header, body, footer), tandis que les templates Mosaico forcent le header et footer \u00e0 null, pour tout travailler au niveau du body. Int\u00e9gration d'images L'int\u00e9gration d'images dans un mail devra tr\u00e8s probablement passer par le stockage des fichiers images sur un serveur de m\u00e9dias, accessible sans authentification. Un type d'images un peu particulier que l'on trouve dans certains mails est l'image d'un pixel transparent : l'int\u00e9r\u00eat de cette image est que si son URL est param\u00e9tr\u00e9e et personnalis\u00e9e dans chaque mail, on peut obtenir des estimations sur le nombre d'ouvertures du mail. Au niveau de CiviCRM, on peut sp\u00e9cifier un r\u00e9pertoire pour les fichiers d'images, ainsi qu'une URL sp\u00e9cifique. Toutefois, on a tout int\u00e9r\u00eat \u00e0 d\u00e9finir ces indications d\u00e8s l'installation, et on a int\u00e9r\u00eat \u00e0 passer ce serveur en HTTPS, en raison de l'acc\u00e8s \u00e0 CiviCRM qui devra se faire depuis HTTPS - sans quoi les navigateurs refuseront de charger les ressources. Etant donn\u00e9 que CiviCRM v\u00e9rifie qu'il a le droit d'acc\u00e9der au r\u00e9pertoire des images en \u00e9criture, et que l'int\u00e9gration des images concerne bien plus que les images de la gallerie de Mosaico, il est improbable de pouvoir rajouter simplement des images venant d'un serveur distant. Si l'on souhaite int\u00e9grer des images venant de serveur tiers, il faudra int\u00e9grer manuellement les images via du code HTML. Toutefois, on peut comprendre l'approche de consid\u00e9rer que les images sont stock\u00e9es sur le serveur local : en effet, les images peuvent \u00eatre redimenssionn\u00e9es par rapport \u00e0 leur taille d'utilisation, en tenant compte d'\u00e9lements tels que la configuration li\u00e9e aux \u00e9crans de type Retina, qui demandent des r\u00e9solutions plus \u00e9lev\u00e9es. URLs relatives aux mails On retrouve plusieurs types d'URLs qui vont avoir trait aux mails : url vers un pixel transparent pour les statistiques urls d'action (unsubscribe, optout,resubscribe, welcome...) url de ressources tierces (images notamment) urls de redirection vers des contenus (avec comptabilisation des actions) Certaines de ces URL vont avoir des \u00e9l\u00e9ments sp\u00e9cifiques dans leur query string : des checksums et des informations sur des envent_queue. mysql > describe civicrm_mailing_event_queue ; + ------------+--------------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | + ------------+--------------+------+-----+---------+----------------+ | id | int unsigned | NO | PRI | NULL | auto_increment | | job_id | int unsigned | NO | MUL | NULL | | | email_id | int unsigned | YES | MUL | NULL | | | contact_id | int unsigned | NO | MUL | NULL | | | hash | varchar ( 255 ) | NO | MUL | NULL | | | phone_id | int unsigned | YES | MUL | NULL | | + ------------+--------------+------+-----+---------+----------------+ 6 rows in set ( 0 . 02 sec ) Sommes de contr\u00f4le On retrouve plusieurs types de sommes de contr\u00f4le, qui sont li\u00e9s \u00e0 des \"hashs\". M\u00eame si les valeurs sont appel\u00e9es hashs, ce ne sont pas forc\u00e9ment des hashs, plut\u00f4t des valeurs plus ou moins al\u00e9atoires. Un but de ces sommes de contr\u00f4le est de se prot\u00e9ger dans une certaine mesure de la forge d'URLs. hash sur un contact : ce champ peut \u00eatre utilis\u00e9 dans le cadre d'un checksum, dans la cr\u00e9ation d'une signature \"fa\u00e7on HMAC\", qui inclut en particulier le hash (secret), l'id du contact, l'heure de signature, et la dur\u00e9e de validit\u00e9 du checksum. Le hash \u00e9tant secret, et les autres valeurs \u00e9tant donn\u00e9es dans la query string, il est possible de recalculer le hash et de v\u00e9rifier si les champs entrant en jeu dans la signature ont \u00e9t\u00e9 alt\u00e9r\u00e9s hash sur un mailing : ce champ est parfois rajout\u00e9 directement dans une URL pour confirmer/remplacer l'identit\u00e9 du mailing que l'on souhaite acc\u00e9der : le hash \u00e9tant une valeur al\u00e9atoire, il y a certes un risque de collision, mais cette mani\u00e8re de faire permet d'\u00e9viter de pouvoir boucler sur des mails hash sur un event queue : il incluerait le job_id, le contact_id et l'email_id, auquel on concat\u00e8ne le temps (fonction time()). Etant donn\u00e9 que le temps n'est pas sauvegard\u00e9, on ne peut pas recalculer cette somme de contr\u00f4le. On peut en revanche v\u00e9rifier selon le stockage si c'est bien la valeur attendue, de mani\u00e8re analogue au hash de mailing. On constate donc qu'un champ de m\u00eame nom peut \u00eatre utilis\u00e9 diff\u00e9remment en fonctions des tables. C'est un \u00e9l\u00e9ment quelque peu d\u00e9routant. Informations sur l'acc\u00e8s au contenu li\u00e9 CiviCRM dispose nativement de la possibilit\u00e9 de remplacer des URL d'\u00e9l\u00e9ments par des redirections g\u00e9n\u00e9r\u00e9es et stock\u00e9es en local. L'int\u00e9r\u00eat de cette technique est que l'on peut ainsi obtenir une sorte de retour sur les \u00e9l\u00e9ments qui fonctionnent dans un mail. mysql > describe civicrm_mailing_trackable_url ; + ------------+--------------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | + ------------+--------------+------+-----+---------+----------------+ | id | int unsigned | NO | PRI | NULL | auto_increment | | url | text | NO | | NULL | | | mailing_id | int unsigned | NO | MUL | NULL | | + ------------+--------------+------+-----+---------+----------------+ 3 rows in set ( 0 . 01 sec ) mysql > describe civicrm_mailing_event_trackable_url_open ; + ------------------+--------------+------+-----+-------------------+-------------------+ | Field | Type | Null | Key | Default | Extra | + ------------------+--------------+------+-----+-------------------+-------------------+ | id | int unsigned | NO | PRI | NULL | auto_increment | | event_queue_id | int unsigned | NO | MUL | NULL | | | trackable_url_id | int unsigned | NO | MUL | NULL | | | time_stamp | timestamp | NO | | CURRENT_TIMESTAMP | DEFAULT_GENERATED | + ------------------+--------------+------+-----+-------------------+-------------------+ 4 rows in set ( 0 . 01 sec ) Mailing automation Le mailing automation est une fonctionnalit\u00e9 qui permet de d\u00e9clencher des mails (r\u00e9ponses \u00e0 des \u00e9v\u00e8nements). La source de l'\u00e9v\u00e8nement peut \u00eatre un mail de retour avec des champs VERP, ou la consultation d'une URL sp\u00e9cifique. CiviCRM peut alors envoyer un mail particulier en r\u00e9ponse \u00e0 l'\u00e9v\u00e8nement, en fonction de sa configuration. Des templates sp\u00e9cifiques sont pr\u00e9vus en fonction des cas. Dans CRM_Core_SelectValues : public static function mailingComponents() { return [ 'Header' => ts('Header'), 'Footer' => ts('Footer'), 'Reply' => ts('Reply Auto-responder'), 'OptOut' => ts('Opt-out Message'), 'Subscribe' => ts('Subscription Confirmation Request'), 'Welcome' => ts('Welcome Message'), 'Unsubscribe' => ts('Unsubscribe Message'), 'Resubscribe' => ts('Resubscribe Message'), ]; } Et \u00e9galement dans CRM_Core_SelectValues : public static function mailingTokens() { return [ '{action.unsubscribe}' => ts('Unsubscribe via email'), '{action.unsubscribeUrl}' => ts('Unsubscribe via web page'), '{action.resubscribe}' => ts('Resubscribe via email'), '{action.resubscribeUrl}' => ts('Resubscribe via web page'), '{action.optOut}' => ts('Opt out via email'), '{action.optOutUrl}' => ts('Opt out via web page'), '{action.forward}' => ts('Forward this email (link)'), '{action.reply}' => ts('Reply to this email (link)'), '{action.subscribeUrl}' => ts('Subscribe via web page'), '{mailing.key}' => ts('Mailing key'), '{mailing.name}' => ts('Mailing name'), '{mailing.group}' => ts('Mailing group'), '{mailing.viewUrl}' => ts('Mailing permalink'), ] + self::domainTokens(); } L'usage et les adaptations pour Civiparoisse Une caract\u00e9ristique fondamentale de Civiparoisse est que l'ensemble des acc\u00e8s au coeur du syst\u00e8me sont authentifi\u00e9s. Cette caract\u00e9ristique doit perdurer pour que le syst\u00e8me reste conceptuellement simple. Or, on constate que les interactions entre les mails et l'environnement sont potentiellement fortes, ce qui complique les choses. Des compromis doivent donc \u00eatre trouv\u00e9s. L'usage sp\u00e9cifique des mails de masse La mise en oeuvres de mails de masse est diff\u00e9rente des mails envoy\u00e9s de personne \u00e0 personne, et de ce fait, on peut supposer qu'une formation sp\u00e9cifique soit prodigu\u00e9e aux utilisateurs. Les mails g\u00e9n\u00e9r\u00e9s : multipart/alternative, avec text/html et text/plain Mosaico semble fournir un int\u00e9r\u00eat pour la mise en oeuvre des mails, car il limite les risques de casse involontaire des mails. Il semble donc int\u00e9ressant de privil\u00e9gier l'utilisation de cet outil. Les mails qui sont g\u00e9n\u00e9r\u00e9s par le syst\u00e8me sont d\u00e9j\u00e0 pr\u00e9vus pour \u00eatre \u00e0 la fois en html et en text/plain. De son c\u00f4t\u00e9, un Mail User Agent va privil\u00e9gier l'affichage d'un seul rendu (celui qu'il est sens\u00e9 comprendre, de plus grande pr\u00e9f\u00e9rence), et l'utilisateur n'est pas forc\u00e9ment au courant qu'il dispose dans le mail de plusieurs versions du contenu, dont une en texte brut. Au lieu de faire un lien vers une page web, il serait plus int\u00e9ressant de faire remarquer \u00e0 l'utilisateur que s'il a du mal \u00e0 lire le mail, qu'il cherche \u00e0 changer de source de message, ou d'afficher la source du mail (puisqu'une version est du texte brut). En revanche, il conviendra \u00e9ventuellement de laisser l'utilisateur pr\u00e9parer manuellement la version textuelle du mail, car cette version simplifi\u00e9e ne correspond pas forc\u00e9ment \u00e0 la version graphique, pour que le mail reste le plus lisible possible. On devra donc adapter les interfaces de l'adaptateur de mosaico \u00e0 cet effet. Les images : stock\u00e9es sur un serveur tiers La philosophie de l'adaptateur de Mosaico est de stocker les images sur le serveur local, en g\u00e9n\u00e9rant des versions \u00e0 des tailles adapt\u00e9es aux mails g\u00e9n\u00e9r\u00e9s. On comprend donc l'int\u00e9r\u00eat de ce fonctionnement, mais il ne peut pas s'appliquer dans Civiparoisse. La meilleure solution est de stocker les images sur un serveur tiers, et de d\u00e9velopper un bloc Mosaico pour cet usage, en sensibilisant les utilisateurs aux probl\u00e9matiques relatives aux images, de sorte \u00e0 ce qu'ils optimisent eux-m\u00eames les m\u00e9dias qu'ils souhaitent utiliser. Tracking Le tracking propos\u00e9 par CiviCRM est certes utilis\u00e9 dans le monde de l'entreprise, mais il est fait d'une mani\u00e8re quelque peu cach\u00e9e, qui est au minimum questionnable dans le cadre d'une paroisse et de ses valeurs. Il semble donc peu appropri\u00e9 d'utiliser le tracking d'ouverture du mail tel que propos\u00e9 nativement, et encore moins le tracking de contenu. Toutefois, des statistiques d'utilisation semblent \u00eatre les bienvenues. On se souviendra \u00e0 cette fin qu'il existe le syst\u00e8me appel\u00e9 Message Disposition Notification RFC 8098 , qui peut demander des notifications par rapport au suivi du mail. Un tel retour sera probablement faible, mais il aura l'avantage d'\u00eatre plus transparent par rapport \u00e0 l'utilisateur, et pourra \u00e9ventuellement m\u00eame fournir des informations sur les Mail User Agent utilis\u00e9s. Il faudra donc impl\u00e9menter la demande de notifications MDN. Mail automation Le mail automation permet surtout de g\u00e9n\u00e9rer une r\u00e9action suite \u00e0 un clic de lien ou \u00e0 la r\u00e9ception d'un mail ( adresse avec VERP). Pour fournir la fonctionnalit\u00e9, il semble faisable d'utiliser des liens mailto, tel que d\u00e9crit dans RFC 6068 . Cette RFC pr\u00e9cise d'ailleurs dans son point 4 qu'on ne peut que supposer que l'utilisation des champs subject et body sera disponible. Toutefois, ceci suffit d\u00e9j\u00e0 pour inclure des informations dans l'un ou l'autre champ, de mani\u00e8re assez analogue \u00e0 ce que l'on fait pour les liens que l'on inclut dans les mails. Si les informations comme les sommes de contr\u00f4le sont transmises, il devient alors possible de les v\u00e9rifier (\u00e9ventuellement via des formulaires \u00e0 d\u00e9velopper) avant qu'un utilisateur de Civiparoisse effectue les actions demand\u00e9es par un tiers. Dans le cadre de cette fonctionnalit\u00e9, il faudrait donc d\u00e9velopper deux cat\u00e9gories d'\u00e9l\u00e9ments : la g\u00e9n\u00e9ration des URL mailto ad\u00e9quates les formulaires (admin) de v\u00e9rification des donn\u00e9es El\u00e9ments hypoth\u00e9tiquement utiles pour le futur Deux types d'\u00e9l\u00e9ments pourraient \u00eatre int\u00e9ressants pour le futur : la possibilit\u00e9 d'utiliser SMIME pour chiffrer les messages envoy\u00e9s, en utilisant la clef publique du destinataire la possibilit\u00e9 d'utiliser SMIME pour signer les messages envoy\u00e9s, pour que les destinataires puissent v\u00e9rifier l'authenticit\u00e9 des messages. Ces deux \u00e9l\u00e9ments supposent toutefois des connaissances et une sensibilisation pouss\u00e9es dont ne disposent pas actuellement la plupart des utilisateurs.","title":"Ecosyst\u00e8me"},{"location":"TECHNIQUE/MAIL/ecosysteme.html#ecosysteme-des-mails-de-masse","text":"Les mails de masse sont des outils de communication qui sont permis et support\u00e9s par un certain nombre de techniques compl\u00e9mentaires, dont une partie d\u00e9pend de l'int\u00e9gration technique de CiviCRM, et du p\u00e9rim\u00e8tre fonctionnel retenu dans le cadre du projet. Il est donc int\u00e9ressant de faire d'abord un \u00e9tat des lieux des fonctionnalit\u00e9s natives propos\u00e9es par CiviCRM, avant de voir l'usage souhait\u00e9 et les adaptations requises.","title":"Ecosyst\u00e8me des mails de masse"},{"location":"TECHNIQUE/MAIL/ecosysteme.html#le-natif-existant","text":"","title":"Le natif existant"},{"location":"TECHNIQUE/MAIL/ecosysteme.html#ciblage-des-destinataires-smart-groups","text":"Il est important que le mail soit pertinent pour ses destinataires. De ce fait, on cherchera \u00e0 identifier ces personnes en se basant sur des crit\u00e8res se basant sur les donn\u00e9es stock\u00e9es dans CiviCRM. Pour identifier les destinataires, une possibilit\u00e9 est de cr\u00e9er des groupes, voire des groupes dynamiques (smart groups : https://docs.civicrm.org/user/fr/latest/organising-your-data/smart-groups/ ). L'int\u00e9r\u00eat des groupes dynamiques est que l'on peut recalculer les destinataires, et ainsi mettre \u00e0 jour les destinataires.","title":"Ciblage des destinataires : smart groups"},{"location":"TECHNIQUE/MAIL/ecosysteme.html#contenu-textuel-du-mail-de-masse-personnalisation","text":"Le mail de masse est envoy\u00e9 \u00e0 un grand nombre de personnes, ce qui est une forme de communication diff\u00e9rente que les communications d'une personne \u00e0 une unique autre ; ce sujet peut donc n\u00e9cessiter une formation sp\u00e9cifique. M\u00eame si le mail de masse s'adresse \u00e0 un grand nombre, un certain degr\u00e9 de personnalisation du mail peut aider \u00e0 renforcer l'int\u00e9r\u00eat du destinataire pour le mail. A cet effet, CiviCRM pr\u00e9voit un m\u00e9canisme de tokens pour injecter des donn\u00e9es personnalis\u00e9es dans les mails. On retrouve par exemple des donn\u00e9es sur l'instance CiviCRM elle-m\u00eame, mais \u00e9galement des donn\u00e9es relatives au contact (par exemple, nom, pr\u00e9nom...). M\u00eame si la personnalisation cherche \u00e0 renforcer le lien avec l'utilisateur, il ne faut pas oublier que les mails circulent la plupart du temps dans un format d\u00e9chiffrable au niveau d'un noeud de transport (notamment MTA ou MDA). On peut donc supposer qu'il est pr\u00e9f\u00e9rable de ne pas inclure des donn\u00e9es sensibles dans les mails. Toutefois, il est \u00e0 remarquer que des donn\u00e9es sensibles peuvent parfois \u00eatre d\u00e9duites du fait de l'envoi d'un mail sur un sujet particulier...","title":"Contenu textuel du mail de masse : personnalisation"},{"location":"TECHNIQUE/MAIL/ecosysteme.html#mise-en-forme-de-mails-de-masse","text":"Les mails sont g\u00e9n\u00e9ralement transmissibles au niveau des mails de masse de CiviCRM peuvent \u00eatre sous deux formes : texte brut : dans ce mode, seul, \u00e9ventuellement, des \u00e9l\u00e9ments comme les retours \u00e0 la ligne et l'ascii-art peuvent intervenir dans la mise en forme au niveau de l'exp\u00e9diteur. Ce mode d'envoi \u00e0 l'int\u00e9r\u00eat d'\u00eatre tr\u00e8s simple, tr\u00e8s l\u00e9ger, et permet de se concentrer sur le contenu r\u00e9dactionnel, et devrait \u00eatre utilisable dans la plupart des clients mails. Toutefois, le texte brut pr\u00e9sente l'inconv\u00e9nient de ne pas v\u00e9hiculer facilement des \u00e9l\u00e9ments significatifs relatifs \u00e0 l'identit\u00e9 num\u00e9rique d'une entit\u00e9 (logo/images, charte graphique), et ne fournit pas nativement de liens vers des \u00e9l\u00e9ments ext\u00e9rieurs qui sont utilisables par exemple pour les statistiques des mails format html : gr\u00e2ce aux liens vers des \u00e9l\u00e9ments externes, on peut incorporer au mail des images, on peut v\u00e9hiculer dans une certaine mesure une charte graphique via des styles CSS, on peut tenter d'obtenir des statistiques d'ouverture des mails, voire m\u00eame de d\u00e9terminer les \u00e9l\u00e9ments qui ont d\u00e9clench\u00e9 le plus de clics utilisateurs dans le mail. Toutefois, le format html est difficile \u00e0 mettre en oeuvre, notamment en raison des diff\u00e9rences plus que notables de pr\u00e9sentation des mails en fonction des clients mails utilis\u00e9s (clients lourds, interface webmail, interface en mode texte pour ne citer qu'eux). Ces diff\u00e9rences ont conduit \u00e0 l'adoption de pratiques particuli\u00e8res pour chercher \u00e0 obtenir un rendu acceptable pour le plus grand nombre. On trouve des conseils sur des sites d'acteurs sp\u00e9cialis\u00e9s comme : https://www.caniemail.com/ : Can I email : ce site est le pendant pour les mails de https://caniuse.com/ , et pr\u00e9sente la compatibilit\u00e9 de techniques par rapport aux clients mails https://www.litmus.com/resources/ : Litmus https://www.emailonacid.com/white-papers/ : Email on Acid https://www.sarbacane.com/email-marketing/comment-faire : Sarbacane (peut proposer des prestations de formation) https://mosaico.io/ : Mosaico : logiciel d'interface utilisateur pour simplifier la mise en forme des mails, en partant de mod\u00e8les (templates) pr\u00e9con\u00e7us https://www.phplist.org/manual/books/phplist-manual/page/targeting-your-campaigns : phpList : choix des destinataires En ce qui concerne la mise en forme HTML, en plus de la litt\u00e9rature qui d\u00e9crit les pratiques employ\u00e9es par certains professionnels, on peut constater qu'il existerait des outils CSS sp\u00e9cialis\u00e9s, tels que : https://bootstrapemail.com/ https://get.foundation/emails.html : Framework foundation pour les mails Etant donn\u00e9 la difficult\u00e9 de cr\u00e9er des mails adapt\u00e9s ex nihilo, il semble judicieux de partir d'un template (soit un fourni par Mosaico, soit un qui sera cr\u00e9e \u00e0 partir d'un framework CSS pour les mails) que l'on int\u00e8grera \u00e0 Mosaico. Le passage par Mosaico permet de fournir une interface utilisateur simplifi\u00e9e qui permet \u00e0 l'utilisateur de ne pas avoir \u00e0 \u00e9crire directement du HTML si ce n'est pas ce qu'il souhaite faire. Si un utilisateur souhaite \u00e9crire du code HTML, l'interface lui en laisse toutefois la possibilit\u00e9. L'utilisation de ces outils n'est toutefois pas un gage de r\u00e9ussite, car le sujet reste malgr\u00e9 tout complexe. Il est \u00e0 noter que les templates CiviCRM et Mosaico sont diff\u00e9rents : les templates CiviCRM peuvent contenir trois sections (header, body, footer), tandis que les templates Mosaico forcent le header et footer \u00e0 null, pour tout travailler au niveau du body.","title":"Mise en forme de mails de masse"},{"location":"TECHNIQUE/MAIL/ecosysteme.html#integration-dimages","text":"L'int\u00e9gration d'images dans un mail devra tr\u00e8s probablement passer par le stockage des fichiers images sur un serveur de m\u00e9dias, accessible sans authentification. Un type d'images un peu particulier que l'on trouve dans certains mails est l'image d'un pixel transparent : l'int\u00e9r\u00eat de cette image est que si son URL est param\u00e9tr\u00e9e et personnalis\u00e9e dans chaque mail, on peut obtenir des estimations sur le nombre d'ouvertures du mail. Au niveau de CiviCRM, on peut sp\u00e9cifier un r\u00e9pertoire pour les fichiers d'images, ainsi qu'une URL sp\u00e9cifique. Toutefois, on a tout int\u00e9r\u00eat \u00e0 d\u00e9finir ces indications d\u00e8s l'installation, et on a int\u00e9r\u00eat \u00e0 passer ce serveur en HTTPS, en raison de l'acc\u00e8s \u00e0 CiviCRM qui devra se faire depuis HTTPS - sans quoi les navigateurs refuseront de charger les ressources. Etant donn\u00e9 que CiviCRM v\u00e9rifie qu'il a le droit d'acc\u00e9der au r\u00e9pertoire des images en \u00e9criture, et que l'int\u00e9gration des images concerne bien plus que les images de la gallerie de Mosaico, il est improbable de pouvoir rajouter simplement des images venant d'un serveur distant. Si l'on souhaite int\u00e9grer des images venant de serveur tiers, il faudra int\u00e9grer manuellement les images via du code HTML. Toutefois, on peut comprendre l'approche de consid\u00e9rer que les images sont stock\u00e9es sur le serveur local : en effet, les images peuvent \u00eatre redimenssionn\u00e9es par rapport \u00e0 leur taille d'utilisation, en tenant compte d'\u00e9lements tels que la configuration li\u00e9e aux \u00e9crans de type Retina, qui demandent des r\u00e9solutions plus \u00e9lev\u00e9es.","title":"Int\u00e9gration d'images"},{"location":"TECHNIQUE/MAIL/ecosysteme.html#urls-relatives-aux-mails","text":"On retrouve plusieurs types d'URLs qui vont avoir trait aux mails : url vers un pixel transparent pour les statistiques urls d'action (unsubscribe, optout,resubscribe, welcome...) url de ressources tierces (images notamment) urls de redirection vers des contenus (avec comptabilisation des actions) Certaines de ces URL vont avoir des \u00e9l\u00e9ments sp\u00e9cifiques dans leur query string : des checksums et des informations sur des envent_queue. mysql > describe civicrm_mailing_event_queue ; + ------------+--------------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | + ------------+--------------+------+-----+---------+----------------+ | id | int unsigned | NO | PRI | NULL | auto_increment | | job_id | int unsigned | NO | MUL | NULL | | | email_id | int unsigned | YES | MUL | NULL | | | contact_id | int unsigned | NO | MUL | NULL | | | hash | varchar ( 255 ) | NO | MUL | NULL | | | phone_id | int unsigned | YES | MUL | NULL | | + ------------+--------------+------+-----+---------+----------------+ 6 rows in set ( 0 . 02 sec )","title":"URLs relatives aux mails"},{"location":"TECHNIQUE/MAIL/ecosysteme.html#sommes-de-controle","text":"On retrouve plusieurs types de sommes de contr\u00f4le, qui sont li\u00e9s \u00e0 des \"hashs\". M\u00eame si les valeurs sont appel\u00e9es hashs, ce ne sont pas forc\u00e9ment des hashs, plut\u00f4t des valeurs plus ou moins al\u00e9atoires. Un but de ces sommes de contr\u00f4le est de se prot\u00e9ger dans une certaine mesure de la forge d'URLs. hash sur un contact : ce champ peut \u00eatre utilis\u00e9 dans le cadre d'un checksum, dans la cr\u00e9ation d'une signature \"fa\u00e7on HMAC\", qui inclut en particulier le hash (secret), l'id du contact, l'heure de signature, et la dur\u00e9e de validit\u00e9 du checksum. Le hash \u00e9tant secret, et les autres valeurs \u00e9tant donn\u00e9es dans la query string, il est possible de recalculer le hash et de v\u00e9rifier si les champs entrant en jeu dans la signature ont \u00e9t\u00e9 alt\u00e9r\u00e9s hash sur un mailing : ce champ est parfois rajout\u00e9 directement dans une URL pour confirmer/remplacer l'identit\u00e9 du mailing que l'on souhaite acc\u00e9der : le hash \u00e9tant une valeur al\u00e9atoire, il y a certes un risque de collision, mais cette mani\u00e8re de faire permet d'\u00e9viter de pouvoir boucler sur des mails hash sur un event queue : il incluerait le job_id, le contact_id et l'email_id, auquel on concat\u00e8ne le temps (fonction time()). Etant donn\u00e9 que le temps n'est pas sauvegard\u00e9, on ne peut pas recalculer cette somme de contr\u00f4le. On peut en revanche v\u00e9rifier selon le stockage si c'est bien la valeur attendue, de mani\u00e8re analogue au hash de mailing. On constate donc qu'un champ de m\u00eame nom peut \u00eatre utilis\u00e9 diff\u00e9remment en fonctions des tables. C'est un \u00e9l\u00e9ment quelque peu d\u00e9routant.","title":"Sommes de contr\u00f4le"},{"location":"TECHNIQUE/MAIL/ecosysteme.html#informations-sur-lacces-au-contenu-lie","text":"CiviCRM dispose nativement de la possibilit\u00e9 de remplacer des URL d'\u00e9l\u00e9ments par des redirections g\u00e9n\u00e9r\u00e9es et stock\u00e9es en local. L'int\u00e9r\u00eat de cette technique est que l'on peut ainsi obtenir une sorte de retour sur les \u00e9l\u00e9ments qui fonctionnent dans un mail. mysql > describe civicrm_mailing_trackable_url ; + ------------+--------------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | + ------------+--------------+------+-----+---------+----------------+ | id | int unsigned | NO | PRI | NULL | auto_increment | | url | text | NO | | NULL | | | mailing_id | int unsigned | NO | MUL | NULL | | + ------------+--------------+------+-----+---------+----------------+ 3 rows in set ( 0 . 01 sec ) mysql > describe civicrm_mailing_event_trackable_url_open ; + ------------------+--------------+------+-----+-------------------+-------------------+ | Field | Type | Null | Key | Default | Extra | + ------------------+--------------+------+-----+-------------------+-------------------+ | id | int unsigned | NO | PRI | NULL | auto_increment | | event_queue_id | int unsigned | NO | MUL | NULL | | | trackable_url_id | int unsigned | NO | MUL | NULL | | | time_stamp | timestamp | NO | | CURRENT_TIMESTAMP | DEFAULT_GENERATED | + ------------------+--------------+------+-----+-------------------+-------------------+ 4 rows in set ( 0 . 01 sec )","title":"Informations sur l'acc\u00e8s au contenu li\u00e9"},{"location":"TECHNIQUE/MAIL/ecosysteme.html#mailing-automation","text":"Le mailing automation est une fonctionnalit\u00e9 qui permet de d\u00e9clencher des mails (r\u00e9ponses \u00e0 des \u00e9v\u00e8nements). La source de l'\u00e9v\u00e8nement peut \u00eatre un mail de retour avec des champs VERP, ou la consultation d'une URL sp\u00e9cifique. CiviCRM peut alors envoyer un mail particulier en r\u00e9ponse \u00e0 l'\u00e9v\u00e8nement, en fonction de sa configuration. Des templates sp\u00e9cifiques sont pr\u00e9vus en fonction des cas. Dans CRM_Core_SelectValues : public static function mailingComponents() { return [ 'Header' => ts('Header'), 'Footer' => ts('Footer'), 'Reply' => ts('Reply Auto-responder'), 'OptOut' => ts('Opt-out Message'), 'Subscribe' => ts('Subscription Confirmation Request'), 'Welcome' => ts('Welcome Message'), 'Unsubscribe' => ts('Unsubscribe Message'), 'Resubscribe' => ts('Resubscribe Message'), ]; } Et \u00e9galement dans CRM_Core_SelectValues : public static function mailingTokens() { return [ '{action.unsubscribe}' => ts('Unsubscribe via email'), '{action.unsubscribeUrl}' => ts('Unsubscribe via web page'), '{action.resubscribe}' => ts('Resubscribe via email'), '{action.resubscribeUrl}' => ts('Resubscribe via web page'), '{action.optOut}' => ts('Opt out via email'), '{action.optOutUrl}' => ts('Opt out via web page'), '{action.forward}' => ts('Forward this email (link)'), '{action.reply}' => ts('Reply to this email (link)'), '{action.subscribeUrl}' => ts('Subscribe via web page'), '{mailing.key}' => ts('Mailing key'), '{mailing.name}' => ts('Mailing name'), '{mailing.group}' => ts('Mailing group'), '{mailing.viewUrl}' => ts('Mailing permalink'), ] + self::domainTokens(); }","title":"Mailing automation"},{"location":"TECHNIQUE/MAIL/ecosysteme.html#lusage-et-les-adaptations-pour-civiparoisse","text":"Une caract\u00e9ristique fondamentale de Civiparoisse est que l'ensemble des acc\u00e8s au coeur du syst\u00e8me sont authentifi\u00e9s. Cette caract\u00e9ristique doit perdurer pour que le syst\u00e8me reste conceptuellement simple. Or, on constate que les interactions entre les mails et l'environnement sont potentiellement fortes, ce qui complique les choses. Des compromis doivent donc \u00eatre trouv\u00e9s.","title":"L'usage et les adaptations pour Civiparoisse"},{"location":"TECHNIQUE/MAIL/ecosysteme.html#lusage-specifique-des-mails-de-masse","text":"La mise en oeuvres de mails de masse est diff\u00e9rente des mails envoy\u00e9s de personne \u00e0 personne, et de ce fait, on peut supposer qu'une formation sp\u00e9cifique soit prodigu\u00e9e aux utilisateurs.","title":"L'usage sp\u00e9cifique des mails de masse"},{"location":"TECHNIQUE/MAIL/ecosysteme.html#les-mails-generes-multipartalternative-avec-texthtml-et-textplain","text":"Mosaico semble fournir un int\u00e9r\u00eat pour la mise en oeuvre des mails, car il limite les risques de casse involontaire des mails. Il semble donc int\u00e9ressant de privil\u00e9gier l'utilisation de cet outil. Les mails qui sont g\u00e9n\u00e9r\u00e9s par le syst\u00e8me sont d\u00e9j\u00e0 pr\u00e9vus pour \u00eatre \u00e0 la fois en html et en text/plain. De son c\u00f4t\u00e9, un Mail User Agent va privil\u00e9gier l'affichage d'un seul rendu (celui qu'il est sens\u00e9 comprendre, de plus grande pr\u00e9f\u00e9rence), et l'utilisateur n'est pas forc\u00e9ment au courant qu'il dispose dans le mail de plusieurs versions du contenu, dont une en texte brut. Au lieu de faire un lien vers une page web, il serait plus int\u00e9ressant de faire remarquer \u00e0 l'utilisateur que s'il a du mal \u00e0 lire le mail, qu'il cherche \u00e0 changer de source de message, ou d'afficher la source du mail (puisqu'une version est du texte brut). En revanche, il conviendra \u00e9ventuellement de laisser l'utilisateur pr\u00e9parer manuellement la version textuelle du mail, car cette version simplifi\u00e9e ne correspond pas forc\u00e9ment \u00e0 la version graphique, pour que le mail reste le plus lisible possible. On devra donc adapter les interfaces de l'adaptateur de mosaico \u00e0 cet effet.","title":"Les mails g\u00e9n\u00e9r\u00e9s : multipart/alternative, avec text/html et text/plain"},{"location":"TECHNIQUE/MAIL/ecosysteme.html#les-images-stockees-sur-un-serveur-tiers","text":"La philosophie de l'adaptateur de Mosaico est de stocker les images sur le serveur local, en g\u00e9n\u00e9rant des versions \u00e0 des tailles adapt\u00e9es aux mails g\u00e9n\u00e9r\u00e9s. On comprend donc l'int\u00e9r\u00eat de ce fonctionnement, mais il ne peut pas s'appliquer dans Civiparoisse. La meilleure solution est de stocker les images sur un serveur tiers, et de d\u00e9velopper un bloc Mosaico pour cet usage, en sensibilisant les utilisateurs aux probl\u00e9matiques relatives aux images, de sorte \u00e0 ce qu'ils optimisent eux-m\u00eames les m\u00e9dias qu'ils souhaitent utiliser.","title":"Les images : stock\u00e9es sur un serveur tiers"},{"location":"TECHNIQUE/MAIL/ecosysteme.html#tracking","text":"Le tracking propos\u00e9 par CiviCRM est certes utilis\u00e9 dans le monde de l'entreprise, mais il est fait d'une mani\u00e8re quelque peu cach\u00e9e, qui est au minimum questionnable dans le cadre d'une paroisse et de ses valeurs. Il semble donc peu appropri\u00e9 d'utiliser le tracking d'ouverture du mail tel que propos\u00e9 nativement, et encore moins le tracking de contenu. Toutefois, des statistiques d'utilisation semblent \u00eatre les bienvenues. On se souviendra \u00e0 cette fin qu'il existe le syst\u00e8me appel\u00e9 Message Disposition Notification RFC 8098 , qui peut demander des notifications par rapport au suivi du mail. Un tel retour sera probablement faible, mais il aura l'avantage d'\u00eatre plus transparent par rapport \u00e0 l'utilisateur, et pourra \u00e9ventuellement m\u00eame fournir des informations sur les Mail User Agent utilis\u00e9s. Il faudra donc impl\u00e9menter la demande de notifications MDN.","title":"Tracking"},{"location":"TECHNIQUE/MAIL/ecosysteme.html#mail-automation","text":"Le mail automation permet surtout de g\u00e9n\u00e9rer une r\u00e9action suite \u00e0 un clic de lien ou \u00e0 la r\u00e9ception d'un mail ( adresse avec VERP). Pour fournir la fonctionnalit\u00e9, il semble faisable d'utiliser des liens mailto, tel que d\u00e9crit dans RFC 6068 . Cette RFC pr\u00e9cise d'ailleurs dans son point 4 qu'on ne peut que supposer que l'utilisation des champs subject et body sera disponible. Toutefois, ceci suffit d\u00e9j\u00e0 pour inclure des informations dans l'un ou l'autre champ, de mani\u00e8re assez analogue \u00e0 ce que l'on fait pour les liens que l'on inclut dans les mails. Si les informations comme les sommes de contr\u00f4le sont transmises, il devient alors possible de les v\u00e9rifier (\u00e9ventuellement via des formulaires \u00e0 d\u00e9velopper) avant qu'un utilisateur de Civiparoisse effectue les actions demand\u00e9es par un tiers. Dans le cadre de cette fonctionnalit\u00e9, il faudrait donc d\u00e9velopper deux cat\u00e9gories d'\u00e9l\u00e9ments : la g\u00e9n\u00e9ration des URL mailto ad\u00e9quates les formulaires (admin) de v\u00e9rification des donn\u00e9es","title":"Mail automation"},{"location":"TECHNIQUE/MAIL/ecosysteme.html#elements-hypothetiquement-utiles-pour-le-futur","text":"Deux types d'\u00e9l\u00e9ments pourraient \u00eatre int\u00e9ressants pour le futur : la possibilit\u00e9 d'utiliser SMIME pour chiffrer les messages envoy\u00e9s, en utilisant la clef publique du destinataire la possibilit\u00e9 d'utiliser SMIME pour signer les messages envoy\u00e9s, pour que les destinataires puissent v\u00e9rifier l'authenticit\u00e9 des messages. Ces deux \u00e9l\u00e9ments supposent toutefois des connaissances et une sensibilisation pouss\u00e9es dont ne disposent pas actuellement la plupart des utilisateurs.","title":"El\u00e9ments hypoth\u00e9tiquement utiles pour le futur"},{"location":"TECHNIQUE/MAIL/fetchmail.html","text":"R\u00e9ception de mails La r\u00e9ception des mails suppose d'abord l'envoi d'un mail \u00e0 recevoir. Les mails transitent g\u00e9n\u00e9ralement par un ou plusieurs MTA avant d'arriver \u00e0 un MDA, mais avec msmtp il est \u00e9galement possible d'utiliser le protocole LMTP pour transmettre \u00e0 un MDA le mail directement. Dans le cadre de l'exp\u00e9rimentation, trois \u00e9l\u00e9ments ont \u00e9t\u00e9 mis en oeuvre : un client mail, qui va transmettre le mail au MDA un serveur MDA un programme de r\u00e9cup\u00e9ration des mails Client mail Un mail de test a \u00e9t\u00e9 forg\u00e9 manuellement : From: src@src.test To: dst@dst.test Subject: test Message Comme expliqu\u00e9 en introduction, msmtp peut utiliser le protocole LMTP. Cette possibilit\u00e9 a \u00e9t\u00e9 exploit\u00e9e via une configuration ad\u00e9quate : defaults account default host dovecot port 24 user src@src.test password pass protocol lmtp logfile - Et l'envoi est pr\u00e9vu par une commande : #!/bin/bash cat /mail/test1.txt | msmtp -t -i -C ${ MSMTPCONFIGFILE } --read-envelope-from Serveur MDA (IMAP) Plusieurs serveurs ont \u00e9t\u00e9 test\u00e9s en vue d'une exp\u00e9rimentation en approche \"quick and dirty\". Cette approche a \u00e9t\u00e9 pr\u00e9f\u00e9r\u00e9e pour le moment car il n'est pas s\u00fbr que le fonctionnement s\u00e9par\u00e9 de CiviCRM sera r\u00e9ellement int\u00e9gr\u00e9, et d'autre part, le serveur IMAP est typiquement un \u00e9l\u00e9ment fourni par un provider tiers. Le gros de l'effort n'\u00e9tait donc a priori pas \u00e0 fournir sur ce sujet. Pourtant, la s\u00e9lection d'un serveur MDA a n\u00e9cessit\u00e9 plus de temps qu'envisag\u00e9 a priori : le premier serveur test\u00e9 est localmail : \u00e9crit en python, il propose une bo\u00eete mail unique, sans mot de passe, avec un support de SMTP et d'IMAP. Le probl\u00e8me rencontr\u00e9 avec ce serveur est que le client de r\u00e9cup\u00e9ration de mails (fetchmail) d\u00e9tectait une diff\u00e9rence de taille entre les tailles annonc\u00e9es et les flux transmis le serveur courier-imap : ce serveur semblait \u00eatre un bon candidat, mais je n'ai pas trouv\u00e9 rapidement de documentation satisfaisante. Il a donc \u00e9t\u00e9 \u00e9cart\u00e9 le serveur cyrus-imap : ce serveur a une documentation suffisante, mais il y a eu un probl\u00e8me sur les d\u00e9penances des librairies pour son installation via les paquets natifs de ubuntu : un probl\u00e8me sur les libraires perl, qui est un probl\u00e8me connu, lors du lancement de l'outil d'administration cyradm : https://bugs.launchpad.net/ubuntu/+source/cyrus-imapd/+bug/1971547 . De ce fait, ce serveur a \u00e9t\u00e9 \u00e9galement \u00e9cart\u00e9 le serveur dovecot : ce serveur dispose d'une documentation fournie, et est en plus assez intuitif au niveau de sa configuration. Ubuntu propose d'ailleurs des fichiers de configuration suffisamment comment\u00e9s pour pouvoir faire une configuration rapide. Cerise sur le g\u00e2teau, dovecot fournit une image Docker pour les exp\u00e9rimentations : https://hub.docker.com/r/dovecot/dovecot/ . N\u00e9anmoins, la compilation d'une image modifi\u00e9e, depuis les sources https://github.com/dovecot/docker a \u00e9t\u00e9 requise, en se basant sur la version 2.3.19.1, \u00e0 cause de l'architecture mat\u00e9rielle utilis\u00e9e pour les tests (armhf) : il s'agissait donc d'utiliser uniquement les paquets pr\u00e9vus par la distribution Debian (celle utilis\u00e9e dans le FROM du Dockerfile) pour avoir des packages disponibles vis \u00e0 vis de l'architecture armhf : mise en commentaire : #ADD dovecot.gpg /etc/apt/trusted.gpg.d #ADD dovecot.list /etc/apt/sources.list.d et modification du nom de package dovecot-lua en dovecot-auth-lua . Cette image est fonctionnelle, et propose une configuration qui accepte les comptes avec le mot de passe \"pass\", et propose notamment un support LMTP et IMAP. La configuration a \u00e9t\u00e9 modifi\u00e9e pour autoriser rapidement l'authentification en texte clair (\u00e0 ne pas utiliser en production :ajout de disable_plaintext_auth=no dans dovecot.conf). Ce serveur a fait le travail attendu lors des tests. Maildirfetcher Le travail consiste ensuite \u00e0 r\u00e9cup\u00e9rer les mails et \u00e0 les mettre \u00e0 disposition dans un dossier Maildir. A cette fin, il faut : initialiser un dossier Maildir et les d\u00e9pendances : outil maildirmake r\u00e9cup\u00e9rer les mails : outil fetchmail injecter les mails dans le Maildir : outil putmail Etant donn\u00e9 que fetchmail s'ex\u00e9cutera comme un \"service\", il est pr\u00e9f\u00e9rable qu'il ne soit pas ex\u00e9cut\u00e9 avec les droits root, mais avec un compte inf\u00e9rieur. Il faut donc prendre en compte cette particularit\u00e9 dans les scripts. Initialisation du dossier de Maildir et dossiers d\u00e9pendants Maildrop est fourni avec un outil maildirmake qui permet de cr\u00e9er un dossier Maildir. Une subtitlit\u00e9 a toutefois \u00e9t\u00e9 mise en oeuvre : pour r\u00e9gler des probl\u00e8mes de mise en oeuvre des droits, le dossier a \u00e9t\u00e9 cr\u00e9e avec les droits roots, et les permissions ont ensuite \u00e9t\u00e9 sett\u00e9es, ce afin de ne pas avoir \u00e0 donner des permissions d'\u00e9critures au niveau parent - ce qui peut \u00eatre particuli\u00e8rement emb\u00eatant par rapport \u00e0 des r\u00e9pertoires de montage de volumes. De m\u00eame, fetchmail n\u00e9cessite un dossier avec droits d'\u00e9criture pour les fichiers d'ID : ce dossier a \u00e9t\u00e9 pr\u00e9vu dans un sous-dossier d'un volume mont\u00e9. Enfin, fetchmail pr\u00e9voit \u00e9galement d'\u00e9crire son pid dans un fichier : \u00e9tant donn\u00e9 que ce contenu d\u00e9pend fondamentalement du conteneur d'ex\u00e9cution, le plus simple est de le stocker dans /tmp. On arrive donc \u00e0 un script d'initialisation des volumes, ex\u00e9cut\u00e9 en root, semblable \u00e0 : #!/bin/bash if [[ ! ( -n ` find /MAILDIR -maxdepth 0 -type d -empty ` ) ]] then echo \"Already initialized\" exit 0 ; fi maildirmake /MAILDIR/Maildir mkdir /IDFILES/idfiles chown -R www-data:www-data /IDFILES/idfiles chmod 700 /IDFILES/idfiles chown -R www-data:www-data /MAILDIR/Maildir Le test a \u00e9t\u00e9 repris des scripts de l'image init . Fetchmail Fetchmail permet de r\u00e9cup\u00e9rer les mails via des protocoles tels que IMAP ou POP et peut les envoyer autre part, par exemple via SMTP, ou m\u00eame vers un Mail Delivery Agent (MDA). Comme pr\u00e9cis\u00e9 auparavant, fetchmail est ex\u00e9cut\u00e9 via des droits restreints. On en arrive donc \u00e0 un script quelque peu particulier pour la commande \u00e0 ex\u00e9cuter dans le container : #!/bin/bash /exec/initializer.sh sudo -u www-data -E /exec/mailfetcher.sh Le param\u00e8tre -E permet de transmettre l'ensemble des variables d'environnement, et ce, de mani\u00e8re non modifi\u00e9e. L'int\u00e9r\u00eat de cette pratique est que l'on r\u00e9cup\u00e8re l'ensemble des variables d'environnement qui ont \u00e9t\u00e9 sett\u00e9es pour le container, mais l'inconv\u00e9nient est que des variables comme HOME ne sont pas sett\u00e9s avec l'utilisateur qui ex\u00e9cute les commandes. Du coup, il faut se m\u00e9fier lors des appels \u00e0 des fichiers, car ils pourraient facilement chercher \u00e0 acc\u00e9der (sans succ\u00e8s, normalement) au contenu de /root . A noter qu'on aurait \u00e9galement pu pr\u00e9ciser la liste des variables d'environnement \u00e0 transmettre, mais ceci signifierait que cette liste devrait \u00e9galement \u00eatre maintenue dans le temps. Il n'y a donc pas de solution parfaite ici. En ce qui concerne le script d'ex\u00e9cution de fetchmail : #!/bin/bash echo ${ FETCHMAILCONFIGFILE } fetchmail -vvv --nodetach -f ${ FETCHMAILCONFIGFILE } -i /IDFILES/idfiles/idfile --pidfile /tmp/fetchmail.pid --norewrite --mda \"/exec/putmail.sh\" Les \u00e9l\u00e9ments qui doivent \u00eatre prioritaires et prendre le dessus par rapport au contenu du fichier de configuration sont indiqu\u00e9s directement sur la ligne de commande : il s'agit des r\u00e9glages pour les chemins, le fait que fetchmail doit \u00eatre \"transparent\" ( norewrite ), et surtout le for\u00e7age de la valeur de --mda pour ex\u00e9cuter putmail. Le fichier de configuration contient les \u00e9l\u00e9ments qui permettront d'acc\u00e9der au serveur IMAP. Pour le test, le fichier est : set daemon 60 poll dovecot protocol IMAP service 143: username \"dst@dst.test\" there password \"pass\" keep sslproto '' La premi\u00e8re ligne permet d'indiquer le fonctionnement en mode daemon, avec un d\u00e9lai de 60 secondes entre les r\u00e9cup\u00e9rations de courier. La ligne poll contient les options qui sont relatives au serveur de mail \u00e0 acc\u00e9der : nom d'h\u00f4te, protocole, port. Fetchmail est particuli\u00e8rement exigeant au niveau des options de poll : il exige que toutes les options relatives au serveur soient indiqu\u00e9es avant toute option relative \u00e0 l'utilisateur ou aux utilisateurs (sans quoi une erreur de syntaxe est souvent d\u00e9clench\u00e9e). Cette exigence de syntaxe n\u00e9cessite bien souvent de se r\u00e9f\u00e9rer \u00e0 la page de manuel, car il est parfois d\u00e9licat de bien identifier ce qui rel\u00e8ve du serveur et ce qui rel\u00e8ve de l'utilisateur. Au niveau de l'utilisateur, on sp\u00e9cifie le nom d'utilisateur distant le there et le mot de passe. L'option keep garde les mails sur le serveur distant, tandis que l'option sslproto '' a permis de d\u00e9sactiver l'emploi du SSL pour le maquettage. L'option fetchall a d\u00fb \u00eatre supprim\u00e9e de la configuration : elle d\u00e9clenchait le ret\u00e9l\u00e9chargement des messages qui \u00e9taient d\u00e9j\u00e0 pr\u00e9sents, ce qui n'\u00e9tait pas \u00e9vident par rapport au manuel. Lors d'une int\u00e9gration Kubernetes, on pourra \u00eatre tent\u00e9 de passer le set daemon en option de ligne de commande. Une autre approche pourrait \u00eatre l'ex\u00e9cution via cronjob Kubernetes, ce qui supprimerait l'utilisation du mode daemon. Putmail Le MDA s\u00e9lectionn\u00e9 est livr\u00e9 avec le package mailutils-mda : il s'agit de putmail. Il recoit via STDIN le mail \u00e0 stocker, et l'int\u00e8gre dans le Maildir fourni en param\u00e8tre. Etant donn\u00e9 que putmail est appel\u00e9 par fetchmail, ses droits d'ex\u00e9cution sont \u00e9galement restreints. On n'utilise pas de configuration particuli\u00e8re pour putmail : il n'y a donc pas besoin de chercher dans $HOME pour des pr\u00e9f\u00e9rences, $HOME qui pourrait encore \u00eatre sett\u00e9 \u00e0 /root si l'on reprend tel quel les variables d'environnement initiales du container. Donc autant ne pas tenter de charger des pr\u00e9f\u00e9rences : option --no-config Script lanc\u00e9 par fetchmail : putmail.sh : #!/bin/bash putmail --no-config /MAILDIR/Maildir exit $?","title":"R\u00e9ception"},{"location":"TECHNIQUE/MAIL/fetchmail.html#reception-de-mails","text":"La r\u00e9ception des mails suppose d'abord l'envoi d'un mail \u00e0 recevoir. Les mails transitent g\u00e9n\u00e9ralement par un ou plusieurs MTA avant d'arriver \u00e0 un MDA, mais avec msmtp il est \u00e9galement possible d'utiliser le protocole LMTP pour transmettre \u00e0 un MDA le mail directement. Dans le cadre de l'exp\u00e9rimentation, trois \u00e9l\u00e9ments ont \u00e9t\u00e9 mis en oeuvre : un client mail, qui va transmettre le mail au MDA un serveur MDA un programme de r\u00e9cup\u00e9ration des mails","title":"R\u00e9ception de mails"},{"location":"TECHNIQUE/MAIL/fetchmail.html#client-mail","text":"Un mail de test a \u00e9t\u00e9 forg\u00e9 manuellement : From: src@src.test To: dst@dst.test Subject: test Message Comme expliqu\u00e9 en introduction, msmtp peut utiliser le protocole LMTP. Cette possibilit\u00e9 a \u00e9t\u00e9 exploit\u00e9e via une configuration ad\u00e9quate : defaults account default host dovecot port 24 user src@src.test password pass protocol lmtp logfile - Et l'envoi est pr\u00e9vu par une commande : #!/bin/bash cat /mail/test1.txt | msmtp -t -i -C ${ MSMTPCONFIGFILE } --read-envelope-from","title":"Client mail"},{"location":"TECHNIQUE/MAIL/fetchmail.html#serveur-mda-imap","text":"Plusieurs serveurs ont \u00e9t\u00e9 test\u00e9s en vue d'une exp\u00e9rimentation en approche \"quick and dirty\". Cette approche a \u00e9t\u00e9 pr\u00e9f\u00e9r\u00e9e pour le moment car il n'est pas s\u00fbr que le fonctionnement s\u00e9par\u00e9 de CiviCRM sera r\u00e9ellement int\u00e9gr\u00e9, et d'autre part, le serveur IMAP est typiquement un \u00e9l\u00e9ment fourni par un provider tiers. Le gros de l'effort n'\u00e9tait donc a priori pas \u00e0 fournir sur ce sujet. Pourtant, la s\u00e9lection d'un serveur MDA a n\u00e9cessit\u00e9 plus de temps qu'envisag\u00e9 a priori : le premier serveur test\u00e9 est localmail : \u00e9crit en python, il propose une bo\u00eete mail unique, sans mot de passe, avec un support de SMTP et d'IMAP. Le probl\u00e8me rencontr\u00e9 avec ce serveur est que le client de r\u00e9cup\u00e9ration de mails (fetchmail) d\u00e9tectait une diff\u00e9rence de taille entre les tailles annonc\u00e9es et les flux transmis le serveur courier-imap : ce serveur semblait \u00eatre un bon candidat, mais je n'ai pas trouv\u00e9 rapidement de documentation satisfaisante. Il a donc \u00e9t\u00e9 \u00e9cart\u00e9 le serveur cyrus-imap : ce serveur a une documentation suffisante, mais il y a eu un probl\u00e8me sur les d\u00e9penances des librairies pour son installation via les paquets natifs de ubuntu : un probl\u00e8me sur les libraires perl, qui est un probl\u00e8me connu, lors du lancement de l'outil d'administration cyradm : https://bugs.launchpad.net/ubuntu/+source/cyrus-imapd/+bug/1971547 . De ce fait, ce serveur a \u00e9t\u00e9 \u00e9galement \u00e9cart\u00e9 le serveur dovecot : ce serveur dispose d'une documentation fournie, et est en plus assez intuitif au niveau de sa configuration. Ubuntu propose d'ailleurs des fichiers de configuration suffisamment comment\u00e9s pour pouvoir faire une configuration rapide. Cerise sur le g\u00e2teau, dovecot fournit une image Docker pour les exp\u00e9rimentations : https://hub.docker.com/r/dovecot/dovecot/ . N\u00e9anmoins, la compilation d'une image modifi\u00e9e, depuis les sources https://github.com/dovecot/docker a \u00e9t\u00e9 requise, en se basant sur la version 2.3.19.1, \u00e0 cause de l'architecture mat\u00e9rielle utilis\u00e9e pour les tests (armhf) : il s'agissait donc d'utiliser uniquement les paquets pr\u00e9vus par la distribution Debian (celle utilis\u00e9e dans le FROM du Dockerfile) pour avoir des packages disponibles vis \u00e0 vis de l'architecture armhf : mise en commentaire : #ADD dovecot.gpg /etc/apt/trusted.gpg.d #ADD dovecot.list /etc/apt/sources.list.d et modification du nom de package dovecot-lua en dovecot-auth-lua . Cette image est fonctionnelle, et propose une configuration qui accepte les comptes avec le mot de passe \"pass\", et propose notamment un support LMTP et IMAP. La configuration a \u00e9t\u00e9 modifi\u00e9e pour autoriser rapidement l'authentification en texte clair (\u00e0 ne pas utiliser en production :ajout de disable_plaintext_auth=no dans dovecot.conf). Ce serveur a fait le travail attendu lors des tests.","title":"Serveur MDA (IMAP)"},{"location":"TECHNIQUE/MAIL/fetchmail.html#maildirfetcher","text":"Le travail consiste ensuite \u00e0 r\u00e9cup\u00e9rer les mails et \u00e0 les mettre \u00e0 disposition dans un dossier Maildir. A cette fin, il faut : initialiser un dossier Maildir et les d\u00e9pendances : outil maildirmake r\u00e9cup\u00e9rer les mails : outil fetchmail injecter les mails dans le Maildir : outil putmail Etant donn\u00e9 que fetchmail s'ex\u00e9cutera comme un \"service\", il est pr\u00e9f\u00e9rable qu'il ne soit pas ex\u00e9cut\u00e9 avec les droits root, mais avec un compte inf\u00e9rieur. Il faut donc prendre en compte cette particularit\u00e9 dans les scripts.","title":"Maildirfetcher"},{"location":"TECHNIQUE/MAIL/fetchmail.html#initialisation-du-dossier-de-maildir-et-dossiers-dependants","text":"Maildrop est fourni avec un outil maildirmake qui permet de cr\u00e9er un dossier Maildir. Une subtitlit\u00e9 a toutefois \u00e9t\u00e9 mise en oeuvre : pour r\u00e9gler des probl\u00e8mes de mise en oeuvre des droits, le dossier a \u00e9t\u00e9 cr\u00e9e avec les droits roots, et les permissions ont ensuite \u00e9t\u00e9 sett\u00e9es, ce afin de ne pas avoir \u00e0 donner des permissions d'\u00e9critures au niveau parent - ce qui peut \u00eatre particuli\u00e8rement emb\u00eatant par rapport \u00e0 des r\u00e9pertoires de montage de volumes. De m\u00eame, fetchmail n\u00e9cessite un dossier avec droits d'\u00e9criture pour les fichiers d'ID : ce dossier a \u00e9t\u00e9 pr\u00e9vu dans un sous-dossier d'un volume mont\u00e9. Enfin, fetchmail pr\u00e9voit \u00e9galement d'\u00e9crire son pid dans un fichier : \u00e9tant donn\u00e9 que ce contenu d\u00e9pend fondamentalement du conteneur d'ex\u00e9cution, le plus simple est de le stocker dans /tmp. On arrive donc \u00e0 un script d'initialisation des volumes, ex\u00e9cut\u00e9 en root, semblable \u00e0 : #!/bin/bash if [[ ! ( -n ` find /MAILDIR -maxdepth 0 -type d -empty ` ) ]] then echo \"Already initialized\" exit 0 ; fi maildirmake /MAILDIR/Maildir mkdir /IDFILES/idfiles chown -R www-data:www-data /IDFILES/idfiles chmod 700 /IDFILES/idfiles chown -R www-data:www-data /MAILDIR/Maildir Le test a \u00e9t\u00e9 repris des scripts de l'image init .","title":"Initialisation du dossier de Maildir et dossiers d\u00e9pendants"},{"location":"TECHNIQUE/MAIL/fetchmail.html#fetchmail","text":"Fetchmail permet de r\u00e9cup\u00e9rer les mails via des protocoles tels que IMAP ou POP et peut les envoyer autre part, par exemple via SMTP, ou m\u00eame vers un Mail Delivery Agent (MDA). Comme pr\u00e9cis\u00e9 auparavant, fetchmail est ex\u00e9cut\u00e9 via des droits restreints. On en arrive donc \u00e0 un script quelque peu particulier pour la commande \u00e0 ex\u00e9cuter dans le container : #!/bin/bash /exec/initializer.sh sudo -u www-data -E /exec/mailfetcher.sh Le param\u00e8tre -E permet de transmettre l'ensemble des variables d'environnement, et ce, de mani\u00e8re non modifi\u00e9e. L'int\u00e9r\u00eat de cette pratique est que l'on r\u00e9cup\u00e8re l'ensemble des variables d'environnement qui ont \u00e9t\u00e9 sett\u00e9es pour le container, mais l'inconv\u00e9nient est que des variables comme HOME ne sont pas sett\u00e9s avec l'utilisateur qui ex\u00e9cute les commandes. Du coup, il faut se m\u00e9fier lors des appels \u00e0 des fichiers, car ils pourraient facilement chercher \u00e0 acc\u00e9der (sans succ\u00e8s, normalement) au contenu de /root . A noter qu'on aurait \u00e9galement pu pr\u00e9ciser la liste des variables d'environnement \u00e0 transmettre, mais ceci signifierait que cette liste devrait \u00e9galement \u00eatre maintenue dans le temps. Il n'y a donc pas de solution parfaite ici. En ce qui concerne le script d'ex\u00e9cution de fetchmail : #!/bin/bash echo ${ FETCHMAILCONFIGFILE } fetchmail -vvv --nodetach -f ${ FETCHMAILCONFIGFILE } -i /IDFILES/idfiles/idfile --pidfile /tmp/fetchmail.pid --norewrite --mda \"/exec/putmail.sh\" Les \u00e9l\u00e9ments qui doivent \u00eatre prioritaires et prendre le dessus par rapport au contenu du fichier de configuration sont indiqu\u00e9s directement sur la ligne de commande : il s'agit des r\u00e9glages pour les chemins, le fait que fetchmail doit \u00eatre \"transparent\" ( norewrite ), et surtout le for\u00e7age de la valeur de --mda pour ex\u00e9cuter putmail. Le fichier de configuration contient les \u00e9l\u00e9ments qui permettront d'acc\u00e9der au serveur IMAP. Pour le test, le fichier est : set daemon 60 poll dovecot protocol IMAP service 143: username \"dst@dst.test\" there password \"pass\" keep sslproto '' La premi\u00e8re ligne permet d'indiquer le fonctionnement en mode daemon, avec un d\u00e9lai de 60 secondes entre les r\u00e9cup\u00e9rations de courier. La ligne poll contient les options qui sont relatives au serveur de mail \u00e0 acc\u00e9der : nom d'h\u00f4te, protocole, port. Fetchmail est particuli\u00e8rement exigeant au niveau des options de poll : il exige que toutes les options relatives au serveur soient indiqu\u00e9es avant toute option relative \u00e0 l'utilisateur ou aux utilisateurs (sans quoi une erreur de syntaxe est souvent d\u00e9clench\u00e9e). Cette exigence de syntaxe n\u00e9cessite bien souvent de se r\u00e9f\u00e9rer \u00e0 la page de manuel, car il est parfois d\u00e9licat de bien identifier ce qui rel\u00e8ve du serveur et ce qui rel\u00e8ve de l'utilisateur. Au niveau de l'utilisateur, on sp\u00e9cifie le nom d'utilisateur distant le there et le mot de passe. L'option keep garde les mails sur le serveur distant, tandis que l'option sslproto '' a permis de d\u00e9sactiver l'emploi du SSL pour le maquettage. L'option fetchall a d\u00fb \u00eatre supprim\u00e9e de la configuration : elle d\u00e9clenchait le ret\u00e9l\u00e9chargement des messages qui \u00e9taient d\u00e9j\u00e0 pr\u00e9sents, ce qui n'\u00e9tait pas \u00e9vident par rapport au manuel. Lors d'une int\u00e9gration Kubernetes, on pourra \u00eatre tent\u00e9 de passer le set daemon en option de ligne de commande. Une autre approche pourrait \u00eatre l'ex\u00e9cution via cronjob Kubernetes, ce qui supprimerait l'utilisation du mode daemon.","title":"Fetchmail"},{"location":"TECHNIQUE/MAIL/fetchmail.html#putmail","text":"Le MDA s\u00e9lectionn\u00e9 est livr\u00e9 avec le package mailutils-mda : il s'agit de putmail. Il recoit via STDIN le mail \u00e0 stocker, et l'int\u00e8gre dans le Maildir fourni en param\u00e8tre. Etant donn\u00e9 que putmail est appel\u00e9 par fetchmail, ses droits d'ex\u00e9cution sont \u00e9galement restreints. On n'utilise pas de configuration particuli\u00e8re pour putmail : il n'y a donc pas besoin de chercher dans $HOME pour des pr\u00e9f\u00e9rences, $HOME qui pourrait encore \u00eatre sett\u00e9 \u00e0 /root si l'on reprend tel quel les variables d'environnement initiales du container. Donc autant ne pas tenter de charger des pr\u00e9f\u00e9rences : option --no-config Script lanc\u00e9 par fetchmail : putmail.sh : #!/bin/bash putmail --no-config /MAILDIR/Maildir exit $?","title":"Putmail"},{"location":"TECHNIQUE/MAIL/mail.html","text":"Probl\u00e9matique des mails La probl\u00e9matique des mails est multiple dans Civiparoisse : des mails peuvent \u00eatre envoy\u00e9s vers un seul destinataire \u00e0 travers l'interface de Civiparoisse des mails de masse peuvent \u00eatre envoy\u00e9s vers une multitude de destinataires des mails de bounce peuvent \u00eatre re\u00e7us. Pour pr\u00e9server l'image de marque des paroisses, il est important de s'assurer qu'une attaque qui prendrait le contr\u00f4le de Civiparoisse (au niveau CiviCRM) ne puisse que difficilement avoir acc\u00e8s aux identifiants de mails : d'o\u00f9 l'utilisation de m\u00e9canismes d'envoi/r\u00e9ceptions indirects en lieu et place des possibilit\u00e9s offertes directement par CiviCRM. L'envoi et de r\u00e9ceptions de mails utilisent des protocoles (et par conns\u00e9quent des logiciels) diff\u00e9rents, quoique compl\u00e9mentaires : le protocole SMTP est utilis\u00e9 lors de l'envoi d'un mail depuis un MUA (Mail User Agent), et de la transmission du mail jusqu'\u00e0 sa destination finale diff\u00e9rents enregistrements DNS (dont les enregistrements MX et TXT pour DKIM) sont mis en oeuvre pour d\u00e9terminer les cibles d'acheminements du mail le protocole LMTP peut \u00eatre utilis\u00e9 pour transf\u00e9rer un mail du MTA (Mail Transfer Agent) ou MDA (Mail Delivery Agent) un MUA peut soit attaquer directement une bo\u00eete mail locale (par exemble au format mbox ou maildir) ou on peut r\u00e9cup\u00e9rer avec d'autres protocoles comme IMAP le contenu de la bo\u00eete. Il y a donc lieu de voir en voir en d\u00e9tail les deux probl\u00e9matiques : envoi de mail r\u00e9cup\u00e9ration de mail","title":"Index"},{"location":"TECHNIQUE/MAIL/mail.html#problematique-des-mails","text":"La probl\u00e9matique des mails est multiple dans Civiparoisse : des mails peuvent \u00eatre envoy\u00e9s vers un seul destinataire \u00e0 travers l'interface de Civiparoisse des mails de masse peuvent \u00eatre envoy\u00e9s vers une multitude de destinataires des mails de bounce peuvent \u00eatre re\u00e7us. Pour pr\u00e9server l'image de marque des paroisses, il est important de s'assurer qu'une attaque qui prendrait le contr\u00f4le de Civiparoisse (au niveau CiviCRM) ne puisse que difficilement avoir acc\u00e8s aux identifiants de mails : d'o\u00f9 l'utilisation de m\u00e9canismes d'envoi/r\u00e9ceptions indirects en lieu et place des possibilit\u00e9s offertes directement par CiviCRM. L'envoi et de r\u00e9ceptions de mails utilisent des protocoles (et par conns\u00e9quent des logiciels) diff\u00e9rents, quoique compl\u00e9mentaires : le protocole SMTP est utilis\u00e9 lors de l'envoi d'un mail depuis un MUA (Mail User Agent), et de la transmission du mail jusqu'\u00e0 sa destination finale diff\u00e9rents enregistrements DNS (dont les enregistrements MX et TXT pour DKIM) sont mis en oeuvre pour d\u00e9terminer les cibles d'acheminements du mail le protocole LMTP peut \u00eatre utilis\u00e9 pour transf\u00e9rer un mail du MTA (Mail Transfer Agent) ou MDA (Mail Delivery Agent) un MUA peut soit attaquer directement une bo\u00eete mail locale (par exemble au format mbox ou maildir) ou on peut r\u00e9cup\u00e9rer avec d'autres protocoles comme IMAP le contenu de la bo\u00eete. Il y a donc lieu de voir en voir en d\u00e9tail les deux probl\u00e9matiques : envoi de mail r\u00e9cup\u00e9ration de mail","title":"Probl\u00e9matique des mails"},{"location":"TECHNIQUE/MAIL/sendmail.html","text":"Envoi de mail L'envoi de mail est caract\u00e9ris\u00e9 par la mise en oeuvre de trois \u00e9l\u00e9ments : le programme d'envoi de mail (client mail), qui va transf\u00e9rer le mail vers le \"smarthost\" le \"smarthost\" qui permet d'encapsuler l'acc\u00e8s aux identifiants, de signer le mail (signature DKIM ) et de transf\u00e9rer le mail vers le serveur le serveur SMTP proprement dit. Client mail Dans le cadre de l'envoi des mails, le plus simple est d'utiliser la transmission par socket unix entre le client mail et le proxy : on r\u00e9utilise donc la transmission via socat mise en oeuvre entre le reverse-proxy et l'authenticateur. Le client mail est configur\u00e9 facilement dans la mesure o\u00f9 en PHP on dispose de l'envoi par d\u00e9faut via sendmail, qui est configur\u00e9 au niveau syst\u00e8me par la directive de configuration sendmail_path de php.ini ; l'approche propos\u00e9e en exemple est le sendmail -t -i , qui a notamment comme propri\u00e9t\u00e9 de fournir le destinataire dans les ent\u00eates du mail. Le champ From est \u00e9galement quasi-obligatoire. On a donc dans php.ini : sendmail_path = \"/mail/sendmail.sh\" Et comme exemple d'envoi de mail de test : #!/usr/bin/php <?php $ret = mail ( 'dst@dst.test' , 'subject' , 'message' , 'From: \"SRC\" <src@src.test>' , \"\" ); echo $ret ; En ce qui concerne le script socat : #!/bin/bash set pipefail socat -d -d -d -D -t 50 -T 50 -lf /tmp/socat.txt STDIO UNIX-CONNECT:/MAILSOCK/sendmail exit 0 Smarthost Le smarthost r\u00e9cup\u00e8re le mail via socat, comme il se doit : #!/bin/bash socat -d -d -d -D -t 50 -T 50 -lf /tmp/socat.txt UNIX-LISTEN:/MAILSOCK/sendmail,fork,user = paroisse,group = www-data,mode = 0660 ,unlink-early EXEC:/mail/msmtp.sh,su = mailer Le script appel\u00e9 se compose en deux parties : la signature, puis la transmission du mail : #!/bin/bash dkimsign \" ${ DKIMSELECTOR } \" \" ${ DKIMDOMAIN } \" \" ${ DKIMKEYFILE } \" | msmtp -t -i -C ${ MSMTPCONFIGFILE } --read-envelope-from Signature et v\u00e9rification de signature Le programme (script) utilis\u00e9 est dkimsign. Il prend un mail sur STDIN et transmet le mail sign\u00e9 (donc avec ajout du header de signature) sur STDOUT, ce qui facilite son utilisation via des pipes. Pour la signature DKIM, la clef DKIM choisie est une clef 2048 bit, g\u00e9n\u00e9r\u00e9e via openssl genrsa. Le s\u00e9lecteur indique le nom de l'entr\u00e9e DNS qui est utilis\u00e9e pour la clef publique, et le domaine est le domaine de l'entr\u00e9e TXT de ladite clef. Si on r\u00e9cup\u00e8re le mail entre temps (par exemple en pontant avec tee ), on peut v\u00e9rifier le mail avec dkimverify, \u00e0 condition d'avoir un serveur DNS avec la clef. Le serveur que l'on peut utiliser pour maquette rapidement est PowerDNS. Il est en effet rapide de le configurer pour utiliser le backend sqlite, puis d'utiliser pdnsutil pour cr\u00e9er les zones n\u00e9cessaires et finalement l'entr\u00e9e TXT : pdnsutil add-record _domainkey.civicrm.test. civikim1 txt \"\\\"v = DKIM1 ; h = sha256 ; k= rsa ; p = MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAw8JkeF4R+gmkCYwsF6Afm9eM0TSshC/Wrs7MDwCi2pnRAFJCdZr5VKhBQ9Je4fINNo4D8lV+fJVIZYymvaa8bz5nTjLl5F5FtwbJzzmvlDpmUJpii9WGt3HsUEiMGo/xSGhVFLJigTNTzqIGaN7R8mpQPAzzCLe9PnsdJeO1Csh3QHKe3zjd1WdWaoH5/oO/d7WgN1ZFGBBZjtN4OzSgKhZP6mAbTozdPs6p5YwTN+TFr/Sm19kRHrw/gMsEPchgLVMdJ3r1ZZlMVPX9MPqaiYPdgvEbfrTw+UvI1YmdOyt0Slz7ajV4XyLGN5QSiYWv7uquuRdSItqMTsfubjCRXQIDAQAB\\\"\" L'entr\u00e9e TXT se fait obligatoirement dans un sous-domaine _domainkey . Ici, le s\u00e9lecteur est civikim1 . Les param\u00e8tres de l'entr\u00e9e sont l'algorithme de hash (h), l'algorithme de signature (k), et la clef publique, sous forme d'encodage base64 du format DER de la clef publique. On se souviendra que dans la signature de mail g\u00e9n\u00e9r\u00e9e, tous les en-t\u00eates ne sont pas prot\u00e9g\u00e9s par la signature. En revanche, le contenu du mail est prot\u00e9g\u00e9 par la signature. Ceci peut s'expliquer que les diff\u00e9rents acteurs sur le trajet du mail peuvent int\u00e9grer leurs headers dans le mail, et cela peut donc de comprendre la pr\u00e9sence du hash des headers dans la signature. Envoi du mail Msmtp a \u00e9t\u00e9 s\u00e9lectionn\u00e9 pour l'envoi des mails. En r\u00e9alit\u00e9, un bon nombre de programmes analogues existe, mais msmtp a la particularit\u00e9 de disposer d'un grand nombre d'options pour l'authentification, ainsi que le support de SSL : on a donc un outil qui, on peut esp\u00e9rer, saura s'adapter aux exigences d'un bon nombre de serveurs SMTP. Le param\u00e8tre --read-envelope-from sp\u00e9cifie que le programme doit lire le champ From de l'en-t\u00eate du mail pour le MAIL FROM. Le coeur de configuration, qui changera pour chaque paroisse, est embarqu\u00e9 dans un fichier de configuration, comme par exemple : defaults account default host mailcatcher port 25 auth off protocol smtp logfile - On cr\u00e9e ici une configuration \"par d\u00e9faut\", ici en sp\u00e9cifiant un envoi par smtp vers le port 25, sans authentification. En production, on utiliserait de l'authentification et on configurerait le support SSL/TLS. Serveur de mail Le serveur de mail de test utilis\u00e9 est mailcatcher. Il est simple de mise en oeuvre et dispose d'une interface web pour pouvoir r\u00e9cup\u00e9rer les mails (et alors \u00e9galement tester la signature du mail).","title":"Envoi"},{"location":"TECHNIQUE/MAIL/sendmail.html#envoi-de-mail","text":"L'envoi de mail est caract\u00e9ris\u00e9 par la mise en oeuvre de trois \u00e9l\u00e9ments : le programme d'envoi de mail (client mail), qui va transf\u00e9rer le mail vers le \"smarthost\" le \"smarthost\" qui permet d'encapsuler l'acc\u00e8s aux identifiants, de signer le mail (signature DKIM ) et de transf\u00e9rer le mail vers le serveur le serveur SMTP proprement dit.","title":"Envoi de mail"},{"location":"TECHNIQUE/MAIL/sendmail.html#client-mail","text":"Dans le cadre de l'envoi des mails, le plus simple est d'utiliser la transmission par socket unix entre le client mail et le proxy : on r\u00e9utilise donc la transmission via socat mise en oeuvre entre le reverse-proxy et l'authenticateur. Le client mail est configur\u00e9 facilement dans la mesure o\u00f9 en PHP on dispose de l'envoi par d\u00e9faut via sendmail, qui est configur\u00e9 au niveau syst\u00e8me par la directive de configuration sendmail_path de php.ini ; l'approche propos\u00e9e en exemple est le sendmail -t -i , qui a notamment comme propri\u00e9t\u00e9 de fournir le destinataire dans les ent\u00eates du mail. Le champ From est \u00e9galement quasi-obligatoire. On a donc dans php.ini : sendmail_path = \"/mail/sendmail.sh\" Et comme exemple d'envoi de mail de test : #!/usr/bin/php <?php $ret = mail ( 'dst@dst.test' , 'subject' , 'message' , 'From: \"SRC\" <src@src.test>' , \"\" ); echo $ret ; En ce qui concerne le script socat : #!/bin/bash set pipefail socat -d -d -d -D -t 50 -T 50 -lf /tmp/socat.txt STDIO UNIX-CONNECT:/MAILSOCK/sendmail exit 0","title":"Client mail"},{"location":"TECHNIQUE/MAIL/sendmail.html#smarthost","text":"Le smarthost r\u00e9cup\u00e8re le mail via socat, comme il se doit : #!/bin/bash socat -d -d -d -D -t 50 -T 50 -lf /tmp/socat.txt UNIX-LISTEN:/MAILSOCK/sendmail,fork,user = paroisse,group = www-data,mode = 0660 ,unlink-early EXEC:/mail/msmtp.sh,su = mailer Le script appel\u00e9 se compose en deux parties : la signature, puis la transmission du mail : #!/bin/bash dkimsign \" ${ DKIMSELECTOR } \" \" ${ DKIMDOMAIN } \" \" ${ DKIMKEYFILE } \" | msmtp -t -i -C ${ MSMTPCONFIGFILE } --read-envelope-from","title":"Smarthost"},{"location":"TECHNIQUE/MAIL/sendmail.html#signature-et-verification-de-signature","text":"Le programme (script) utilis\u00e9 est dkimsign. Il prend un mail sur STDIN et transmet le mail sign\u00e9 (donc avec ajout du header de signature) sur STDOUT, ce qui facilite son utilisation via des pipes. Pour la signature DKIM, la clef DKIM choisie est une clef 2048 bit, g\u00e9n\u00e9r\u00e9e via openssl genrsa. Le s\u00e9lecteur indique le nom de l'entr\u00e9e DNS qui est utilis\u00e9e pour la clef publique, et le domaine est le domaine de l'entr\u00e9e TXT de ladite clef. Si on r\u00e9cup\u00e8re le mail entre temps (par exemple en pontant avec tee ), on peut v\u00e9rifier le mail avec dkimverify, \u00e0 condition d'avoir un serveur DNS avec la clef. Le serveur que l'on peut utiliser pour maquette rapidement est PowerDNS. Il est en effet rapide de le configurer pour utiliser le backend sqlite, puis d'utiliser pdnsutil pour cr\u00e9er les zones n\u00e9cessaires et finalement l'entr\u00e9e TXT : pdnsutil add-record _domainkey.civicrm.test. civikim1 txt \"\\\"v = DKIM1 ; h = sha256 ; k= rsa ; p = MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAw8JkeF4R+gmkCYwsF6Afm9eM0TSshC/Wrs7MDwCi2pnRAFJCdZr5VKhBQ9Je4fINNo4D8lV+fJVIZYymvaa8bz5nTjLl5F5FtwbJzzmvlDpmUJpii9WGt3HsUEiMGo/xSGhVFLJigTNTzqIGaN7R8mpQPAzzCLe9PnsdJeO1Csh3QHKe3zjd1WdWaoH5/oO/d7WgN1ZFGBBZjtN4OzSgKhZP6mAbTozdPs6p5YwTN+TFr/Sm19kRHrw/gMsEPchgLVMdJ3r1ZZlMVPX9MPqaiYPdgvEbfrTw+UvI1YmdOyt0Slz7ajV4XyLGN5QSiYWv7uquuRdSItqMTsfubjCRXQIDAQAB\\\"\" L'entr\u00e9e TXT se fait obligatoirement dans un sous-domaine _domainkey . Ici, le s\u00e9lecteur est civikim1 . Les param\u00e8tres de l'entr\u00e9e sont l'algorithme de hash (h), l'algorithme de signature (k), et la clef publique, sous forme d'encodage base64 du format DER de la clef publique. On se souviendra que dans la signature de mail g\u00e9n\u00e9r\u00e9e, tous les en-t\u00eates ne sont pas prot\u00e9g\u00e9s par la signature. En revanche, le contenu du mail est prot\u00e9g\u00e9 par la signature. Ceci peut s'expliquer que les diff\u00e9rents acteurs sur le trajet du mail peuvent int\u00e9grer leurs headers dans le mail, et cela peut donc de comprendre la pr\u00e9sence du hash des headers dans la signature.","title":"Signature et v\u00e9rification de signature"},{"location":"TECHNIQUE/MAIL/sendmail.html#envoi-du-mail","text":"Msmtp a \u00e9t\u00e9 s\u00e9lectionn\u00e9 pour l'envoi des mails. En r\u00e9alit\u00e9, un bon nombre de programmes analogues existe, mais msmtp a la particularit\u00e9 de disposer d'un grand nombre d'options pour l'authentification, ainsi que le support de SSL : on a donc un outil qui, on peut esp\u00e9rer, saura s'adapter aux exigences d'un bon nombre de serveurs SMTP. Le param\u00e8tre --read-envelope-from sp\u00e9cifie que le programme doit lire le champ From de l'en-t\u00eate du mail pour le MAIL FROM. Le coeur de configuration, qui changera pour chaque paroisse, est embarqu\u00e9 dans un fichier de configuration, comme par exemple : defaults account default host mailcatcher port 25 auth off protocol smtp logfile - On cr\u00e9e ici une configuration \"par d\u00e9faut\", ici en sp\u00e9cifiant un envoi par smtp vers le port 25, sans authentification. En production, on utiliserait de l'authentification et on configurerait le support SSL/TLS.","title":"Envoi du mail"},{"location":"TECHNIQUE/MAIL/sendmail.html#serveur-de-mail","text":"Le serveur de mail de test utilis\u00e9 est mailcatcher. Il est simple de mise en oeuvre et dispose d'une interface web pour pouvoir r\u00e9cup\u00e9rer les mails (et alors \u00e9galement tester la signature du mail).","title":"Serveur de mail"}]}